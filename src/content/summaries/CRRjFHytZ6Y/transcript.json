{
  "videoId": "CRRjFHytZ6Y",
  "language": "en",
  "source": "caption-extractor",
  "segments": [
    {
      "start": 0.08,
      "duration": 3.839,
      "text": "Andre Karpathy, one of the most"
    },
    {
      "start": 2.56,
      "duration": 4.16,
      "text": "important figures in artificial"
    },
    {
      "start": 3.919,
      "duration": 5.6,
      "text": "intelligence, says we're 10 years away"
    },
    {
      "start": 6.72,
      "duration": 5.999,
      "text": "from AGI. He was just on Dwaresh's"
    },
    {
      "start": 9.519,
      "duration": 5.28,
      "text": "podcast, and it was really an incredible"
    },
    {
      "start": 12.719,
      "duration": 5.121,
      "text": "discussion between the two. But I"
    },
    {
      "start": 14.799,
      "duration": 5.441,
      "text": "actually found his follow-up post on X"
    },
    {
      "start": 17.84,
      "duration": 3.84,
      "text": "to be just as interesting. And that's"
    },
    {
      "start": 20.24,
      "duration": 3.119,
      "text": "what we're going to go over today. He"
    },
    {
      "start": 21.68,
      "duration": 4,
      "text": "clarifies many of the points he made on"
    },
    {
      "start": 23.359,
      "duration": 4,
      "text": "the Darkh podcast and even goes a little"
    },
    {
      "start": 25.68,
      "duration": 3.519,
      "text": "bit further. Let's get into it. And"
    },
    {
      "start": 27.359,
      "duration": 6.161,
      "text": "quickly, let me just tell you about our"
    },
    {
      "start": 29.199,
      "duration": 6.88,
      "text": "new 100 ways to use AI guide. This is"
    },
    {
      "start": 33.52,
      "duration": 4.24,
      "text": "absolutely free, created by my team. All"
    },
    {
      "start": 36.079,
      "duration": 3.841,
      "text": "you need to do is subscribe to our"
    },
    {
      "start": 37.76,
      "duration": 3.92,
      "text": "newsletter. I'll drop the link down"
    },
    {
      "start": 39.92,
      "duration": 3.36,
      "text": "below. Download it right now. Check it"
    },
    {
      "start": 41.68,
      "duration": 4.8,
      "text": "out. All right. So, first he talks about"
    },
    {
      "start": 43.28,
      "duration": 6.08,
      "text": "AGI timelines. And yes, he did say AGI"
    },
    {
      "start": 46.48,
      "duration": 5.919,
      "text": "is 10 plus years away. The first thing"
    },
    {
      "start": 49.36,
      "duration": 5.6,
      "text": "he clarifies is this is the decade of"
    },
    {
      "start": 52.399,
      "duration": 5.281,
      "text": "agents. And this is really in response"
    },
    {
      "start": 54.96,
      "duration": 4.72,
      "text": "to OpenAI and others saying this is the"
    },
    {
      "start": 57.68,
      "duration": 3.76,
      "text": "year of agents. And it's kind of an"
    },
    {
      "start": 59.68,
      "duration": 3.359,
      "text": "interesting point to make because what"
    },
    {
      "start": 61.44,
      "duration": 3.759,
      "text": "does it even mean the year of agents,"
    },
    {
      "start": 63.039,
      "duration": 4.321,
      "text": "the decade of agents? When I say the"
    },
    {
      "start": 65.199,
      "duration": 4.96,
      "text": "year of agents, I just mean it's going"
    },
    {
      "start": 67.36,
      "duration": 5.119,
      "text": "to become at the forefront of people's"
    },
    {
      "start": 70.159,
      "duration": 4.241,
      "text": "thoughts and implementations. I think"
    },
    {
      "start": 72.479,
      "duration": 3.281,
      "text": "when he says the decade of agents,"
    },
    {
      "start": 74.4,
      "duration": 3.759,
      "text": "that's how long it's going to take to"
    },
    {
      "start": 75.76,
      "duration": 4.88,
      "text": "actually get agents that are usable,"
    },
    {
      "start": 78.159,
      "duration": 4.96,
      "text": "valuable, and proliferating through the"
    },
    {
      "start": 80.64,
      "duration": 4.799,
      "text": "entire economy. So he links a tweet that"
    },
    {
      "start": 83.119,
      "duration": 4.401,
      "text": "he posted from earlier this year. Let me"
    },
    {
      "start": 85.439,
      "duration": 4.081,
      "text": "show it to you. Projects like OpenAI's"
    },
    {
      "start": 87.52,
      "duration": 3.68,
      "text": "operator are to the digital world as"
    },
    {
      "start": 89.52,
      "duration": 2.959,
      "text": "humanoid robots are to the physical"
    },
    {
      "start": 91.2,
      "duration": 4,
      "text": "world. Now if you don't remember what"
    },
    {
      "start": 92.479,
      "duration": 4.64,
      "text": "OpenAI's operator is, it hasn't really"
    },
    {
      "start": 95.2,
      "duration": 4.16,
      "text": "been all that popular, I don't believe,"
    },
    {
      "start": 97.119,
      "duration": 4.64,
      "text": "but it's basically Chad GPT that can"
    },
    {
      "start": 99.36,
      "duration": 4.799,
      "text": "take control of the browser and actually"
    },
    {
      "start": 101.759,
      "duration": 4.801,
      "text": "browse the web on your behalf. This was"
    },
    {
      "start": 104.159,
      "duration": 4.401,
      "text": "a really special project. We've seen a"
    },
    {
      "start": 106.56,
      "duration": 4.64,
      "text": "number of other projects very similar to"
    },
    {
      "start": 108.56,
      "duration": 5.12,
      "text": "it, but what makes it so special is the"
    },
    {
      "start": 111.2,
      "duration": 4.72,
      "text": "fact that it is generalized. You just"
    },
    {
      "start": 113.68,
      "duration": 4.799,
      "text": "need to give it a web browser and a"
    },
    {
      "start": 115.92,
      "duration": 4.72,
      "text": "prompt or a task and it's going to go"
    },
    {
      "start": 118.479,
      "duration": 4,
      "text": "out and actually accomplish things on"
    },
    {
      "start": 120.64,
      "duration": 3.68,
      "text": "your behalf without having any"
    },
    {
      "start": 122.479,
      "duration": 4.24,
      "text": "specialized knowledge of what you're"
    },
    {
      "start": 124.32,
      "duration": 4.639,
      "text": "asking it to do. So one general setting"
    },
    {
      "start": 126.719,
      "duration": 4.32,
      "text": "monitor keyboard and mouse or human body"
    },
    {
      "start": 128.959,
      "duration": 5.681,
      "text": "that can in principle gradually perform"
    },
    {
      "start": 131.039,
      "duration": 5.041,
      "text": "arbitrarily general tasks via an IO"
    },
    {
      "start": 134.64,
      "duration": 3.76,
      "text": "interface originally designed for"
    },
    {
      "start": 136.08,
      "duration": 4.56,
      "text": "humans. In both cases, it leads to a"
    },
    {
      "start": 138.4,
      "duration": 4.559,
      "text": "gradually mixed autonomy world where"
    },
    {
      "start": 140.64,
      "duration": 4.48,
      "text": "humans become highlevel supervisors of"
    },
    {
      "start": 142.959,
      "duration": 3.841,
      "text": "low-level automation. This will happen"
    },
    {
      "start": 145.12,
      "duration": 3.52,
      "text": "faster in the digital world than in the"
    },
    {
      "start": 146.8,
      "duration": 3.76,
      "text": "physical world because flipping bits is"
    },
    {
      "start": 148.64,
      "duration": 3.84,
      "text": "somewhere around a thousand times less"
    },
    {
      "start": 150.56,
      "duration": 4,
      "text": "expensive than moving atoms. That just"
    },
    {
      "start": 152.48,
      "duration": 4.08,
      "text": "means that an AI can manipulate the"
    },
    {
      "start": 154.56,
      "duration": 4.88,
      "text": "internet much more easily than it can"
    },
    {
      "start": 156.56,
      "duration": 5.039,
      "text": "manipulate the real physical world. But"
    },
    {
      "start": 159.44,
      "duration": 4.4,
      "text": "here's the interesting part though. The"
    },
    {
      "start": 161.599,
      "duration": 4.961,
      "text": "market size and opportunity feels a lot"
    },
    {
      "start": 163.84,
      "duration": 5.2,
      "text": "bigger in physical world. Now what do"
    },
    {
      "start": 166.56,
      "duration": 5.12,
      "text": "you think about that? Do you think that"
    },
    {
      "start": 169.04,
      "duration": 4.8,
      "text": "knowledge work is a bigger market"
    },
    {
      "start": 171.68,
      "duration": 5.04,
      "text": "opportunity than physical work? I think"
    },
    {
      "start": 173.84,
      "duration": 5.36,
      "text": "potentially if we expand beyond Earth"
    },
    {
      "start": 176.72,
      "duration": 4.96,
      "text": "then really it's infinite in the"
    },
    {
      "start": 179.2,
      "duration": 4.319,
      "text": "physical world. But right now, it just"
    },
    {
      "start": 181.68,
      "duration": 3.76,
      "text": "seems like knowledge work is the bigger"
    },
    {
      "start": 183.519,
      "duration": 4.401,
      "text": "opportunity. But here's why he says it's"
    },
    {
      "start": 185.44,
      "duration": 4.64,
      "text": "the decade of agents and not the year of"
    },
    {
      "start": 187.92,
      "duration": 4.239,
      "text": "agents. People on my timeline are saying"
    },
    {
      "start": 190.08,
      "duration": 4.879,
      "text": "2025 is the year of agents. Personally,"
    },
    {
      "start": 192.159,
      "duration": 4.401,
      "text": "I think 2025 to 2035 is the decade of"
    },
    {
      "start": 194.959,
      "duration": 3.521,
      "text": "agents. I feel a huge amount of work"
    },
    {
      "start": 196.56,
      "duration": 4.8,
      "text": "across the board to make it actually"
    },
    {
      "start": 198.48,
      "duration": 5.36,
      "text": "work, but it should work. And what he's"
    },
    {
      "start": 201.36,
      "duration": 5.44,
      "text": "talking about is scaffolding. Now, back"
    },
    {
      "start": 203.84,
      "duration": 5.44,
      "text": "to this recent post. Basically, my AI"
    },
    {
      "start": 206.8,
      "duration": 4.88,
      "text": "timelines are about five to 10 times"
    },
    {
      "start": 209.28,
      "duration": 4.56,
      "text": "pessimistic with regards to what you'll"
    },
    {
      "start": 211.68,
      "duration": 4.559,
      "text": "find in your neighborhood SFAI house"
    },
    {
      "start": 213.84,
      "duration": 4.16,
      "text": "party or on your Twitter timeline."
    },
    {
      "start": 216.239,
      "duration": 4.241,
      "text": "Basically, everything that I'm exposed"
    },
    {
      "start": 218,
      "duration": 4.72,
      "text": "to and likely you're exposed to as well."
    },
    {
      "start": 220.48,
      "duration": 4.16,
      "text": "I'm extremely optimistic. I don't think"
    },
    {
      "start": 222.72,
      "duration": 4.48,
      "text": "it's one year. I also don't think it's"
    },
    {
      "start": 224.64,
      "duration": 5.04,
      "text": "10 years, but still quite optimistic"
    },
    {
      "start": 227.2,
      "duration": 5.2,
      "text": "with regards to a rising tide of AI"
    },
    {
      "start": 229.68,
      "duration": 5.119,
      "text": "deniers and skeptics. So he really finds"
    },
    {
      "start": 232.4,
      "duration": 4.8,
      "text": "himself believing we're somewhere in the"
    },
    {
      "start": 234.799,
      "duration": 5.201,
      "text": "middle of the most pessimistic and the"
    },
    {
      "start": 237.2,
      "duration": 6,
      "text": "most optimistic. So here's the conflict"
    },
    {
      "start": 240,
      "duration": 4.799,
      "text": "as he lays it out. One, we saw a huge"
    },
    {
      "start": 243.2,
      "duration": 4.08,
      "text": "amount of progress in recent years with"
    },
    {
      "start": 244.799,
      "duration": 4.881,
      "text": "LLMs. This is true. Look at the end of"
    },
    {
      "start": 247.28,
      "duration": 4.64,
      "text": "2022 when Chat GBT first came out till"
    },
    {
      "start": 249.68,
      "duration": 4.559,
      "text": "now. Look how much progress we've seen."
    },
    {
      "start": 251.92,
      "duration": 3.92,
      "text": "But at the same time, there is still a"
    },
    {
      "start": 254.239,
      "duration": 3.84,
      "text": "lot of work remaining. grunt work,"
    },
    {
      "start": 255.84,
      "duration": 4.16,
      "text": "integration work, sensors and actuators"
    },
    {
      "start": 258.079,
      "duration": 3.761,
      "text": "to the physical world, societal work,"
    },
    {
      "start": 260,
      "duration": 4.56,
      "text": "safety and security work, jailbreaks,"
    },
    {
      "start": 261.84,
      "duration": 4.4,
      "text": "poisoning, etc. And also research to get"
    },
    {
      "start": 264.56,
      "duration": 3.6,
      "text": "done before we have an entity that you'd"
    },
    {
      "start": 266.24,
      "duration": 4.399,
      "text": "prefer to hire over a person for an"
    },
    {
      "start": 268.16,
      "duration": 3.84,
      "text": "arbitrary job in the world. And he's"
    },
    {
      "start": 270.639,
      "duration": 3.84,
      "text": "right. And all of the things he"
    },
    {
      "start": 272,
      "duration": 4.24,
      "text": "mentioned, or at least some of them, are"
    },
    {
      "start": 274.479,
      "duration": 4.321,
      "text": "going to be accomplished by continued"
    },
    {
      "start": 276.24,
      "duration": 4.239,
      "text": "rollout of scaffolding. This is what a"
    },
    {
      "start": 278.8,
      "duration": 3.92,
      "text": "lot of people refer to as model"
    },
    {
      "start": 280.479,
      "duration": 4.881,
      "text": "overhang. The capabilities, the"
    },
    {
      "start": 282.72,
      "duration": 6.08,
      "text": "intelligence in the core models are"
    },
    {
      "start": 285.36,
      "duration": 5.68,
      "text": "really good, but the actual tooling and"
    },
    {
      "start": 288.8,
      "duration": 4.8,
      "text": "the memory and the infrastructure"
    },
    {
      "start": 291.04,
      "duration": 4.48,
      "text": "buildout to actually power and gain"
    },
    {
      "start": 293.6,
      "duration": 5.2,
      "text": "value from the core intelligence of"
    },
    {
      "start": 295.52,
      "duration": 4.88,
      "text": "these models is still way behind the"
    },
    {
      "start": 298.8,
      "duration": 4.08,
      "text": "actual capabilities of the models. Now,"
    },
    {
      "start": 300.4,
      "duration": 4,
      "text": "Andre Karpathy also says that the core"
    },
    {
      "start": 302.88,
      "duration": 4.24,
      "text": "capabilities of the models are not quite"
    },
    {
      "start": 304.4,
      "duration": 4.48,
      "text": "there yet, but I'm much more optimistic"
    },
    {
      "start": 307.12,
      "duration": 3.359,
      "text": "than he is. I think that overall 10"
    },
    {
      "start": 308.88,
      "duration": 3.84,
      "text": "years should otherwise be a very bullish"
    },
    {
      "start": 310.479,
      "duration": 3.841,
      "text": "timeline for AGI. It's only in contrast"
    },
    {
      "start": 312.72,
      "duration": 5.12,
      "text": "to present hype that it doesn't feel"
    },
    {
      "start": 314.32,
      "duration": 4.96,
      "text": "that way. Next, animals versus ghosts."
    },
    {
      "start": 317.84,
      "duration": 3.04,
      "text": "And I'm going to get to that in one"
    },
    {
      "start": 319.28,
      "duration": 3.44,
      "text": "second. But first, let me just tell you"
    },
    {
      "start": 320.88,
      "duration": 4.159,
      "text": "about the sponsor of today's video, Dell"
    },
    {
      "start": 322.72,
      "duration": 4.479,
      "text": "Technologies. And a special thank you to"
    },
    {
      "start": 325.039,
      "duration": 4.801,
      "text": "Dell Technologies for sponsoring this"
    },
    {
      "start": 327.199,
      "duration": 5.601,
      "text": "portion of the video. Dell's ProMax"
    },
    {
      "start": 329.84,
      "duration": 5.84,
      "text": "family of PCs are incredibly powerful"
    },
    {
      "start": 332.8,
      "duration": 5.6,
      "text": "for AI workloads. using the new Grace"
    },
    {
      "start": 335.68,
      "duration": 6.4,
      "text": "Blackwell series of Nvidia GPUs,"
    },
    {
      "start": 338.4,
      "duration": 7.44,
      "text": "including GB300 and GB10. These are"
    },
    {
      "start": 342.08,
      "duration": 6.399,
      "text": "absolute monster GPUs in your desktop."
    },
    {
      "start": 345.84,
      "duration": 5.6,
      "text": "Learn more about DellPro Max GB10 and"
    },
    {
      "start": 348.479,
      "duration": 6.881,
      "text": "GB300 and the Dell Pro Max lineup of"
    },
    {
      "start": 351.44,
      "duration": 6,
      "text": "workstations with Nvidia RTX Pro GPUs."
    },
    {
      "start": 355.36,
      "duration": 4.48,
      "text": "Click the link in the description below."
    },
    {
      "start": 357.44,
      "duration": 4.72,
      "text": "Let them know I sent you. Check it out."
    },
    {
      "start": 359.84,
      "duration": 5.52,
      "text": "gist of his point here is that the way"
    },
    {
      "start": 362.16,
      "duration": 5.44,
      "text": "LLMs learn feels much more akin to a"
    },
    {
      "start": 365.36,
      "duration": 3.279,
      "text": "ghost than how animals learn. And he's"
    },
    {
      "start": 367.6,
      "duration": 2.719,
      "text": "going to explain what that actually"
    },
    {
      "start": 368.639,
      "duration": 4.4,
      "text": "means. Let me break it down. I am"
    },
    {
      "start": 370.319,
      "duration": 4.481,
      "text": "suspicious that there is a single simple"
    },
    {
      "start": 373.039,
      "duration": 4.321,
      "text": "algorithm you can let loose on the world"
    },
    {
      "start": 374.8,
      "duration": 5.519,
      "text": "and it learns everything from scratch."
    },
    {
      "start": 377.36,
      "duration": 5.44,
      "text": "Super interesting point. A single simple"
    },
    {
      "start": 380.319,
      "duration": 4,
      "text": "algorithm that can learn everything from"
    },
    {
      "start": 382.8,
      "duration": 3.2,
      "text": "scratch. He doesn't believe that's"
    },
    {
      "start": 384.319,
      "duration": 3.201,
      "text": "possible. If someone builds such a"
    },
    {
      "start": 386,
      "duration": 4.24,
      "text": "thing, I will be wrong and it will be"
    },
    {
      "start": 387.52,
      "duration": 5.36,
      "text": "the most incredible breakthrough in AI."
    },
    {
      "start": 390.24,
      "duration": 5.92,
      "text": "In my mind, animals are not an example"
    },
    {
      "start": 392.88,
      "duration": 5.599,
      "text": "of this at all. They are prepackaged"
    },
    {
      "start": 396.16,
      "duration": 3.84,
      "text": "with a ton of intelligence by evolution,"
    },
    {
      "start": 398.479,
      "duration": 3.681,
      "text": "and the learning they do is quite"
    },
    {
      "start": 400,
      "duration": 4.88,
      "text": "minimal overall. Basically, animals,"
    },
    {
      "start": 402.16,
      "duration": 5.2,
      "text": "including humans, are born with all of"
    },
    {
      "start": 404.88,
      "duration": 4.4,
      "text": "this prepackaged knowledge of how to do"
    },
    {
      "start": 407.36,
      "duration": 3.6,
      "text": "things through generations and"
    },
    {
      "start": 409.28,
      "duration": 4.24,
      "text": "generations of evolution. And the"
    },
    {
      "start": 410.96,
      "duration": 4.4,
      "text": "example he gives, zebras at birth. And"
    },
    {
      "start": 413.52,
      "duration": 4.88,
      "text": "let me show you why he gives this"
    },
    {
      "start": 415.36,
      "duration": 5.92,
      "text": "example. Okay, so this is a zebra just"
    },
    {
      "start": 418.4,
      "duration": 6,
      "text": "after birth. And not only does it know"
    },
    {
      "start": 421.28,
      "duration": 6.319,
      "text": "all the basics like breathing and sight,"
    },
    {
      "start": 424.4,
      "duration": 5.6,
      "text": "but it can start walking immediately and"
    },
    {
      "start": 427.599,
      "duration": 4.641,
      "text": "it knows how. And that is not a simple"
    },
    {
      "start": 430,
      "duration": 6.16,
      "text": "feat. So watch this again right after"
    },
    {
      "start": 432.24,
      "duration": 6.079,
      "text": "birth. Here we go. And kind of wobbly,"
    },
    {
      "start": 436.16,
      "duration": 4.879,
      "text": "but kind of gets the gist of what it"
    },
    {
      "start": 438.319,
      "duration": 4.561,
      "text": "needs to do immediately. Stands up. And"
    },
    {
      "start": 441.039,
      "duration": 4.481,
      "text": "there it goes. And so there we go. It's"
    },
    {
      "start": 442.88,
      "duration": 4.96,
      "text": "starting to walk already. Look at that."
    },
    {
      "start": 445.52,
      "duration": 4.079,
      "text": "Zebras at birth. That is generation"
    },
    {
      "start": 447.84,
      "duration": 4.96,
      "text": "after generation of evolution"
    },
    {
      "start": 449.599,
      "duration": 6.081,
      "text": "prepackaged into this baby animal. But"
    },
    {
      "start": 452.8,
      "duration": 5.519,
      "text": "he says we're not able to replicate"
    },
    {
      "start": 455.68,
      "duration": 6.88,
      "text": "evolution simply with algorithms alone."
    },
    {
      "start": 458.319,
      "duration": 6.801,
      "text": "He says LLMs are a different approach to"
    },
    {
      "start": 462.56,
      "duration": 4.88,
      "text": "learning. It's not evolution. But with"
    },
    {
      "start": 465.12,
      "duration": 4.24,
      "text": "LLMs, we have stumbled by an alternative"
    },
    {
      "start": 467.44,
      "duration": 4.24,
      "text": "approach to prepackage a ton of"
    },
    {
      "start": 469.36,
      "duration": 4.239,
      "text": "intelligence in a neural network. Not by"
    },
    {
      "start": 471.68,
      "duration": 4.799,
      "text": "evolution, but by predicting the next"
    },
    {
      "start": 473.599,
      "duration": 5.44,
      "text": "token over the internet. But that type"
    },
    {
      "start": 476.479,
      "duration": 4.241,
      "text": "of learning is different from evolution."
    },
    {
      "start": 479.039,
      "duration": 4.56,
      "text": "Here's what he says. Distinct from"
    },
    {
      "start": 480.72,
      "duration": 5.44,
      "text": "animals, more like ghosts or spirits. We"
    },
    {
      "start": 483.599,
      "duration": 4.641,
      "text": "can and should make them more animallike"
    },
    {
      "start": 486.16,
      "duration": 4,
      "text": "over time. And in some ways, that's what"
    },
    {
      "start": 488.24,
      "duration": 3.92,
      "text": "a lot of frontier work is all about. And"
    },
    {
      "start": 490.16,
      "duration": 4.4,
      "text": "he specifically talks about memorization"
    },
    {
      "start": 492.16,
      "duration": 4.479,
      "text": "in particular. When we think about LLMs,"
    },
    {
      "start": 494.56,
      "duration": 4.72,
      "text": "they are memorizing things. They aren't"
    },
    {
      "start": 496.639,
      "duration": 5.201,
      "text": "as much generalizing, at least not yet."
    },
    {
      "start": 499.28,
      "duration": 5.44,
      "text": "we see some generalization, especially"
    },
    {
      "start": 501.84,
      "duration": 5.28,
      "text": "on benchmarks like the ARK prize. That's"
    },
    {
      "start": 504.72,
      "duration": 5.84,
      "text": "really a test of generalization. And"
    },
    {
      "start": 507.12,
      "duration": 6.32,
      "text": "generalization is really the key to a"
    },
    {
      "start": 510.56,
      "duration": 5.12,
      "text": "GI, artificial general intelligence."
    },
    {
      "start": 513.44,
      "duration": 5.039,
      "text": "It's not enough just to memorize. That's"
    },
    {
      "start": 515.68,
      "duration": 4.96,
      "text": "good, but being able to learn new things"
    },
    {
      "start": 518.479,
      "duration": 5.12,
      "text": "on the fly rather than having it"
    },
    {
      "start": 520.64,
      "duration": 4.879,
      "text": "explicitly taught to you is really the"
    },
    {
      "start": 523.599,
      "duration": 3.841,
      "text": "key. And then he kind of doubles down"
    },
    {
      "start": 525.519,
      "duration": 4.32,
      "text": "and talks about reinforcement learning."
    },
    {
      "start": 527.44,
      "duration": 4.8,
      "text": "So, I've critiqued RL a few times"
    },
    {
      "start": 529.839,
      "duration": 4.481,
      "text": "already. First, you're sucking"
    },
    {
      "start": 532.24,
      "duration": 5.039,
      "text": "supervision through a straw. So, I think"
    },
    {
      "start": 534.32,
      "duration": 5.68,
      "text": "the signal per flop is very bad, which"
    },
    {
      "start": 537.279,
      "duration": 5.201,
      "text": "basically means how much actual learning"
    },
    {
      "start": 540,
      "duration": 5.2,
      "text": "you get per how much compute you use to"
    },
    {
      "start": 542.48,
      "duration": 3.76,
      "text": "get there is really bad at this point."
    },
    {
      "start": 545.2,
      "duration": 2.88,
      "text": "But I think it's only going to get"
    },
    {
      "start": 546.24,
      "duration": 4,
      "text": "better. I mean, obviously, it's only"
    },
    {
      "start": 548.08,
      "duration": 4.56,
      "text": "going to get better. But is that ratio"
    },
    {
      "start": 550.24,
      "duration": 4.88,
      "text": "going to improve enough to really hit"
    },
    {
      "start": 552.64,
      "duration": 4.4,
      "text": "generalization? RL is very noisy because"
    },
    {
      "start": 555.12,
      "duration": 4.08,
      "text": "a completion might have lots of errors"
    },
    {
      "start": 557.04,
      "duration": 4.64,
      "text": "that might get encouraged if you happen"
    },
    {
      "start": 559.2,
      "duration": 4.96,
      "text": "to stumble to the right answer and"
    },
    {
      "start": 561.68,
      "duration": 4.24,
      "text": "conversely brilliant insight tokens that"
    },
    {
      "start": 564.16,
      "duration": 4.96,
      "text": "might get discouraged if you happen to"
    },
    {
      "start": 565.92,
      "duration": 5.84,
      "text": "screw up later. This is the problem with"
    },
    {
      "start": 569.12,
      "duration": 4.56,
      "text": "outcomebased rewards. So let me just"
    },
    {
      "start": 571.76,
      "duration": 4.16,
      "text": "break down what that means for you. With"
    },
    {
      "start": 573.68,
      "duration": 4.96,
      "text": "outcomebased rewards in reinforcement"
    },
    {
      "start": 575.92,
      "duration": 4.08,
      "text": "learning, you are telling the model, you"
    },
    {
      "start": 578.64,
      "duration": 3.92,
      "text": "are telling the weights, you're updating"
    },
    {
      "start": 580,
      "duration": 4.959,
      "text": "the weights whenever something goes"
    },
    {
      "start": 582.56,
      "duration": 4.399,
      "text": "right. And so if you think about how"
    },
    {
      "start": 584.959,
      "duration": 4.56,
      "text": "chain of thought works, there are a"
    },
    {
      "start": 586.959,
      "duration": 4.801,
      "text": "bunch of intermediate thoughts that"
    },
    {
      "start": 589.519,
      "duration": 4.081,
      "text": "happen before the final answer. So let's"
    },
    {
      "start": 591.76,
      "duration": 5.12,
      "text": "give a really simple example. 1 plus 1"
    },
    {
      "start": 593.6,
      "duration": 5.679,
      "text": "equals 2. And let's say the model has to"
    },
    {
      "start": 596.88,
      "duration": 4.32,
      "text": "think a ton about it. And it thinks in"
    },
    {
      "start": 599.279,
      "duration": 5.361,
      "text": "all the wrong ways. And it says, \"Okay,"
    },
    {
      "start": 601.2,
      "duration": 6.16,
      "text": "well 1 minus 1 is 0 and that must mean"
    },
    {
      "start": 604.64,
      "duration": 5.04,
      "text": "10 + 50 is 60.\" And it's having all of"
    },
    {
      "start": 607.36,
      "duration": 4.08,
      "text": "these irrelevant thoughts. Or really, it"
    },
    {
      "start": 609.68,
      "duration": 4.88,
      "text": "could just be fundamentally wrong. So it"
    },
    {
      "start": 611.44,
      "duration": 5.44,
      "text": "could say 3 + 3 is 50. And then at the"
    },
    {
      "start": 614.56,
      "duration": 5.04,
      "text": "final answer when it says 1 + 1 equals"
    },
    {
      "start": 616.88,
      "duration": 4.8,
      "text": "2, the entire thought process gets"
    },
    {
      "start": 619.6,
      "duration": 4.16,
      "text": "rewarded. And so it's actually thinking,"
    },
    {
      "start": 621.68,
      "duration": 3.92,
      "text": "oh look, everything I thought along the"
    },
    {
      "start": 623.76,
      "duration": 3.44,
      "text": "way and the final answer is actually"
    },
    {
      "start": 625.6,
      "duration": 4,
      "text": "correct. Now that's where process"
    },
    {
      "start": 627.2,
      "duration": 4.56,
      "text": "rewards come into play. But even those"
    },
    {
      "start": 629.6,
      "duration": 4.08,
      "text": "have problems as he's saying. So let's"
    },
    {
      "start": 631.76,
      "duration": 4.4,
      "text": "say your model takes five steps to"
    },
    {
      "start": 633.68,
      "duration": 4.08,
      "text": "figure something out and at the and then"
    },
    {
      "start": 636.16,
      "duration": 3.919,
      "text": "when it reaches the final answer, the"
    },
    {
      "start": 637.76,
      "duration": 5.28,
      "text": "final answer is wrong. But each of the"
    },
    {
      "start": 640.079,
      "duration": 4.801,
      "text": "five steps is right. That final signal"
    },
    {
      "start": 643.04,
      "duration": 4,
      "text": "is going to tell it, hey, you got those"
    },
    {
      "start": 644.88,
      "duration": 3.519,
      "text": "steps right, but the overall answer was"
    },
    {
      "start": 647.04,
      "duration": 4,
      "text": "wrong. And so it's actually going to get"
    },
    {
      "start": 648.399,
      "duration": 4.641,
      "text": "penalized even though those intermediate"
    },
    {
      "start": 651.04,
      "duration": 4.16,
      "text": "steps were really good. Process"
    },
    {
      "start": 653.04,
      "duration": 4.72,
      "text": "supervision and LLM judges have issues,"
    },
    {
      "start": 655.2,
      "duration": 5.28,
      "text": "too. I think we'll see alternative"
    },
    {
      "start": 657.76,
      "duration": 4.8,
      "text": "learning paradigms. I am long agentic"
    },
    {
      "start": 660.48,
      "duration": 4.72,
      "text": "interaction but short reinforcement"
    },
    {
      "start": 662.56,
      "duration": 5.76,
      "text": "learning which is crazy because"
    },
    {
      "start": 665.2,
      "duration": 6.079,
      "text": "seemingly every frontier lab is so"
    },
    {
      "start": 668.32,
      "duration": 5.92,
      "text": "bullish on reinforcement learning but he"
    },
    {
      "start": 671.279,
      "duration": 4.641,
      "text": "says agentic interactions is the way."
    },
    {
      "start": 674.24,
      "duration": 4.32,
      "text": "What I think he's saying with agentic"
    },
    {
      "start": 675.92,
      "duration": 6.24,
      "text": "interactions is essentially creating a"
    },
    {
      "start": 678.56,
      "duration": 5.68,
      "text": "playground for agents to experiment and"
    },
    {
      "start": 682.16,
      "duration": 4.88,
      "text": "learn as they go. This is the way that"
    },
    {
      "start": 684.24,
      "duration": 5.599,
      "text": "the deep mind team who Andre Karpathy"
    },
    {
      "start": 687.04,
      "duration": 4.4,
      "text": "was an intern at was able to create AI"
    },
    {
      "start": 689.839,
      "duration": 3.44,
      "text": "that is the best in the world at the"
    },
    {
      "start": 691.44,
      "duration": 4.399,
      "text": "game go. And there are companies"
    },
    {
      "start": 693.279,
      "duration": 4.641,
      "text": "building world models which are really"
    },
    {
      "start": 695.839,
      "duration": 4.881,
      "text": "just playgrounds for agents either"
    },
    {
      "start": 697.92,
      "duration": 5.2,
      "text": "embodied agents or digital agents to"
    },
    {
      "start": 700.72,
      "duration": 4.48,
      "text": "play around in and figure out things as"
    },
    {
      "start": 703.12,
      "duration": 3.92,
      "text": "they go. He continues, \"I've seen a"
    },
    {
      "start": 705.2,
      "duration": 3.84,
      "text": "number of papers pop up recently that"
    },
    {
      "start": 707.04,
      "duration": 4.799,
      "text": "are, in my opinion, barking up the right"
    },
    {
      "start": 709.04,
      "duration": 4.72,
      "text": "tree along the lines of what I called"
    },
    {
      "start": 711.839,
      "duration": 3.841,
      "text": "system prompt learning.\" So, he"
    },
    {
      "start": 713.76,
      "duration": 3.84,
      "text": "references a post that he made a few"
    },
    {
      "start": 715.68,
      "duration": 3.599,
      "text": "months ago where he defined system"
    },
    {
      "start": 717.6,
      "duration": 4,
      "text": "prompt learning. And by the way, let's"
    },
    {
      "start": 719.279,
      "duration": 4.881,
      "text": "pause for a second and appreciate how"
    },
    {
      "start": 721.6,
      "duration": 5.28,
      "text": "good Andre Karpathy is at naming things."
    },
    {
      "start": 724.16,
      "duration": 5.76,
      "text": "He was the first to name hallucinations."
    },
    {
      "start": 726.88,
      "duration": 5.84,
      "text": "He was the first to name vibe coding."
    },
    {
      "start": 729.92,
      "duration": 4.479,
      "text": "So, he's all over the naming. And now we"
    },
    {
      "start": 732.72,
      "duration": 3.76,
      "text": "have system prompt learning. Let me"
    },
    {
      "start": 734.399,
      "duration": 3.521,
      "text": "explain what that is. So pre-training is"
    },
    {
      "start": 736.48,
      "duration": 3.84,
      "text": "for knowledge. Fine-tuning is for"
    },
    {
      "start": 737.92,
      "duration": 4.32,
      "text": "habitual behavior. Both of these involve"
    },
    {
      "start": 740.32,
      "duration": 4.24,
      "text": "change in parameters. But a lot of human"
    },
    {
      "start": 742.24,
      "duration": 4.24,
      "text": "learning feels more like a change in"
    },
    {
      "start": 744.56,
      "duration": 5.2,
      "text": "system prompt. And remember the system"
    },
    {
      "start": 746.48,
      "duration": 5.76,
      "text": "prompt is the message that you append to"
    },
    {
      "start": 749.76,
      "duration": 4.639,
      "text": "every prompt and it's given to the model"
    },
    {
      "start": 752.24,
      "duration": 4.64,
      "text": "and it basically affects what the"
    },
    {
      "start": 754.399,
      "duration": 4.401,
      "text": "model's behavior is. It's really core to"
    },
    {
      "start": 756.88,
      "duration": 3.759,
      "text": "how the model's personality actually"
    },
    {
      "start": 758.8,
      "duration": 4,
      "text": "manifests. One example of that is when"
    },
    {
      "start": 760.639,
      "duration": 4,
      "text": "XAI changes their system prompt, all of"
    },
    {
      "start": 762.8,
      "duration": 4.32,
      "text": "a sudden it starts talking about Elon"
    },
    {
      "start": 764.639,
      "duration": 4.32,
      "text": "Musk in every single post. The process"
    },
    {
      "start": 767.12,
      "duration": 3.92,
      "text": "is you encounter a problem, figure"
    },
    {
      "start": 768.959,
      "duration": 4.161,
      "text": "something out, then remember something"
    },
    {
      "start": 771.04,
      "duration": 4.32,
      "text": "in fairly explicit terms for the next"
    },
    {
      "start": 773.12,
      "duration": 4.8,
      "text": "time. For example, it seems when I"
    },
    {
      "start": 775.36,
      "duration": 4.08,
      "text": "encounter this and that kind of problem,"
    },
    {
      "start": 777.92,
      "duration": 3.84,
      "text": "I should try this and that kind of"
    },
    {
      "start": 779.44,
      "duration": 4.399,
      "text": "approach solution. It feels more like"
    },
    {
      "start": 781.76,
      "duration": 5.04,
      "text": "taking notes for yourself. And he's"
    },
    {
      "start": 783.839,
      "duration": 4.641,
      "text": "saying the system prompt could be the"
    },
    {
      "start": 786.8,
      "duration": 3.76,
      "text": "best place to take those notes. But the"
    },
    {
      "start": 788.48,
      "duration": 4.4,
      "text": "system prompt is very limited. We have a"
    },
    {
      "start": 790.56,
      "duration": 4.48,
      "text": "context window and that context window"
    },
    {
      "start": 792.88,
      "duration": 3.36,
      "text": "is finite. So you can only put so much"
    },
    {
      "start": 795.04,
      "duration": 3.52,
      "text": "in there. You need to put the system"
    },
    {
      "start": 796.24,
      "duration": 4.399,
      "text": "prompt and you need to put the actual"
    },
    {
      "start": 798.56,
      "duration": 3.6,
      "text": "prompt from the user. It feels more like"
    },
    {
      "start": 800.639,
      "duration": 3.521,
      "text": "taking notes for yourself. Something"
    },
    {
      "start": 802.16,
      "duration": 4.08,
      "text": "like the memory feature. So that's the"
    },
    {
      "start": 804.16,
      "duration": 4.88,
      "text": "memory feature of chat GPT which kind of"
    },
    {
      "start": 806.24,
      "duration": 4.96,
      "text": "has a log of everything it thinks it"
    },
    {
      "start": 809.04,
      "duration": 4.799,
      "text": "needs to remember about the user but not"
    },
    {
      "start": 811.2,
      "duration": 4.56,
      "text": "store per user random facts but general"
    },
    {
      "start": 813.839,
      "duration": 4.081,
      "text": "global problem solving knowledge and"
    },
    {
      "start": 815.76,
      "duration": 4.96,
      "text": "strategies. He actually looked at"
    },
    {
      "start": 817.92,
      "duration": 5.84,
      "text": "Claude's system message, which is 17,000"
    },
    {
      "start": 820.72,
      "duration": 4.96,
      "text": "words, and not only specifies basic"
    },
    {
      "start": 823.76,
      "duration": 4.079,
      "text": "behavior, style, and preferences, but"
    },
    {
      "start": 825.68,
      "duration": 4.32,
      "text": "also has a large amount of general"
    },
    {
      "start": 827.839,
      "duration": 4.24,
      "text": "problem solving. Here's an example. If"
    },
    {
      "start": 830,
      "duration": 3.76,
      "text": "Claude is asked to count words, letters,"
    },
    {
      "start": 832.079,
      "duration": 3.281,
      "text": "and characters, it thinks step by step"
    },
    {
      "start": 833.76,
      "duration": 3.68,
      "text": "before answering the person. It"
    },
    {
      "start": 835.36,
      "duration": 3.919,
      "text": "explicitly counts the words, letters, or"
    },
    {
      "start": 837.44,
      "duration": 4.24,
      "text": "characters by assigning a number to"
    },
    {
      "start": 839.279,
      "duration": 4.321,
      "text": "each. It only answers the person once it"
    },
    {
      "start": 841.68,
      "duration": 5.44,
      "text": "has performed this explicit counting"
    },
    {
      "start": 843.6,
      "duration": 5.2,
      "text": "step. This is explicitly to help Claude"
    },
    {
      "start": 847.12,
      "duration": 4.48,
      "text": "solve the how many Rs are in the word"
    },
    {
      "start": 848.8,
      "duration": 5.279,
      "text": "strawberry test. And he says there have"
    },
    {
      "start": 851.6,
      "duration": 5.12,
      "text": "been a lot of papers that are really"
    },
    {
      "start": 854.079,
      "duration": 4.961,
      "text": "promising, but those papers and what is"
    },
    {
      "start": 856.72,
      "duration": 5.679,
      "text": "actually out in the world at production"
    },
    {
      "start": 859.04,
      "duration": 5.599,
      "text": "scale is lacking to say the least. And"
    },
    {
      "start": 862.399,
      "duration": 5.12,
      "text": "he references chai chipt memory once"
    },
    {
      "start": 864.639,
      "duration": 5.521,
      "text": "more but it is the primordial deployed"
    },
    {
      "start": 867.519,
      "duration": 4.641,
      "text": "example of a new learning paradigm which"
    },
    {
      "start": 870.16,
      "duration": 3.52,
      "text": "basically means it is just the most"
    },
    {
      "start": 872.16,
      "duration": 4.799,
      "text": "basic version of what he's talking"
    },
    {
      "start": 873.68,
      "duration": 6.48,
      "text": "about. He also talks about the cognitive"
    },
    {
      "start": 876.959,
      "duration": 5.281,
      "text": "core. So he really is railing against"
    },
    {
      "start": 880.16,
      "duration": 4.56,
      "text": "memorization which is what happens when"
    },
    {
      "start": 882.24,
      "duration": 4.56,
      "text": "you scale these models up tremendously."
    },
    {
      "start": 884.72,
      "duration": 4.32,
      "text": "So, cognitive core, the idea of"
    },
    {
      "start": 886.8,
      "duration": 4.159,
      "text": "stripping down LLMs of making it harder"
    },
    {
      "start": 889.04,
      "duration": 4.88,
      "text": "for them to memorize or actively"
    },
    {
      "start": 890.959,
      "duration": 5.361,
      "text": "stripping away their memory to make them"
    },
    {
      "start": 893.92,
      "duration": 3.919,
      "text": "better at generalization. Otherwise,"
    },
    {
      "start": 896.32,
      "duration": 4.56,
      "text": "they lean too hard on what they've"
    },
    {
      "start": 897.839,
      "duration": 5.68,
      "text": "memorized. And of course, let's make the"
    },
    {
      "start": 900.88,
      "duration": 4.88,
      "text": "comparison to humans. So, humans can't"
    },
    {
      "start": 903.519,
      "duration": 5.12,
      "text": "memorize so easily, which now looks more"
    },
    {
      "start": 905.76,
      "duration": 4.96,
      "text": "like a feature than a bug by contrast."
    },
    {
      "start": 908.639,
      "duration": 4.401,
      "text": "Because if we memorize everything, then"
    },
    {
      "start": 910.72,
      "duration": 6.08,
      "text": "of course we're always going to use our"
    },
    {
      "start": 913.04,
      "duration": 6.32,
      "text": "memory as our crutch, as our go-to for"
    },
    {
      "start": 916.8,
      "duration": 4.32,
      "text": "any future learning. Maybe the inability"
    },
    {
      "start": 919.36,
      "duration": 4.08,
      "text": "to memorize is kind of like"
    },
    {
      "start": 921.12,
      "duration": 4,
      "text": "regularization. And so, let me actually"
    },
    {
      "start": 923.44,
      "duration": 4,
      "text": "go a little bit deeper into his"
    },
    {
      "start": 925.12,
      "duration": 4.159,
      "text": "cognitive core post. This was a post"
    },
    {
      "start": 927.44,
      "duration": 4,
      "text": "from just a few months ago. With the"
    },
    {
      "start": 929.279,
      "duration": 3.841,
      "text": "cognitive core, he means a few billion"
    },
    {
      "start": 931.44,
      "duration": 4,
      "text": "parameter model that maximally"
    },
    {
      "start": 933.12,
      "duration": 4.88,
      "text": "sacrifices encyclopedic knowledge for"
    },
    {
      "start": 935.44,
      "duration": 4,
      "text": "capability. And we started to see a"
    },
    {
      "start": 938,
      "duration": 3.199,
      "text": "couple things like that. In fact,"
    },
    {
      "start": 939.44,
      "duration": 3.92,
      "text": "remember just a couple weeks ago, we had"
    },
    {
      "start": 941.199,
      "duration": 4,
      "text": "that incredible paper that showed, I"
    },
    {
      "start": 943.36,
      "duration": 4,
      "text": "believe it was like a 7 million"
    },
    {
      "start": 945.199,
      "duration": 4.961,
      "text": "parameter model that was quite capable"
    },
    {
      "start": 947.36,
      "duration": 5.2,
      "text": "of solving puzzles. It lives always on"
    },
    {
      "start": 950.16,
      "duration": 4.64,
      "text": "and by default on every computer as the"
    },
    {
      "start": 952.56,
      "duration": 4.88,
      "text": "kernel of LLM personal computing. Its"
    },
    {
      "start": 954.8,
      "duration": 5.2,
      "text": "features are slowly crystallizing. One"
    },
    {
      "start": 957.44,
      "duration": 5.36,
      "text": "natively multimodal text vision audio at"
    },
    {
      "start": 960,
      "duration": 5.04,
      "text": "both input and output. Matrioska style"
    },
    {
      "start": 962.8,
      "duration": 4.24,
      "text": "architecture allowing a dial of"
    },
    {
      "start": 965.04,
      "duration": 4.4,
      "text": "capability up and down at test time"
    },
    {
      "start": 967.04,
      "duration": 5.039,
      "text": "reasoning also with a dial system 2"
    },
    {
      "start": 969.44,
      "duration": 4.959,
      "text": "aggressively tool using ondevice"
    },
    {
      "start": 972.079,
      "duration": 3.601,
      "text": "fine-tuning Laura slots for test time"
    },
    {
      "start": 974.399,
      "duration": 3.761,
      "text": "training personalization and"
    },
    {
      "start": 975.68,
      "duration": 4.959,
      "text": "customization and delegates and doublech"
    },
    {
      "start": 978.16,
      "duration": 4.72,
      "text": "checkcks just the right parts with the"
    },
    {
      "start": 980.639,
      "duration": 6.161,
      "text": "oracles in the cloud if internet is"
    },
    {
      "start": 982.88,
      "duration": 6.8,
      "text": "available and this was in reply to Gemma"
    },
    {
      "start": 986.8,
      "duration": 5.12,
      "text": "3N coming out that's the open-source"
    },
    {
      "start": 989.68,
      "duration": 4.24,
      "text": "very small highly capable model from"
    },
    {
      "start": 991.92,
      "duration": 4.64,
      "text": "Google. Then he finishes on this point"
    },
    {
      "start": 993.92,
      "duration": 5.279,
      "text": "with the trend in model sizes backwards"
    },
    {
      "start": 996.56,
      "duration": 4.48,
      "text": "and why models have to first get larger"
    },
    {
      "start": 999.199,
      "duration": 4.481,
      "text": "before they can get smaller. The next"
    },
    {
      "start": 1001.04,
      "duration": 4.88,
      "text": "point I want to touch on is LLM agents"
    },
    {
      "start": 1003.68,
      "duration": 4.32,
      "text": "and what he thinks about that. So he did"
    },
    {
      "start": 1005.92,
      "duration": 4.479,
      "text": "have some pretty strong critiques of the"
    },
    {
      "start": 1008,
      "duration": 3.92,
      "text": "agent industry in its current form."
    },
    {
      "start": 1010.399,
      "duration": 3.601,
      "text": "Specifically, my critique of the"
    },
    {
      "start": 1011.92,
      "duration": 3.919,
      "text": "industry is more in overshooting the"
    },
    {
      "start": 1014,
      "duration": 3.839,
      "text": "tooling with respect to present"
    },
    {
      "start": 1015.839,
      "duration": 4.481,
      "text": "capability. And he goes on to explain"
    },
    {
      "start": 1017.839,
      "duration": 5.761,
      "text": "his current view of agents is he wants"
    },
    {
      "start": 1020.32,
      "duration": 6.16,
      "text": "to collaborate with LLMs with agents"
    },
    {
      "start": 1023.6,
      "duration": 6,
      "text": "where his shortcomings and and their"
    },
    {
      "start": 1026.48,
      "duration": 5.439,
      "text": "strong suits are paired up really well."
    },
    {
      "start": 1029.6,
      "duration": 5.12,
      "text": "But he doesn't think agents are quite"
    },
    {
      "start": 1031.919,
      "duration": 5.441,
      "text": "ready to just be assigned a task and go"
    },
    {
      "start": 1034.72,
      "duration": 5.76,
      "text": "off for 20 30 minutes at a time. And in"
    },
    {
      "start": 1037.36,
      "duration": 6,
      "text": "fact, he specifically said his newest"
    },
    {
      "start": 1040.48,
      "duration": 6.559,
      "text": "project, Nano Chat, was built almost"
    },
    {
      "start": 1043.36,
      "duration": 5.679,
      "text": "entirely by hand. Manual coding, no vibe"
    },
    {
      "start": 1047.039,
      "duration": 3.52,
      "text": "coding. The industry lives in a future"
    },
    {
      "start": 1049.039,
      "duration": 3.441,
      "text": "where fully autonomous entities"
    },
    {
      "start": 1050.559,
      "duration": 3.841,
      "text": "collaborate in parallel to write all the"
    },
    {
      "start": 1052.48,
      "duration": 4.24,
      "text": "code and humans are useless. For"
    },
    {
      "start": 1054.4,
      "duration": 3.92,
      "text": "example, I don't want an agent that goes"
    },
    {
      "start": 1056.72,
      "duration": 3.199,
      "text": "off for 20 minutes and comes back with a"
    },
    {
      "start": 1058.32,
      "duration": 3.68,
      "text": "thousand lines of code. I certainly"
    },
    {
      "start": 1059.919,
      "duration": 3.841,
      "text": "don't feel ready to supervise a team of"
    },
    {
      "start": 1062,
      "duration": 3.84,
      "text": "10 of them. I'd like to go in chunks"
    },
    {
      "start": 1063.76,
      "duration": 4.56,
      "text": "that I can keep in my head where an LLM"
    },
    {
      "start": 1065.84,
      "duration": 4.64,
      "text": "explains the code that it is writing."
    },
    {
      "start": 1068.32,
      "duration": 4.32,
      "text": "I'd like it to prove to me that what it"
    },
    {
      "start": 1070.48,
      "duration": 4.72,
      "text": "did is correct. I want it to pull the"
    },
    {
      "start": 1072.64,
      "duration": 5.44,
      "text": "API docs and show me that it used things"
    },
    {
      "start": 1075.2,
      "duration": 4.96,
      "text": "correctly. Fewer assumptions and asked"
    },
    {
      "start": 1078.08,
      "duration": 4.88,
      "text": "to collaborate when it's not sure about"
    },
    {
      "start": 1080.16,
      "duration": 4.879,
      "text": "something. And he specifically says if"
    },
    {
      "start": 1082.96,
      "duration": 3.599,
      "text": "agents do just go out and write a"
    },
    {
      "start": 1085.039,
      "duration": 3.76,
      "text": "thousand or a few thousand lines of code"
    },
    {
      "start": 1086.559,
      "duration": 5.681,
      "text": "and then come back and I don't really"
    },
    {
      "start": 1088.799,
      "duration": 5.76,
      "text": "review every single line by line with"
    },
    {
      "start": 1092.24,
      "duration": 4.48,
      "text": "high precision and understanding of the"
    },
    {
      "start": 1094.559,
      "duration": 4.961,
      "text": "context. We're going to have what he"
    },
    {
      "start": 1096.72,
      "duration": 5.44,
      "text": "calls mountains of slop. And I want to"
    },
    {
      "start": 1099.52,
      "duration": 5.12,
      "text": "finish with one fun little tidbit. Elon"
    },
    {
      "start": 1102.16,
      "duration": 4,
      "text": "Musk replied to this post and said, \"You"
    },
    {
      "start": 1104.64,
      "duration": 3.6,
      "text": "make a lot of great points, especially"
    },
    {
      "start": 1106.16,
      "duration": 4.72,
      "text": "that children should learn the tools of"
    },
    {
      "start": 1108.24,
      "duration": 4.72,
      "text": "physics early. Are you down for an AI"
    },
    {
      "start": 1110.88,
      "duration": 4.159,
      "text": "coding contest or whatever form of"
    },
    {
      "start": 1112.96,
      "duration": 5.36,
      "text": "competition you'd like for Andre vers"
    },
    {
      "start": 1115.039,
      "duration": 4.801,
      "text": "Grock 5, Allah Kasparov verse Deep Blue?"
    },
    {
      "start": 1118.32,
      "duration": 4.4,
      "text": "And if you don't remember, Gary"
    },
    {
      "start": 1119.84,
      "duration": 5.04,
      "text": "Kasparov, one of the best chess players"
    },
    {
      "start": 1122.72,
      "duration": 5.04,
      "text": "of all time. I believe it was in the"
    },
    {
      "start": 1124.88,
      "duration": 4.32,
      "text": "'9s, played against IBM's Deep Blue,"
    },
    {
      "start": 1127.76,
      "duration": 2.88,
      "text": "which wasn't really artificial"
    },
    {
      "start": 1129.2,
      "duration": 4.32,
      "text": "intelligence. It was more of a brute"
    },
    {
      "start": 1130.64,
      "duration": 5.6,
      "text": "force and huristics approach and beat"
    },
    {
      "start": 1133.52,
      "duration": 4.32,
      "text": "Gary Kasparov. And so what Elon Musk is"
    },
    {
      "start": 1136.24,
      "duration": 3.679,
      "text": "saying is, okay, let's have a coding"
    },
    {
      "start": 1137.84,
      "duration": 6,
      "text": "challenge where Andre Karpathy versus"
    },
    {
      "start": 1139.919,
      "duration": 5.921,
      "text": "Gro 5 is the battle. And Andre replies,"
    },
    {
      "start": 1143.84,
      "duration": 4.64,
      "text": "I'd much rather use and collaborate with"
    },
    {
      "start": 1145.84,
      "duration": 4.8,
      "text": "Gro 5 than compete against it. Though"
    },
    {
      "start": 1148.48,
      "duration": 4.319,
      "text": "quite similar to chess and in the limit,"
    },
    {
      "start": 1150.64,
      "duration": 4.08,
      "text": "speaking of physics, my value ad"
    },
    {
      "start": 1152.799,
      "duration": 3.201,
      "text": "probably trends to zero. What he's"
    },
    {
      "start": 1154.72,
      "duration": 3.6,
      "text": "saying is first, he doesn't want to do"
    },
    {
      "start": 1156,
      "duration": 4.16,
      "text": "that competition because he's not into"
    },
    {
      "start": 1158.32,
      "duration": 4.4,
      "text": "the hype and that seems to be like a"
    },
    {
      "start": 1160.16,
      "duration": 5.6,
      "text": "pure hype play. and his value ad trends"
    },
    {
      "start": 1162.72,
      "duration": 5.199,
      "text": "to zero, meaning yes, Grock 5 is going"
    },
    {
      "start": 1165.76,
      "duration": 4.72,
      "text": "to be better at a coding challenge than"
    },
    {
      "start": 1167.919,
      "duration": 4.961,
      "text": "me over enough time. So, I found this to"
    },
    {
      "start": 1170.48,
      "duration": 4.48,
      "text": "be fascinating. I'll link the post down"
    },
    {
      "start": 1172.88,
      "duration": 5.52,
      "text": "below. If you enjoyed this video, please"
    },
    {
      "start": 1174.96,
      "duration": 3.44,
      "text": "consider giving a like and subscribe."
    }
  ],
  "fullText": "Andre Karpathy, one of the most important figures in artificial intelligence, says we're 10 years away from AGI. He was just on Dwaresh's podcast, and it was really an incredible discussion between the two. But I actually found his follow-up post on X to be just as interesting. And that's what we're going to go over today. He clarifies many of the points he made on the Darkh podcast and even goes a little bit further. Let's get into it. And quickly, let me just tell you about our new 100 ways to use AI guide. This is absolutely free, created by my team. All you need to do is subscribe to our newsletter. I'll drop the link down below. Download it right now. Check it out. All right. So, first he talks about AGI timelines. And yes, he did say AGI is 10 plus years away. The first thing he clarifies is this is the decade of agents. And this is really in response to OpenAI and others saying this is the year of agents. And it's kind of an interesting point to make because what does it even mean the year of agents, the decade of agents? When I say the year of agents, I just mean it's going to become at the forefront of people's thoughts and implementations. I think when he says the decade of agents, that's how long it's going to take to actually get agents that are usable, valuable, and proliferating through the entire economy. So he links a tweet that he posted from earlier this year. Let me show it to you. Projects like OpenAI's operator are to the digital world as humanoid robots are to the physical world. Now if you don't remember what OpenAI's operator is, it hasn't really been all that popular, I don't believe, but it's basically Chad GPT that can take control of the browser and actually browse the web on your behalf. This was a really special project. We've seen a number of other projects very similar to it, but what makes it so special is the fact that it is generalized. You just need to give it a web browser and a prompt or a task and it's going to go out and actually accomplish things on your behalf without having any specialized knowledge of what you're asking it to do. So one general setting monitor keyboard and mouse or human body that can in principle gradually perform arbitrarily general tasks via an IO interface originally designed for humans. In both cases, it leads to a gradually mixed autonomy world where humans become highlevel supervisors of low-level automation. This will happen faster in the digital world than in the physical world because flipping bits is somewhere around a thousand times less expensive than moving atoms. That just means that an AI can manipulate the internet much more easily than it can manipulate the real physical world. But here's the interesting part though. The market size and opportunity feels a lot bigger in physical world. Now what do you think about that? Do you think that knowledge work is a bigger market opportunity than physical work? I think potentially if we expand beyond Earth then really it's infinite in the physical world. But right now, it just seems like knowledge work is the bigger opportunity. But here's why he says it's the decade of agents and not the year of agents. People on my timeline are saying 2025 is the year of agents. Personally, I think 2025 to 2035 is the decade of agents. I feel a huge amount of work across the board to make it actually work, but it should work. And what he's talking about is scaffolding. Now, back to this recent post. Basically, my AI timelines are about five to 10 times pessimistic with regards to what you'll find in your neighborhood SFAI house party or on your Twitter timeline. Basically, everything that I'm exposed to and likely you're exposed to as well. I'm extremely optimistic. I don't think it's one year. I also don't think it's 10 years, but still quite optimistic with regards to a rising tide of AI deniers and skeptics. So he really finds himself believing we're somewhere in the middle of the most pessimistic and the most optimistic. So here's the conflict as he lays it out. One, we saw a huge amount of progress in recent years with LLMs. This is true. Look at the end of 2022 when Chat GBT first came out till now. Look how much progress we've seen. But at the same time, there is still a lot of work remaining. grunt work, integration work, sensors and actuators to the physical world, societal work, safety and security work, jailbreaks, poisoning, etc. And also research to get done before we have an entity that you'd prefer to hire over a person for an arbitrary job in the world. And he's right. And all of the things he mentioned, or at least some of them, are going to be accomplished by continued rollout of scaffolding. This is what a lot of people refer to as model overhang. The capabilities, the intelligence in the core models are really good, but the actual tooling and the memory and the infrastructure buildout to actually power and gain value from the core intelligence of these models is still way behind the actual capabilities of the models. Now, Andre Karpathy also says that the core capabilities of the models are not quite there yet, but I'm much more optimistic than he is. I think that overall 10 years should otherwise be a very bullish timeline for AGI. It's only in contrast to present hype that it doesn't feel that way. Next, animals versus ghosts. And I'm going to get to that in one second. But first, let me just tell you about the sponsor of today's video, Dell Technologies. And a special thank you to Dell Technologies for sponsoring this portion of the video. Dell's ProMax family of PCs are incredibly powerful for AI workloads. using the new Grace Blackwell series of Nvidia GPUs, including GB300 and GB10. These are absolute monster GPUs in your desktop. Learn more about DellPro Max GB10 and GB300 and the Dell Pro Max lineup of workstations with Nvidia RTX Pro GPUs. Click the link in the description below. Let them know I sent you. Check it out. gist of his point here is that the way LLMs learn feels much more akin to a ghost than how animals learn. And he's going to explain what that actually means. Let me break it down. I am suspicious that there is a single simple algorithm you can let loose on the world and it learns everything from scratch. Super interesting point. A single simple algorithm that can learn everything from scratch. He doesn't believe that's possible. If someone builds such a thing, I will be wrong and it will be the most incredible breakthrough in AI. In my mind, animals are not an example of this at all. They are prepackaged with a ton of intelligence by evolution, and the learning they do is quite minimal overall. Basically, animals, including humans, are born with all of this prepackaged knowledge of how to do things through generations and generations of evolution. And the example he gives, zebras at birth. And let me show you why he gives this example. Okay, so this is a zebra just after birth. And not only does it know all the basics like breathing and sight, but it can start walking immediately and it knows how. And that is not a simple feat. So watch this again right after birth. Here we go. And kind of wobbly, but kind of gets the gist of what it needs to do immediately. Stands up. And there it goes. And so there we go. It's starting to walk already. Look at that. Zebras at birth. That is generation after generation of evolution prepackaged into this baby animal. But he says we're not able to replicate evolution simply with algorithms alone. He says LLMs are a different approach to learning. It's not evolution. But with LLMs, we have stumbled by an alternative approach to prepackage a ton of intelligence in a neural network. Not by evolution, but by predicting the next token over the internet. But that type of learning is different from evolution. Here's what he says. Distinct from animals, more like ghosts or spirits. We can and should make them more animallike over time. And in some ways, that's what a lot of frontier work is all about. And he specifically talks about memorization in particular. When we think about LLMs, they are memorizing things. They aren't as much generalizing, at least not yet. we see some generalization, especially on benchmarks like the ARK prize. That's really a test of generalization. And generalization is really the key to a GI, artificial general intelligence. It's not enough just to memorize. That's good, but being able to learn new things on the fly rather than having it explicitly taught to you is really the key. And then he kind of doubles down and talks about reinforcement learning. So, I've critiqued RL a few times already. First, you're sucking supervision through a straw. So, I think the signal per flop is very bad, which basically means how much actual learning you get per how much compute you use to get there is really bad at this point. But I think it's only going to get better. I mean, obviously, it's only going to get better. But is that ratio going to improve enough to really hit generalization? RL is very noisy because a completion might have lots of errors that might get encouraged if you happen to stumble to the right answer and conversely brilliant insight tokens that might get discouraged if you happen to screw up later. This is the problem with outcomebased rewards. So let me just break down what that means for you. With outcomebased rewards in reinforcement learning, you are telling the model, you are telling the weights, you're updating the weights whenever something goes right. And so if you think about how chain of thought works, there are a bunch of intermediate thoughts that happen before the final answer. So let's give a really simple example. 1 plus 1 equals 2. And let's say the model has to think a ton about it. And it thinks in all the wrong ways. And it says, \"Okay, well 1 minus 1 is 0 and that must mean 10 + 50 is 60.\" And it's having all of these irrelevant thoughts. Or really, it could just be fundamentally wrong. So it could say 3 + 3 is 50. And then at the final answer when it says 1 + 1 equals 2, the entire thought process gets rewarded. And so it's actually thinking, oh look, everything I thought along the way and the final answer is actually correct. Now that's where process rewards come into play. But even those have problems as he's saying. So let's say your model takes five steps to figure something out and at the and then when it reaches the final answer, the final answer is wrong. But each of the five steps is right. That final signal is going to tell it, hey, you got those steps right, but the overall answer was wrong. And so it's actually going to get penalized even though those intermediate steps were really good. Process supervision and LLM judges have issues, too. I think we'll see alternative learning paradigms. I am long agentic interaction but short reinforcement learning which is crazy because seemingly every frontier lab is so bullish on reinforcement learning but he says agentic interactions is the way. What I think he's saying with agentic interactions is essentially creating a playground for agents to experiment and learn as they go. This is the way that the deep mind team who Andre Karpathy was an intern at was able to create AI that is the best in the world at the game go. And there are companies building world models which are really just playgrounds for agents either embodied agents or digital agents to play around in and figure out things as they go. He continues, \"I've seen a number of papers pop up recently that are, in my opinion, barking up the right tree along the lines of what I called system prompt learning.\" So, he references a post that he made a few months ago where he defined system prompt learning. And by the way, let's pause for a second and appreciate how good Andre Karpathy is at naming things. He was the first to name hallucinations. He was the first to name vibe coding. So, he's all over the naming. And now we have system prompt learning. Let me explain what that is. So pre-training is for knowledge. Fine-tuning is for habitual behavior. Both of these involve change in parameters. But a lot of human learning feels more like a change in system prompt. And remember the system prompt is the message that you append to every prompt and it's given to the model and it basically affects what the model's behavior is. It's really core to how the model's personality actually manifests. One example of that is when XAI changes their system prompt, all of a sudden it starts talking about Elon Musk in every single post. The process is you encounter a problem, figure something out, then remember something in fairly explicit terms for the next time. For example, it seems when I encounter this and that kind of problem, I should try this and that kind of approach solution. It feels more like taking notes for yourself. And he's saying the system prompt could be the best place to take those notes. But the system prompt is very limited. We have a context window and that context window is finite. So you can only put so much in there. You need to put the system prompt and you need to put the actual prompt from the user. It feels more like taking notes for yourself. Something like the memory feature. So that's the memory feature of chat GPT which kind of has a log of everything it thinks it needs to remember about the user but not store per user random facts but general global problem solving knowledge and strategies. He actually looked at Claude's system message, which is 17,000 words, and not only specifies basic behavior, style, and preferences, but also has a large amount of general problem solving. Here's an example. If Claude is asked to count words, letters, and characters, it thinks step by step before answering the person. It explicitly counts the words, letters, or characters by assigning a number to each. It only answers the person once it has performed this explicit counting step. This is explicitly to help Claude solve the how many Rs are in the word strawberry test. And he says there have been a lot of papers that are really promising, but those papers and what is actually out in the world at production scale is lacking to say the least. And he references chai chipt memory once more but it is the primordial deployed example of a new learning paradigm which basically means it is just the most basic version of what he's talking about. He also talks about the cognitive core. So he really is railing against memorization which is what happens when you scale these models up tremendously. So, cognitive core, the idea of stripping down LLMs of making it harder for them to memorize or actively stripping away their memory to make them better at generalization. Otherwise, they lean too hard on what they've memorized. And of course, let's make the comparison to humans. So, humans can't memorize so easily, which now looks more like a feature than a bug by contrast. Because if we memorize everything, then of course we're always going to use our memory as our crutch, as our go-to for any future learning. Maybe the inability to memorize is kind of like regularization. And so, let me actually go a little bit deeper into his cognitive core post. This was a post from just a few months ago. With the cognitive core, he means a few billion parameter model that maximally sacrifices encyclopedic knowledge for capability. And we started to see a couple things like that. In fact, remember just a couple weeks ago, we had that incredible paper that showed, I believe it was like a 7 million parameter model that was quite capable of solving puzzles. It lives always on and by default on every computer as the kernel of LLM personal computing. Its features are slowly crystallizing. One natively multimodal text vision audio at both input and output. Matrioska style architecture allowing a dial of capability up and down at test time reasoning also with a dial system 2 aggressively tool using ondevice fine-tuning Laura slots for test time training personalization and customization and delegates and doublech checkcks just the right parts with the oracles in the cloud if internet is available and this was in reply to Gemma 3N coming out that's the open-source very small highly capable model from Google. Then he finishes on this point with the trend in model sizes backwards and why models have to first get larger before they can get smaller. The next point I want to touch on is LLM agents and what he thinks about that. So he did have some pretty strong critiques of the agent industry in its current form. Specifically, my critique of the industry is more in overshooting the tooling with respect to present capability. And he goes on to explain his current view of agents is he wants to collaborate with LLMs with agents where his shortcomings and and their strong suits are paired up really well. But he doesn't think agents are quite ready to just be assigned a task and go off for 20 30 minutes at a time. And in fact, he specifically said his newest project, Nano Chat, was built almost entirely by hand. Manual coding, no vibe coding. The industry lives in a future where fully autonomous entities collaborate in parallel to write all the code and humans are useless. For example, I don't want an agent that goes off for 20 minutes and comes back with a thousand lines of code. I certainly don't feel ready to supervise a team of 10 of them. I'd like to go in chunks that I can keep in my head where an LLM explains the code that it is writing. I'd like it to prove to me that what it did is correct. I want it to pull the API docs and show me that it used things correctly. Fewer assumptions and asked to collaborate when it's not sure about something. And he specifically says if agents do just go out and write a thousand or a few thousand lines of code and then come back and I don't really review every single line by line with high precision and understanding of the context. We're going to have what he calls mountains of slop. And I want to finish with one fun little tidbit. Elon Musk replied to this post and said, \"You make a lot of great points, especially that children should learn the tools of physics early. Are you down for an AI coding contest or whatever form of competition you'd like for Andre vers Grock 5, Allah Kasparov verse Deep Blue? And if you don't remember, Gary Kasparov, one of the best chess players of all time. I believe it was in the '9s, played against IBM's Deep Blue, which wasn't really artificial intelligence. It was more of a brute force and huristics approach and beat Gary Kasparov. And so what Elon Musk is saying is, okay, let's have a coding challenge where Andre Karpathy versus Gro 5 is the battle. And Andre replies, I'd much rather use and collaborate with Gro 5 than compete against it. Though quite similar to chess and in the limit, speaking of physics, my value ad probably trends to zero. What he's saying is first, he doesn't want to do that competition because he's not into the hype and that seems to be like a pure hype play. and his value ad trends to zero, meaning yes, Grock 5 is going to be better at a coding challenge than me over enough time. So, I found this to be fascinating. I'll link the post down below. If you enjoyed this video, please consider giving a like and subscribe.",
  "fetchedAt": "2026-01-18T18:32:18.984Z"
}