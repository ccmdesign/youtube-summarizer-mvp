{
  "videoId": "DtePicx_kFY",
  "language": "en",
  "source": "caption-extractor",
  "segments": [
    {
      "start": 0.08,
      "duration": 6.08,
      "text": "despite the fact that I was involved in"
    },
    {
      "start": 2.56,
      "duration": 5.12,
      "text": "inventing the Transformer luckily um no"
    },
    {
      "start": 6.16,
      "duration": 3.2,
      "text": "one's been working on them as long as I"
    },
    {
      "start": 7.68,
      "duration": 4.4,
      "text": "have rights with maybe the exception of"
    },
    {
      "start": 9.36,
      "duration": 5.199,
      "text": "the other se seven authors. So I"
    },
    {
      "start": 12.08,
      "duration": 4.8,
      "text": "actually made the decision uh earlier"
    },
    {
      "start": 14.559,
      "duration": 4.161,
      "text": "this year that I'm going to drastically"
    },
    {
      "start": 16.88,
      "duration": 4.399,
      "text": "reduce the amounts of of research that"
    },
    {
      "start": 18.72,
      "duration": 5.04,
      "text": "I'm doing specifically on the"
    },
    {
      "start": 21.279,
      "duration": 6.32,
      "text": "transformer because of the feeling that"
    },
    {
      "start": 23.76,
      "duration": 5.679,
      "text": "I have that it's it's an oversaturated"
    },
    {
      "start": 27.599,
      "duration": 3.52,
      "text": "space, right? It's not that there's no"
    },
    {
      "start": 29.439,
      "duration": 4.401,
      "text": "more interesting things to be done with"
    },
    {
      "start": 31.119,
      "duration": 5.6,
      "text": "them. And I'm going to make use of the"
    },
    {
      "start": 33.84,
      "duration": 5.92,
      "text": "opportunity to do something different,"
    },
    {
      "start": 36.719,
      "duration": 5.121,
      "text": "right? To actually turn up the amount of"
    },
    {
      "start": 39.76,
      "duration": 3.6,
      "text": "exploration that I'm doing in my"
    },
    {
      "start": 41.84,
      "duration": 4,
      "text": "research."
    },
    {
      "start": 43.36,
      "duration": 4.8,
      "text": "We just released the continuous thought"
    },
    {
      "start": 45.84,
      "duration": 5.039,
      "text": "machine. It's a spotlight at Europe's"
    },
    {
      "start": 48.16,
      "duration": 5.36,
      "text": "2025 this year. You should care about it"
    },
    {
      "start": 50.879,
      "duration": 5.121,
      "text": "because it has native adaptive compute."
    },
    {
      "start": 53.52,
      "duration": 4.719,
      "text": "It's a new way of building a recurrent"
    },
    {
      "start": 56,
      "duration": 4.32,
      "text": "model that uses [music] higher level"
    },
    {
      "start": 58.239,
      "duration": 4.64,
      "text": "concepts for neurons and a"
    },
    {
      "start": 60.32,
      "duration": 5.04,
      "text": "synchronization as a representation that"
    },
    {
      "start": 62.879,
      "duration": 4.721,
      "text": "lets us solve problems in ways that seem"
    },
    {
      "start": 65.36,
      "duration": 4.96,
      "text": "more human by being biologically and"
    },
    {
      "start": 67.6,
      "duration": 5.76,
      "text": "nature inspired."
    },
    {
      "start": 70.32,
      "duration": 4.96,
      "text": "The atmosphere in AI research was"
    },
    {
      "start": 73.36,
      "duration": 5.52,
      "text": "actually quite different back during the"
    },
    {
      "start": 75.28,
      "duration": 4.96,
      "text": "Transformer uh years um because it"
    },
    {
      "start": 78.88,
      "duration": 4.239,
      "text": "doesn't feel like something [music]"
    },
    {
      "start": 80.24,
      "duration": 5.199,
      "text": "similar could actually happen right now."
    },
    {
      "start": 83.119,
      "duration": 4.401,
      "text": "because of the reduced amount of freedom"
    },
    {
      "start": 85.439,
      "duration": 6.081,
      "text": "that we have, right? [music] The"
    },
    {
      "start": 87.52,
      "duration": 5.76,
      "text": "Transformers was very very bottom up,"
    },
    {
      "start": 91.52,
      "duration": 3.919,
      "text": "right? It's not that somebody had this"
    },
    {
      "start": 93.28,
      "duration": 3.76,
      "text": "grand plan that came down from on high"
    },
    {
      "start": 95.439,
      "duration": 4.64,
      "text": "that this is what we should be working"
    },
    {
      "start": 97.04,
      "duration": 4.8,
      "text": "on. It was a bunch of people talking"
    },
    {
      "start": 100.079,
      "duration": 3.841,
      "text": "over lunch, thinking about [music] what"
    },
    {
      "start": 101.84,
      "duration": 5.279,
      "text": "the current problems are and how to"
    },
    {
      "start": 103.92,
      "duration": 5.519,
      "text": "solve them and having the freedom to"
    },
    {
      "start": 107.119,
      "duration": 3.68,
      "text": "have, you know, literally months to"
    },
    {
      "start": 109.439,
      "duration": 4.081,
      "text": "dedicate to just trying this [music]"
    },
    {
      "start": 110.799,
      "duration": 6.161,
      "text": "idea and having this this new"
    },
    {
      "start": 113.52,
      "duration": 5.599,
      "text": "architecture fall out. [music]"
    },
    {
      "start": 116.96,
      "duration": 5.199,
      "text": "We've spent hundreds of millions of"
    },
    {
      "start": 119.119,
      "duration": 5.201,
      "text": "dollars. The biggest sort of evolution"
    },
    {
      "start": 122.159,
      "duration": 5.041,
      "text": "based search is probably in the tens of"
    },
    {
      "start": 124.32,
      "duration": 5.12,
      "text": "thousands. We have all this compute."
    },
    {
      "start": 127.2,
      "duration": 4.72,
      "text": "What happens? What happens if you scale"
    },
    {
      "start": 129.44,
      "duration": 4.32,
      "text": "up these search algorithms? And I'm sure"
    },
    {
      "start": 131.92,
      "duration": 3.84,
      "text": "you'll find something interesting, you"
    },
    {
      "start": 133.76,
      "duration": 4,
      "text": "know, when someone eventually does bite"
    },
    {
      "start": 135.76,
      "duration": 4.08,
      "text": "that bullet and really scale [music] up"
    },
    {
      "start": 137.76,
      "duration": 4.8,
      "text": "these evolutionary sort of a life"
    },
    {
      "start": 139.84,
      "duration": 4.88,
      "text": "experiments because I pitched it in an"
    },
    {
      "start": 142.56,
      "duration": 5.6,
      "text": "environment where people were just going"
    },
    {
      "start": 144.72,
      "duration": 5.519,
      "text": "all in on this one technology. I got"
    },
    {
      "start": 148.16,
      "duration": 5.84,
      "text": "zero interest."
    },
    {
      "start": 150.239,
      "duration": 5.841,
      "text": "So now I have my own company and I can"
    },
    {
      "start": 154,
      "duration": 5.84,
      "text": "pursue those directions."
    },
    {
      "start": 156.08,
      "duration": 6,
      "text": "This podcast is supported by Cyber Fund."
    },
    {
      "start": 159.84,
      "duration": 4.24,
      "text": ">> Hey folks, I'm Omar, product and design"
    },
    {
      "start": 162.08,
      "duration": 3.68,
      "text": "lead at Google DeepMind. We just"
    },
    {
      "start": 164.08,
      "duration": 3.84,
      "text": "launched a revamped vibe coding"
    },
    {
      "start": 165.76,
      "duration": 4.16,
      "text": "experience in AI Studio that lets you"
    },
    {
      "start": 167.92,
      "duration": 4.56,
      "text": "mix and match AI capabilities [music] to"
    },
    {
      "start": 169.92,
      "duration": 4.88,
      "text": "turn your ideas into reality faster than"
    },
    {
      "start": 172.48,
      "duration": 4,
      "text": "ever. Just describe your app and Gemini"
    },
    {
      "start": 174.8,
      "duration": 4.159,
      "text": "will automatically wire up the right"
    },
    {
      "start": 176.48,
      "duration": 4.56,
      "text": "models and APIs for you. And if you need"
    },
    {
      "start": 178.959,
      "duration": 4,
      "text": "a spark, hit I'm feeling lucky and we'll"
    },
    {
      "start": 181.04,
      "duration": 4.24,
      "text": "help you get started. Head to"
    },
    {
      "start": 182.959,
      "duration": 3.521,
      "text": "a.studio/build studio/build to create"
    },
    {
      "start": 185.28,
      "duration": 2.959,
      "text": "your first app."
    },
    {
      "start": 186.48,
      "duration": 4.479,
      "text": ">> Two for AI Labs is a research [music]"
    },
    {
      "start": 188.239,
      "duration": 5.441,
      "text": "lab based in Zurich. They've got a team"
    },
    {
      "start": 190.959,
      "duration": 4.161,
      "text": "of amazing ML engineers and research"
    },
    {
      "start": 193.68,
      "duration": 2.479,
      "text": "scientists. They're doing some really"
    },
    {
      "start": 195.12,
      "duration": 2.72,
      "text": "cool stuff. If you look at their"
    },
    {
      "start": 196.159,
      "duration": 3.36,
      "text": "website, [music] for example, you can"
    },
    {
      "start": 197.84,
      "duration": 4.88,
      "text": "see what their approach was for winning"
    },
    {
      "start": 199.519,
      "duration": 5.498,
      "text": "the ARC AGI 3 pub uh competition which"
    },
    {
      "start": 202.72,
      "duration": 4.799,
      "text": "closed out a few months ago and they are"
    },
    {
      "start": 205.017,
      "duration": 4.023,
      "text": "[music] hiring amazing ML engineers and"
    },
    {
      "start": 207.519,
      "duration": 4.241,
      "text": "research scientists. They also care"
    },
    {
      "start": 209.04,
      "duration": 4.4,
      "text": "deeply about AI safety. So if any of"
    },
    {
      "start": 211.76,
      "duration": 5.199,
      "text": "that is a fit for you, please go to Two"
    },
    {
      "start": 213.44,
      "duration": 5.12,
      "text": "for [music] AOLABS and uh give it a go."
    },
    {
      "start": 216.959,
      "duration": 3.521,
      "text": "The audience will know I'm a huge fan of"
    },
    {
      "start": 218.56,
      "duration": 3.599,
      "text": "Kenneth Stanley's ideas. So his book,"
    },
    {
      "start": 220.48,
      "duration": 4.24,
      "text": "Why Greatness Cannot Be Planned, changed"
    },
    {
      "start": 222.159,
      "duration": 5.201,
      "text": "my life. It was absolutely insane. And"
    },
    {
      "start": 224.72,
      "duration": 4.48,
      "text": "what he was speaking to is that we need"
    },
    {
      "start": 227.36,
      "duration": 4.72,
      "text": "to allow people to follow their own"
    },
    {
      "start": 229.2,
      "duration": 5.759,
      "text": "gradient of interest unfettered by"
    },
    {
      "start": 232.08,
      "duration": 5.04,
      "text": "objectives and committees and and so on."
    },
    {
      "start": 234.959,
      "duration": 4.241,
      "text": "Because that is how we do epistemic"
    },
    {
      "start": 237.12,
      "duration": 4.72,
      "text": "foraging. that when you have too many"
    },
    {
      "start": 239.2,
      "duration": 4.959,
      "text": "agendas involved in the mix, you kind of"
    },
    {
      "start": 241.84,
      "duration": 4.56,
      "text": "end up with a gray goo and you don't"
    },
    {
      "start": 244.159,
      "duration": 4.241,
      "text": "discover, you know, interesting novelty"
    },
    {
      "start": 246.4,
      "duration": 3.919,
      "text": "and diversity. And I suppose that's"
    },
    {
      "start": 248.4,
      "duration": 5.199,
      "text": "basically the thesis of of your company,"
    },
    {
      "start": 250.319,
      "duration": 6.401,
      "text": "Sakana, is to lean into those ideas."
    },
    {
      "start": 253.599,
      "duration": 5.841,
      "text": ">> Yes, exactly. Um, at the company, we're"
    },
    {
      "start": 256.72,
      "duration": 4.32,
      "text": "a massive fan of that book. We're we're"
    },
    {
      "start": 259.44,
      "duration": 4.72,
      "text": "hoping to have him come and talk at our"
    },
    {
      "start": 261.04,
      "duration": 6,
      "text": "company next week, actually. And um it's"
    },
    {
      "start": 264.16,
      "duration": 4.64,
      "text": "a philosophy that we we do talk about"
    },
    {
      "start": 267.04,
      "duration": 3.84,
      "text": "internally, right? We have copies of the"
    },
    {
      "start": 268.8,
      "duration": 4.8,
      "text": "books in including the the recent"
    },
    {
      "start": 270.88,
      "duration": 5.28,
      "text": "Japanese translation. As you know, one"
    },
    {
      "start": 273.6,
      "duration": 4.159,
      "text": "of the co-founders, one of my my main"
    },
    {
      "start": 276.16,
      "duration": 4.16,
      "text": "jobs, one of the main things that I have"
    },
    {
      "start": 277.759,
      "duration": 4.88,
      "text": "to keep doing for this company is making"
    },
    {
      "start": 280.32,
      "duration": 5.28,
      "text": "sure that we protect the freedom that"
    },
    {
      "start": 282.639,
      "duration": 4.641,
      "text": "the researchers currently have, right?"
    },
    {
      "start": 285.6,
      "duration": 3.36,
      "text": "Because it's it's it's a it's a"
    },
    {
      "start": 287.28,
      "duration": 3.199,
      "text": "privilege really that we have the"
    },
    {
      "start": 288.96,
      "duration": 4.32,
      "text": "resources to be able to do that. And"
    },
    {
      "start": 290.479,
      "duration": 5.121,
      "text": "inevitably, as I've seen happen, as the"
    },
    {
      "start": 293.28,
      "duration": 6,
      "text": "company grows, more and more pressure"
    },
    {
      "start": 295.6,
      "duration": 6.08,
      "text": "comes in and it narrows the freedom. But"
    },
    {
      "start": 299.28,
      "duration": 5.84,
      "text": "I think because, you know, we we believe"
    },
    {
      "start": 301.68,
      "duration": 5.76,
      "text": "in this philosophy so strongly, I'm"
    },
    {
      "start": 305.12,
      "duration": 5.6,
      "text": "hoping that we can give people all the"
    },
    {
      "start": 307.44,
      "duration": 4.88,
      "text": "research freedom that we do now um for"
    },
    {
      "start": 310.72,
      "duration": 3.52,
      "text": "as long as possible."
    },
    {
      "start": 312.32,
      "duration": 4.64,
      "text": ">> And what are those processes that"
    },
    {
      "start": 314.24,
      "duration": 4.32,
      "text": "curtail freedom as a company matures? I"
    },
    {
      "start": 316.96,
      "duration": 4.48,
      "text": "mean, how would you describe that? It's"
    },
    {
      "start": 318.56,
      "duration": 5.04,
      "text": "great that there's never been so much"
    },
    {
      "start": 321.44,
      "duration": 5.68,
      "text": "interest and people and talent and"
    },
    {
      "start": 323.6,
      "duration": 5.68,
      "text": "resources and money in the industry,"
    },
    {
      "start": 327.12,
      "duration": 4.24,
      "text": "but unfortunately that just increases"
    },
    {
      "start": 329.28,
      "duration": 4.72,
      "text": "the amount of pressure people have in"
    },
    {
      "start": 331.36,
      "duration": 5.6,
      "text": "order to compete with all the other"
    },
    {
      "start": 334,
      "duration": 5.6,
      "text": "people working on it and trying to get"
    },
    {
      "start": 336.96,
      "duration": 4.64,
      "text": "the the value out of this technology and"
    },
    {
      "start": 339.6,
      "duration": 3.84,
      "text": "making money."
    },
    {
      "start": 341.6,
      "duration": 4.56,
      "text": "And I think that's what just happens,"
    },
    {
      "start": 343.44,
      "duration": 4.8,
      "text": "right? As a startup, you have a a"
    },
    {
      "start": 346.16,
      "duration": 5.039,
      "text": "feeling of, you know, excitement and"
    },
    {
      "start": 348.24,
      "duration": 4.32,
      "text": "trying something new. And right at the"
    },
    {
      "start": 351.199,
      "duration": 2.481,
      "text": "beginning, you have a bit of a runway."
    },
    {
      "start": 352.56,
      "duration": 3.359,
      "text": "So, you have the freedom to try"
    },
    {
      "start": 353.68,
      "duration": 4.72,
      "text": "different things. But inevitably, people"
    },
    {
      "start": 355.919,
      "duration": 5.441,
      "text": "are starting to ask for returns on their"
    },
    {
      "start": 358.4,
      "duration": 6.639,
      "text": "investments or they're expecting you to"
    },
    {
      "start": 361.36,
      "duration": 5.52,
      "text": "churn out some product. And this just"
    },
    {
      "start": 365.039,
      "duration": 4.401,
      "text": "unfortunately"
    },
    {
      "start": 366.88,
      "duration": 5.92,
      "text": "reduces the uh the the creativity that"
    },
    {
      "start": 369.44,
      "duration": 6.8,
      "text": "that researchers have because you know"
    },
    {
      "start": 372.8,
      "duration": 5.119,
      "text": "the the the the pressures to publish or"
    },
    {
      "start": 376.24,
      "duration": 3.92,
      "text": "the pressure to to create technology"
    },
    {
      "start": 377.919,
      "duration": 7.201,
      "text": "that's actually useful for the products"
    },
    {
      "start": 380.16,
      "duration": 7.599,
      "text": "that we have goes up and so the feeling"
    },
    {
      "start": 385.12,
      "duration": 4.799,
      "text": "of autonomy I think starts to go down."
    },
    {
      "start": 387.759,
      "duration": 4.321,
      "text": "But you know I literally tell people"
    },
    {
      "start": 389.919,
      "duration": 4.4,
      "text": "when they start working for the company"
    },
    {
      "start": 392.08,
      "duration": 5.2,
      "text": "I want you to work on what you think is"
    },
    {
      "start": 394.319,
      "duration": 4.72,
      "text": "interesting and important and I mean it"
    },
    {
      "start": 397.28,
      "duration": 4.4,
      "text": "there there is I mean in YouTube there's"
    },
    {
      "start": 399.039,
      "duration": 3.121,
      "text": "a phenomenon called audience capture"
    },
    {
      "start": 401.68,
      "duration": 2.88,
      "text": ">> right"
    },
    {
      "start": 402.16,
      "duration": 4.4,
      "text": ">> and I think there might be a phenomenon"
    },
    {
      "start": 404.56,
      "duration": 4.24,
      "text": "called technology capture which is that"
    },
    {
      "start": 406.56,
      "duration": 5.28,
      "text": "in the early days of Google it was quite"
    },
    {
      "start": 408.8,
      "duration": 5.6,
      "text": "open-ended and I mean transformers is"
    },
    {
      "start": 411.84,
      "duration": 4,
      "text": "now the ubiquitous backbone of all AI"
    },
    {
      "start": 414.4,
      "duration": 4.4,
      "text": "technology and it's a huge achievement"
    },
    {
      "start": 415.84,
      "duration": 4.4,
      "text": "that that you're involved in But I mean"
    },
    {
      "start": 418.8,
      "duration": 3.28,
      "text": "there's a similar story with with Open"
    },
    {
      "start": 420.24,
      "duration": 3.679,
      "text": "AI. They're now starting to see all of"
    },
    {
      "start": 422.08,
      "duration": 3.44,
      "text": "these commercialization opportunities."
    },
    {
      "start": 423.919,
      "duration": 3.201,
      "text": "They they can I mean they're going to"
    },
    {
      "start": 425.52,
      "duration": 3.04,
      "text": "become LinkedIn. They're going to become"
    },
    {
      "start": 427.12,
      "duration": 2.72,
      "text": "an application platform. They're going"
    },
    {
      "start": 428.56,
      "duration": 3.12,
      "text": "to become a search platform. They're"
    },
    {
      "start": 429.84,
      "duration": 3.68,
      "text": "going to become a social network. And"
    },
    {
      "start": 431.68,
      "duration": 4.639,
      "text": "and I guess this could happen to you"
    },
    {
      "start": 433.52,
      "duration": 4.16,
      "text": "guys that there's a very strong chance,"
    },
    {
      "start": 436.319,
      "duration": 2.561,
      "text": "especially with your new paper that"
    },
    {
      "start": 437.68,
      "duration": 3.2,
      "text": "we're going to talk about today, this"
    },
    {
      "start": 438.88,
      "duration": 4.159,
      "text": "continuous thought machines. It it could"
    },
    {
      "start": 440.88,
      "duration": 4.24,
      "text": "be a revolutionary technology, but then"
    },
    {
      "start": 443.039,
      "duration": 3.681,
      "text": "it will become obvious how it could be"
    },
    {
      "start": 445.12,
      "duration": 3.12,
      "text": "commercialized. And that's how those"
    },
    {
      "start": 446.72,
      "duration": 4.56,
      "text": "pressures come in."
    },
    {
      "start": 448.24,
      "duration": 4.64,
      "text": ">> I I like the I like the audience capture"
    },
    {
      "start": 451.28,
      "duration": 4.24,
      "text": "analogy."
    },
    {
      "start": 452.88,
      "duration": 4.96,
      "text": "I think um there's definitely been some"
    },
    {
      "start": 455.52,
      "duration": 6.88,
      "text": "kind of capture by large language"
    },
    {
      "start": 457.84,
      "duration": 7.52,
      "text": "models, right? They they worked so well"
    },
    {
      "start": 462.4,
      "duration": 6.16,
      "text": "that everyone wanted to work on them."
    },
    {
      "start": 465.36,
      "duration": 6.559,
      "text": "And I'm really worried that we're kind"
    },
    {
      "start": 468.56,
      "duration": 6.56,
      "text": "of stuck in this local minimum now,"
    },
    {
      "start": 471.919,
      "duration": 5.28,
      "text": "right? and we sort of need to try to try"
    },
    {
      "start": 475.12,
      "duration": 3.68,
      "text": "to escape it. So, we spoke about the"
    },
    {
      "start": 477.199,
      "duration": 3.84,
      "text": "transformers, but there's a there's a"
    },
    {
      "start": 478.8,
      "duration": 3.6,
      "text": "time just before the transformers that"
    },
    {
      "start": 481.039,
      "duration": 4.081,
      "text": "I'd like to talk about because I think"
    },
    {
      "start": 482.4,
      "duration": 4.16,
      "text": "it's quite illustrative. So, of course,"
    },
    {
      "start": 485.12,
      "duration": 2.96,
      "text": "the the main technology before"
    },
    {
      "start": 486.56,
      "duration": 5.12,
      "text": "transformers was recurrent neural"
    },
    {
      "start": 488.08,
      "duration": 4.959,
      "text": "networks, right? And there was a similar"
    },
    {
      "start": 491.68,
      "duration": 3.519,
      "text": "feeling, right? When recurrent neural"
    },
    {
      "start": 493.039,
      "duration": 3.761,
      "text": "networks came in and we we you know, we"
    },
    {
      "start": 495.199,
      "duration": 4.961,
      "text": "discovered this new sort of sequence of"
    },
    {
      "start": 496.8,
      "duration": 5.28,
      "text": "sequence learning, that was also a"
    },
    {
      "start": 500.16,
      "duration": 6.64,
      "text": "massive breakthrough, right? the the the"
    },
    {
      "start": 502.08,
      "duration": 8.799,
      "text": "the the translation quality went up"
    },
    {
      "start": 506.8,
      "duration": 6.799,
      "text": "massively, right? Um voice recognition"
    },
    {
      "start": 510.879,
      "duration": 4.4,
      "text": "uh quality went up massively. And there"
    },
    {
      "start": 513.599,
      "duration": 3.601,
      "text": "was this a similar sort of feeling then"
    },
    {
      "start": 515.279,
      "duration": 4.081,
      "text": "of like okay yes we've you know we found"
    },
    {
      "start": 517.2,
      "duration": 5.839,
      "text": "the technology and we just need to sort"
    },
    {
      "start": 519.36,
      "duration": 8,
      "text": "of perfect this technology and back then"
    },
    {
      "start": 523.039,
      "duration": 6.641,
      "text": "even my my favorite uh task was uh"
    },
    {
      "start": 527.36,
      "duration": 5.36,
      "text": "character level language modeling right"
    },
    {
      "start": 529.68,
      "duration": 5.68,
      "text": "so every time a new RNN based character"
    },
    {
      "start": 532.72,
      "duration": 5.92,
      "text": "level language modeling paper came out I"
    },
    {
      "start": 535.36,
      "duration": 4.56,
      "text": "got quite excited right um I you know"
    },
    {
      "start": 538.64,
      "duration": 2.639,
      "text": "I'd want to like quickly read the paper"
    },
    {
      "start": 539.92,
      "duration": 2.96,
      "text": "like okay how did they you know how did"
    },
    {
      "start": 541.279,
      "duration": 4.641,
      "text": "they get the improvements"
    },
    {
      "start": 542.88,
      "duration": 6.639,
      "text": "But the papers were always these just"
    },
    {
      "start": 545.92,
      "duration": 6.56,
      "text": "these slight modifications on the same"
    },
    {
      "start": 549.519,
      "duration": 6.481,
      "text": "architecture, right? It was LSTMs and"
    },
    {
      "start": 552.48,
      "duration": 5.28,
      "text": "GRUs and maybe um initializing it with"
    },
    {
      "start": 556,
      "duration": 3.68,
      "text": "the identity matrix to so that you could"
    },
    {
      "start": 557.76,
      "duration": 3.6,
      "text": "use the relu function or like maybe if"
    },
    {
      "start": 559.68,
      "duration": 3.839,
      "text": "you put the gate in a different place or"
    },
    {
      "start": 561.36,
      "duration": 4,
      "text": "if you if you layer them in a slightly"
    },
    {
      "start": 563.519,
      "duration": 5.521,
      "text": "different way or if you had gating going"
    },
    {
      "start": 565.36,
      "duration": 6,
      "text": "upwards as well as as sideways. Um, and"
    },
    {
      "start": 569.04,
      "duration": 5.76,
      "text": "I remember one of my favorites was this"
    },
    {
      "start": 571.36,
      "duration": 5.76,
      "text": "uh like hierarchical LSTM where it would"
    },
    {
      "start": 574.8,
      "duration": 4.96,
      "text": "actually decide to compute or not"
    },
    {
      "start": 577.12,
      "duration": 5.36,
      "text": "compute the different layers. And if you"
    },
    {
      "start": 579.76,
      "duration": 4.639,
      "text": "trained on Wikipedia and you looked at"
    },
    {
      "start": 582.48,
      "duration": 3.76,
      "text": "the structure of when it was decided to"
    },
    {
      "start": 584.399,
      "duration": 5.12,
      "text": "compute or not compute, it kind of"
    },
    {
      "start": 586.24,
      "duration": 4.64,
      "text": "looked like the structure of of the the"
    },
    {
      "start": 589.519,
      "duration": 3.601,
      "text": "sentences were actually being picked up"
    },
    {
      "start": 590.88,
      "duration": 5.44,
      "text": "by the model. And I used to love that"
    },
    {
      "start": 593.12,
      "duration": 6.08,
      "text": "sort of stuff, right? Um, but the the"
    },
    {
      "start": 596.32,
      "duration": 5.84,
      "text": "the the improvements were always like"
    },
    {
      "start": 599.2,
      "duration": 5.92,
      "text": "1.26 bits per character, 1.25 bits per"
    },
    {
      "start": 602.16,
      "duration": 4.56,
      "text": "character, 1.24. That was a result that"
    },
    {
      "start": 605.12,
      "duration": 3.279,
      "text": "was publishable, right? That was"
    },
    {
      "start": 606.72,
      "duration": 4.239,
      "text": "exciting."
    },
    {
      "start": 608.399,
      "duration": 4.88,
      "text": "But then after the transformer the team"
    },
    {
      "start": 610.959,
      "duration": 5.761,
      "text": "that I went on to afterwards right we"
    },
    {
      "start": 613.279,
      "duration": 5.68,
      "text": "applied for the first time very deep"
    },
    {
      "start": 616.72,
      "duration": 5.119,
      "text": "transformer models decoder only"
    },
    {
      "start": 618.959,
      "duration": 4.721,
      "text": "transformer models to language modeling"
    },
    {
      "start": 621.839,
      "duration": 4.481,
      "text": "and we immediately got something like"
    },
    {
      "start": 623.68,
      "duration": 4.48,
      "text": "1.1"
    },
    {
      "start": 626.32,
      "duration": 4.24,
      "text": "uh right so so something that was so"
    },
    {
      "start": 628.16,
      "duration": 5.119,
      "text": "good that people actually come to our"
    },
    {
      "start": 630.56,
      "duration": 5.04,
      "text": "desk and politely tell us like uh I"
    },
    {
      "start": 633.279,
      "duration": 4.881,
      "text": "think you you made a error like a"
    },
    {
      "start": 635.6,
      "duration": 4.88,
      "text": "calculation do you think it's nats not"
    },
    {
      "start": 638.16,
      "duration": 5.28,
      "text": "bits per character and we're like no no"
    },
    {
      "start": 640.48,
      "duration": 5.12,
      "text": "no we you know it really is the the the"
    },
    {
      "start": 643.44,
      "duration": 4.399,
      "text": "correct the correct number. What struck"
    },
    {
      "start": 645.6,
      "duration": 5.44,
      "text": "me later is that all of a sudden all of"
    },
    {
      "start": 647.839,
      "duration": 6.641,
      "text": "that research and to be clear very good"
    },
    {
      "start": 651.04,
      "duration": 4.4,
      "text": "research was suddenly made completely"
    },
    {
      "start": 654.48,
      "duration": 1.28,
      "text": "redundant."
    },
    {
      "start": 655.44,
      "duration": 2.88,
      "text": ">> Yes."
    },
    {
      "start": 655.76,
      "duration": 4.96,
      "text": ">> Right. All of those endless permutations"
    },
    {
      "start": 658.32,
      "duration": 5.92,
      "text": "to to RNN's"
    },
    {
      "start": 660.72,
      "duration": 6.48,
      "text": "were suddenly seemingly a waste of time."
    },
    {
      "start": 664.24,
      "duration": 4.719,
      "text": "We're kind of in the situation right now"
    },
    {
      "start": 667.2,
      "duration": 4.48,
      "text": "where a lot of the papers are just"
    },
    {
      "start": 668.959,
      "duration": 5.201,
      "text": "taking the same architecture"
    },
    {
      "start": 671.68,
      "duration": 4.24,
      "text": "and making these endless amount of"
    },
    {
      "start": 674.16,
      "duration": 3.76,
      "text": "different tweaks of like you know where"
    },
    {
      "start": 675.92,
      "duration": 3.52,
      "text": "to put them normalization layer and"
    },
    {
      "start": 677.92,
      "duration": 4.24,
      "text": "slightly different ways of training them"
    },
    {
      "start": 679.44,
      "duration": 5.2,
      "text": "and and we might be wasting the time in"
    },
    {
      "start": 682.16,
      "duration": 4.16,
      "text": "exactly the same way right like I"
    },
    {
      "start": 684.64,
      "duration": 3.28,
      "text": "personally don't think we're done right"
    },
    {
      "start": 686.32,
      "duration": 2.959,
      "text": "I don't think that this is the final"
    },
    {
      "start": 687.92,
      "duration": 4.64,
      "text": "architecture and we just need to keep"
    },
    {
      "start": 689.279,
      "duration": 6.401,
      "text": "scaling up there's some breakthrough"
    },
    {
      "start": 692.56,
      "duration": 5.2,
      "text": "that will occur at some point and then"
    },
    {
      "start": 695.68,
      "duration": 3.68,
      "text": "it will once again become obvious that"
    },
    {
      "start": 697.76,
      "duration": 2.88,
      "text": "we're kind of wasting a lot of time"
    },
    {
      "start": 699.36,
      "duration": 3.36,
      "text": "right now."
    },
    {
      "start": 700.64,
      "duration": 4.56,
      "text": ">> Yeah. So we are a victim of our own"
    },
    {
      "start": 702.72,
      "duration": 4,
      "text": "success and this basin of attraction"
    },
    {
      "start": 705.2,
      "duration": 3.12,
      "text": "there are so many basins of attraction."
    },
    {
      "start": 706.72,
      "duration": 3.28,
      "text": "Sarah Hooker spoke about the hardware"
    },
    {
      "start": 708.32,
      "duration": 5.199,
      "text": "lottery and this is a kind of"
    },
    {
      "start": 710,
      "duration": 5.04,
      "text": "architecture lottery and it it it"
    },
    {
      "start": 713.519,
      "duration": 4.161,
      "text": "actually made me think of the um"
    },
    {
      "start": 715.04,
      "duration": 6,
      "text": "agricultural revolution which is that"
    },
    {
      "start": 717.68,
      "duration": 5.36,
      "text": "this kind of phase change happened and"
    },
    {
      "start": 721.04,
      "duration": 3.84,
      "text": "all of the folks that had these skills"
    },
    {
      "start": 723.04,
      "duration": 4.08,
      "text": "that were so necessary, these diverse"
    },
    {
      "start": 724.88,
      "duration": 4.959,
      "text": "skills for living and surviving, they"
    },
    {
      "start": 727.12,
      "duration": 5.12,
      "text": "died out. And that's actually quite"
    },
    {
      "start": 729.839,
      "duration": 4.481,
      "text": "paradoxical because we need those skills"
    },
    {
      "start": 732.24,
      "duration": 5.039,
      "text": "to take the next step. M"
    },
    {
      "start": 734.32,
      "duration": 5.36,
      "text": ">> and so we we're now in this regime we've"
    },
    {
      "start": 737.279,
      "duration": 4.161,
      "text": "got the term foundation model and the"
    },
    {
      "start": 739.68,
      "duration": 4.08,
      "text": "implication is that you can do anything"
    },
    {
      "start": 741.44,
      "duration": 4.079,
      "text": "with a foundation model in the corporate"
    },
    {
      "start": 743.76,
      "duration": 4.079,
      "text": "world we used to have data scientists"
    },
    {
      "start": 745.519,
      "duration": 4.801,
      "text": "you know they were ML engineers doing"
    },
    {
      "start": 747.839,
      "duration": 5.521,
      "text": "these architectural tweaks even in you"
    },
    {
      "start": 750.32,
      "duration": 5.6,
      "text": "know midsize enterprise and now we just"
    },
    {
      "start": 753.36,
      "duration": 5.44,
      "text": "have AI engineers who are just doing"
    },
    {
      "start": 755.92,
      "duration": 4.8,
      "text": "prompt engineering and so on. So you're"
    },
    {
      "start": 758.8,
      "duration": 4.88,
      "text": "saying that the fundamental skills that"
    },
    {
      "start": 760.72,
      "duration": 5.28,
      "text": "we need to be diverse to think of new"
    },
    {
      "start": 763.68,
      "duration": 4.88,
      "text": "solutions and new architectures, they're"
    },
    {
      "start": 766,
      "duration": 6,
      "text": "dying out. I think I'm going to disagree"
    },
    {
      "start": 768.56,
      "duration": 8.399,
      "text": "with that. I think the problem is we"
    },
    {
      "start": 772,
      "duration": 8.16,
      "text": "have plenty of very talented"
    },
    {
      "start": 776.959,
      "duration": 5.921,
      "text": "uh very creative researchers out there,"
    },
    {
      "start": 780.16,
      "duration": 4.96,
      "text": "but they're not using their talents."
    },
    {
      "start": 782.88,
      "duration": 3.92,
      "text": "Right? For example, you know, if you're"
    },
    {
      "start": 785.12,
      "duration": 4.08,
      "text": "in academia,"
    },
    {
      "start": 786.8,
      "duration": 5.36,
      "text": "there's pressure to publish, right? And"
    },
    {
      "start": 789.2,
      "duration": 4.56,
      "text": "if there's pressure to publish,"
    },
    {
      "start": 792.16,
      "duration": 4.32,
      "text": "you think to yourself, okay, well, I"
    },
    {
      "start": 793.76,
      "duration": 5.28,
      "text": "have this really cool idea,"
    },
    {
      "start": 796.48,
      "duration": 4.64,
      "text": "but it might not work. It might be too"
    },
    {
      "start": 799.04,
      "duration": 4,
      "text": "weird, right? It might be difficult to"
    },
    {
      "start": 801.12,
      "duration": 4.56,
      "text": "get it accepted because I have to sort"
    },
    {
      "start": 803.04,
      "duration": 4.4,
      "text": "of like sell the idea more."
    },
    {
      "start": 805.68,
      "duration": 6.32,
      "text": "Or I can just try this new positional"
    },
    {
      "start": 807.44,
      "duration": 6.639,
      "text": "embedding, right? The problem is that"
    },
    {
      "start": 812,
      "duration": 4.88,
      "text": "the current"
    },
    {
      "start": 814.079,
      "duration": 5.281,
      "text": "environment both in academia and in"
    },
    {
      "start": 816.88,
      "duration": 5.12,
      "text": "companies are not actually giving people"
    },
    {
      "start": 819.36,
      "duration": 4.479,
      "text": "the freedom that they need to do the"
    },
    {
      "start": 822,
      "duration": 2.079,
      "text": "research that they probably want to do."
    },
    {
      "start": 823.839,
      "duration": 1.44,
      "text": "I"
    },
    {
      "start": 824.079,
      "duration": 3.76,
      "text": ">> mean there's also this interesting thing"
    },
    {
      "start": 825.279,
      "duration": 6.321,
      "text": "that even in spite of great new research"
    },
    {
      "start": 827.839,
      "duration": 5.361,
      "text": "I mean I was speaking to Seb Hoger and"
    },
    {
      "start": 831.6,
      "duration": 4.16,
      "text": "he's got all of these new architectural"
    },
    {
      "start": 833.2,
      "duration": 3.759,
      "text": "ideas and open AI aren't implementing"
    },
    {
      "start": 835.76,
      "duration": 2.8,
      "text": "them. I mean Google are doing this"
    },
    {
      "start": 836.959,
      "duration": 4.801,
      "text": "diffusion language model which is quite"
    },
    {
      "start": 838.56,
      "duration": 5.04,
      "text": "cool. And I I'd like to know your"
    },
    {
      "start": 841.76,
      "duration": 3.84,
      "text": "opinion on why that is. So there's a few"
    },
    {
      "start": 843.6,
      "duration": 4.4,
      "text": "philosophies floating around like this"
    },
    {
      "start": 845.6,
      "duration": 4.96,
      "text": "concept of a universal representation"
    },
    {
      "start": 848,
      "duration": 4.8,
      "text": "that there are universal patterns and"
    },
    {
      "start": 850.56,
      "duration": 4.48,
      "text": "the the transformer representations"
    },
    {
      "start": 852.8,
      "duration": 4.479,
      "text": "resemble those in the brain. And it's"
    },
    {
      "start": 855.04,
      "duration": 3.68,
      "text": "rather led to this idea of well we don't"
    },
    {
      "start": 857.279,
      "duration": 3.041,
      "text": "need to use different architectures"
    },
    {
      "start": 858.72,
      "duration": 3.679,
      "text": "because if we just have more scale and"
    },
    {
      "start": 860.32,
      "duration": 3.84,
      "text": "more compute then all roads lead to"
    },
    {
      "start": 862.399,
      "duration": 2.961,
      "text": "Rome. So why would we bother doing it"
    },
    {
      "start": 864.16,
      "duration": 3.2,
      "text": "any differently?"
    },
    {
      "start": 865.36,
      "duration": 4.64,
      "text": ">> There's actually better right? There is"
    },
    {
      "start": 867.36,
      "duration": 5.839,
      "text": "actually already architectures that have"
    },
    {
      "start": 870,
      "duration": 6.16,
      "text": "been shown in the research to work"
    },
    {
      "start": 873.199,
      "duration": 5.681,
      "text": "better than transformers. Okay."
    },
    {
      "start": 876.16,
      "duration": 5.76,
      "text": "But not better enough"
    },
    {
      "start": 878.88,
      "duration": 4.959,
      "text": "in order to move the entire industry"
    },
    {
      "start": 881.92,
      "duration": 4.4,
      "text": "away from such an established"
    },
    {
      "start": 883.839,
      "duration": 4.161,
      "text": "architecture where you're familiar with"
    },
    {
      "start": 886.32,
      "duration": 3.36,
      "text": "it. You know how to train it. You know"
    },
    {
      "start": 888,
      "duration": 4.16,
      "text": "how it works. You know how the internals"
    },
    {
      "start": 889.68,
      "duration": 4.64,
      "text": "work, right? You know how to fine-tune"
    },
    {
      "start": 892.16,
      "duration": 3.679,
      "text": "them. You have all this software is"
    },
    {
      "start": 894.32,
      "duration": 3.84,
      "text": "already set up for training"
    },
    {
      "start": 895.839,
      "duration": 4.321,
      "text": "transformers. fine gening transformers"
    },
    {
      "start": 898.16,
      "duration": 3.679,
      "text": "inference."
    },
    {
      "start": 900.16,
      "duration": 3.679,
      "text": "So if you want to move the industry away"
    },
    {
      "start": 901.839,
      "duration": 3.521,
      "text": "from that, being better is not good"
    },
    {
      "start": 903.839,
      "duration": 5.12,
      "text": "enough."
    },
    {
      "start": 905.36,
      "duration": 6.56,
      "text": "It has to be obviously crushingly"
    },
    {
      "start": 908.959,
      "duration": 5.921,
      "text": "better. Transformers were that much"
    },
    {
      "start": 911.92,
      "duration": 4.719,
      "text": "better over RNNs. Okay, transformers"
    },
    {
      "start": 914.88,
      "duration": 4.72,
      "text": "where you just applied it to a new"
    },
    {
      "start": 916.639,
      "duration": 4.801,
      "text": "problem and it just was so so much"
    },
    {
      "start": 919.6,
      "duration": 4.88,
      "text": "faster to train and you just got such"
    },
    {
      "start": 921.44,
      "duration": 4.8,
      "text": "higher accuracy that you just had to"
    },
    {
      "start": 924.48,
      "duration": 3.28,
      "text": "move."
    },
    {
      "start": 926.24,
      "duration": 3.12,
      "text": "And I think the deep the deep learning"
    },
    {
      "start": 927.76,
      "duration": 4.16,
      "text": "revolution was also another example of"
    },
    {
      "start": 929.36,
      "duration": 6,
      "text": "that, right? Where you had plenty of"
    },
    {
      "start": 931.92,
      "duration": 5.44,
      "text": "skeptics and people were pushing um"
    },
    {
      "start": 935.36,
      "duration": 3.919,
      "text": "neural networks even back then and"
    },
    {
      "start": 937.36,
      "duration": 3.919,
      "text": "people are going, \"No, we think symbolic"
    },
    {
      "start": 939.279,
      "duration": 3.441,
      "text": "stuff will work better.\" But then they"
    },
    {
      "start": 941.279,
      "duration": 3.841,
      "text": "demonstrated it as being so much better"
    },
    {
      "start": 942.72,
      "duration": 5.6,
      "text": "that you couldn't ignore it. This fact"
    },
    {
      "start": 945.12,
      "duration": 5.6,
      "text": "makes finding the next thing even"
    },
    {
      "start": 948.32,
      "duration": 5.519,
      "text": "harder. Right? That's the gravitational"
    },
    {
      "start": 950.72,
      "duration": 4.559,
      "text": "pole of always pull pulling you back to,"
    },
    {
      "start": 953.839,
      "duration": 4.161,
      "text": "oh, okay, but a transformer is good"
    },
    {
      "start": 955.279,
      "duration": 4.401,
      "text": "enough. And yeah, you made a cool little"
    },
    {
      "start": 958,
      "duration": 3.68,
      "text": "architecture over here that yeah, it"
    },
    {
      "start": 959.68,
      "duration": 4.079,
      "text": "looks like it's it's got better"
    },
    {
      "start": 961.68,
      "duration": 3.92,
      "text": "accuracy, but OpenAI over here just made"
    },
    {
      "start": 963.759,
      "duration": 3.841,
      "text": "it 10 times bigger and it beats that."
    },
    {
      "start": 965.6,
      "duration": 4.159,
      "text": "So, let's just keep going. May I also"
    },
    {
      "start": 967.6,
      "duration": 4.479,
      "text": "submit that there could be an additional"
    },
    {
      "start": 969.759,
      "duration": 4.08,
      "text": "reason which is you know I love that"
    },
    {
      "start": 972.079,
      "duration": 4.32,
      "text": "fractured entangled representations"
    },
    {
      "start": 973.839,
      "duration": 4.641,
      "text": "paper. Um there's there's this shortcut"
    },
    {
      "start": 976.399,
      "duration": 3.521,
      "text": "learning problem and I think that"
    },
    {
      "start": 978.48,
      "duration": 4.08,
      "text": "there's a little bit of a mirage going"
    },
    {
      "start": 979.92,
      "duration": 4.56,
      "text": "on here and there there might be"
    },
    {
      "start": 982.56,
      "duration": 3.519,
      "text": "problems with these language models that"
    },
    {
      "start": 984.48,
      "duration": 3.599,
      "text": "we don't you know that we're not fully"
    },
    {
      "start": 986.079,
      "duration": 3.601,
      "text": "aware of and there's also this thing"
    },
    {
      "start": 988.079,
      "duration": 4.161,
      "text": "that we're seeing that we are starting"
    },
    {
      "start": 989.68,
      "duration": 4.079,
      "text": "to bastardize the architecture. So we"
    },
    {
      "start": 992.24,
      "duration": 3.68,
      "text": "know we need to have adaptive"
    },
    {
      "start": 993.759,
      "duration": 3.52,
      "text": "computation for reasoning. We know we"
    },
    {
      "start": 995.92,
      "duration": 3.52,
      "text": "want things like uncertainty"
    },
    {
      "start": 997.279,
      "duration": 4.721,
      "text": "quantification and what we're doing is"
    },
    {
      "start": 999.44,
      "duration": 4.24,
      "text": "is we're bolting these things on top"
    },
    {
      "start": 1002,
      "duration": 3.279,
      "text": "rather than having an architecture which"
    },
    {
      "start": 1003.68,
      "duration": 2.88,
      "text": "intrinsically does all of these things"
    },
    {
      "start": 1005.279,
      "duration": 4.161,
      "text": "that we know we need."
    },
    {
      "start": 1006.56,
      "duration": 4.56,
      "text": ">> Yeah. And I and I think the the our"
    },
    {
      "start": 1009.44,
      "duration": 5.04,
      "text": "continuous thought machine is is an"
    },
    {
      "start": 1011.12,
      "duration": 5.36,
      "text": "attempt at addressing those um more"
    },
    {
      "start": 1014.48,
      "duration": 4.479,
      "text": "directly, right? Which which Luke will"
    },
    {
      "start": 1016.48,
      "duration": 4.479,
      "text": "be able to tell you more about later."
    },
    {
      "start": 1018.959,
      "duration": 4,
      "text": "There's something still not quite right"
    },
    {
      "start": 1020.959,
      "duration": 4.561,
      "text": "with this the current technology, right?"
    },
    {
      "start": 1022.959,
      "duration": 6.321,
      "text": "I I think the the phrase that's becoming"
    },
    {
      "start": 1025.52,
      "duration": 7.039,
      "text": "popular is jagged intelligence, right?"
    },
    {
      "start": 1029.28,
      "duration": 4.88,
      "text": "That the fact that you can ask an LLM"
    },
    {
      "start": 1032.559,
      "duration": 4.561,
      "text": "something and it can solve literally"
    },
    {
      "start": 1034.16,
      "duration": 4.72,
      "text": "like a PhD level problem and then you"
    },
    {
      "start": 1037.12,
      "duration": 4.16,
      "text": "know in the next sentence it can say"
    },
    {
      "start": 1038.88,
      "duration": 5.679,
      "text": "something just so clearly obviously"
    },
    {
      "start": 1041.28,
      "duration": 4.72,
      "text": "wrong that it it's it's jarring, right?"
    },
    {
      "start": 1044.559,
      "duration": 4.161,
      "text": "And I think this is actually a"
    },
    {
      "start": 1046,
      "duration": 4.64,
      "text": "reflection of something probably quite"
    },
    {
      "start": 1048.72,
      "duration": 4.16,
      "text": "fundamentally wrong with the current"
    },
    {
      "start": 1050.64,
      "duration": 4.48,
      "text": "architecture. As amazing as they are,"
    },
    {
      "start": 1052.88,
      "duration": 7.44,
      "text": "the current technology"
    },
    {
      "start": 1055.12,
      "duration": 7.04,
      "text": "is actually too good. Okay."
    },
    {
      "start": 1060.32,
      "duration": 5.359,
      "text": "Another reason why it's it's difficult"
    },
    {
      "start": 1062.16,
      "duration": 5.2,
      "text": "to move away from them, right? So"
    },
    {
      "start": 1065.679,
      "duration": 3.681,
      "text": "they're too good in in in the following"
    },
    {
      "start": 1067.36,
      "duration": 3.439,
      "text": "sense. And you you spoke about the fact"
    },
    {
      "start": 1069.36,
      "duration": 2.559,
      "text": "that we have these foundation models."
    },
    {
      "start": 1070.799,
      "duration": 2.481,
      "text": "That's okay. so that we have the"
    },
    {
      "start": 1071.919,
      "duration": 4.801,
      "text": "foundation that we can do anything with"
    },
    {
      "start": 1073.28,
      "duration": 5.2,
      "text": "them. Yes, I think current neural"
    },
    {
      "start": 1076.72,
      "duration": 5.12,
      "text": "networks"
    },
    {
      "start": 1078.48,
      "duration": 6.88,
      "text": "are so powerful that if you have enough"
    },
    {
      "start": 1081.84,
      "duration": 5.04,
      "text": "patience and enough compute and enough"
    },
    {
      "start": 1085.36,
      "duration": 4.48,
      "text": "data,"
    },
    {
      "start": 1086.88,
      "duration": 5.2,
      "text": "you can make them do anything."
    },
    {
      "start": 1089.84,
      "duration": 4.4,
      "text": "But I don't necessarily think that they"
    },
    {
      "start": 1092.08,
      "duration": 3.92,
      "text": "want to, right? we're sort of forcing"
    },
    {
      "start": 1094.24,
      "duration": 4.799,
      "text": "them like they're universal pro"
    },
    {
      "start": 1096,
      "duration": 5.52,
      "text": "approximators but I think there are"
    },
    {
      "start": 1099.039,
      "duration": 5.601,
      "text": "probably a space of you know function"
    },
    {
      "start": 1101.52,
      "duration": 5.039,
      "text": "approximators that will more want to"
    },
    {
      "start": 1104.64,
      "duration": 4.08,
      "text": "represent things in the way that a human"
    },
    {
      "start": 1106.559,
      "duration": 5.521,
      "text": "represents them. So there's actually"
    },
    {
      "start": 1108.72,
      "duration": 7.6,
      "text": "quite an obscure paper that is my poster"
    },
    {
      "start": 1112.08,
      "duration": 6.32,
      "text": "child for this. It's called intelligence"
    },
    {
      "start": 1116.32,
      "duration": 4.32,
      "text": "matrix exponentiation"
    },
    {
      "start": 1118.4,
      "duration": 4,
      "text": ">> and I think it was actually rejected."
    },
    {
      "start": 1120.64,
      "duration": 4.48,
      "text": "So, you know, you can probably project"
    },
    {
      "start": 1122.4,
      "duration": 4.8,
      "text": "uh the image of a figure one, but"
    },
    {
      "start": 1125.12,
      "duration": 4.4,
      "text": "there's an image of it's solving, you"
    },
    {
      "start": 1127.2,
      "duration": 4.16,
      "text": "know, the classical spiral data set of"
    },
    {
      "start": 1129.52,
      "duration": 2.72,
      "text": "needing to separate the two classes in"
    },
    {
      "start": 1131.36,
      "duration": 2,
      "text": "the spiral."
    },
    {
      "start": 1132.24,
      "duration": 4.08,
      "text": ">> Yes."
    },
    {
      "start": 1133.36,
      "duration": 6.8,
      "text": ">> And it has the decision boundary for a"
    },
    {
      "start": 1136.32,
      "duration": 7.44,
      "text": "for both a classic RNN uh multi-layer"
    },
    {
      "start": 1140.16,
      "duration": 6,
      "text": "perceptron and a tanh multi-layer"
    },
    {
      "start": 1143.76,
      "duration": 4.64,
      "text": "perceptron. And you can see they both"
    },
    {
      "start": 1146.16,
      "duration": 4.16,
      "text": "solve it, right? Technically, they both"
    },
    {
      "start": 1148.4,
      "duration": 3.6,
      "text": "solve the problem because they they they"
    },
    {
      "start": 1150.32,
      "duration": 5.44,
      "text": "classify all the points correctly and"
    },
    {
      "start": 1152,
      "duration": 6.88,
      "text": "get a very good test score on this on"
    },
    {
      "start": 1155.76,
      "duration": 5.6,
      "text": "this very simple data set. And then they"
    },
    {
      "start": 1158.88,
      "duration": 4.48,
      "text": "show you the decision boundary for the"
    },
    {
      "start": 1161.36,
      "duration": 5.04,
      "text": "for the M layer that they built in this"
    },
    {
      "start": 1163.36,
      "duration": 6.72,
      "text": "paper and it's a spiral."
    },
    {
      "start": 1166.4,
      "duration": 6.399,
      "text": "The layer represented the spiral as a"
    },
    {
      "start": 1170.08,
      "duration": 4.24,
      "text": "spiral. Sh shouldn't we should you know"
    },
    {
      "start": 1172.799,
      "duration": 3.76,
      "text": "if the data is a spiral shouldn't we"
    },
    {
      "start": 1174.32,
      "duration": 4.8,
      "text": "represent it as a spiral? And then if"
    },
    {
      "start": 1176.559,
      "duration": 5.041,
      "text": "you look back at the decision boundaries"
    },
    {
      "start": 1179.12,
      "duration": 4.64,
      "text": "for for the spiral and the classic relu"
    },
    {
      "start": 1181.6,
      "duration": 4.319,
      "text": "multi-layer perceptron,"
    },
    {
      "start": 1183.76,
      "duration": 6.08,
      "text": "it's clear that you just have these tiny"
    },
    {
      "start": 1185.919,
      "duration": 7.681,
      "text": "little peacewise linear separations."
    },
    {
      "start": 1189.84,
      "duration": 7.28,
      "text": "Um, and that's what I mean. Yes,"
    },
    {
      "start": 1193.6,
      "duration": 5.6,
      "text": "if you know if you train these things"
    },
    {
      "start": 1197.12,
      "duration": 4.4,
      "text": "enough and you push these little"
    },
    {
      "start": 1199.2,
      "duration": 4,
      "text": "peacewise linear boundaries around"
    },
    {
      "start": 1201.52,
      "duration": 5.36,
      "text": "enough,"
    },
    {
      "start": 1203.2,
      "duration": 7.04,
      "text": "it can it can fit the spiral and get a"
    },
    {
      "start": 1206.88,
      "duration": 5.919,
      "text": "high accuracy. But there's no feeling"
    },
    {
      "start": 1210.24,
      "duration": 5.36,
      "text": "when I look at those that that image"
    },
    {
      "start": 1212.799,
      "duration": 6.961,
      "text": "that the relu version actually"
    },
    {
      "start": 1215.6,
      "duration": 6.319,
      "text": "understands that it is a spiral,"
    },
    {
      "start": 1219.76,
      "duration": 4.4,
      "text": "right? And when you represent it as a"
    },
    {
      "start": 1221.919,
      "duration": 4,
      "text": "spiral, it actually extrapolates"
    },
    {
      "start": 1224.16,
      "duration": 2.8,
      "text": "correctly because the spiral just keeps"
    },
    {
      "start": 1225.919,
      "duration": 2.401,
      "text": "going out."
    },
    {
      "start": 1226.96,
      "duration": 2.56,
      "text": ">> You're touching on something fascinating"
    },
    {
      "start": 1228.32,
      "duration": 4.08,
      "text": "there because, you know, we were talking"
    },
    {
      "start": 1229.52,
      "duration": 5.36,
      "text": "about the need for adaptivity and um"
    },
    {
      "start": 1232.4,
      "duration": 4.88,
      "text": "adaptive computation. Um I'm really"
    },
    {
      "start": 1234.88,
      "duration": 4.24,
      "text": "inspired by Randall Bisreerero's spline"
    },
    {
      "start": 1237.28,
      "duration": 4.72,
      "text": "theory of of neural networks and we"
    },
    {
      "start": 1239.12,
      "duration": 4.96,
      "text": "we've had them on many times and you can"
    },
    {
      "start": 1242,
      "duration": 3.28,
      "text": "look on the TensorFlow playground. You"
    },
    {
      "start": 1244.08,
      "duration": 2.959,
      "text": "can look what happens when you have a"
    },
    {
      "start": 1245.28,
      "duration": 4.639,
      "text": "ReLU network on on this, you know,"
    },
    {
      "start": 1247.039,
      "duration": 4.401,
      "text": "spiral manifold. And, you know, you'd be"
    },
    {
      "start": 1249.919,
      "duration": 3.601,
      "text": "forgiven for thinking that these things"
    },
    {
      "start": 1251.44,
      "duration": 4.64,
      "text": "are basically a locality sensitive"
    },
    {
      "start": 1253.52,
      "duration": 4.399,
      "text": "hashing table, right? Because they they"
    },
    {
      "start": 1256.08,
      "duration": 5.52,
      "text": "do they they they they partition the"
    },
    {
      "start": 1257.919,
      "duration": 6.321,
      "text": "space and and they they can predict the"
    },
    {
      "start": 1261.6,
      "duration": 4.319,
      "text": "spiral manifold, right? But we want to"
    },
    {
      "start": 1264.24,
      "duration": 3.439,
      "text": "do something a little bit more different"
    },
    {
      "start": 1265.919,
      "duration": 4.481,
      "text": "than that. And it also comes into this"
    },
    {
      "start": 1267.679,
      "duration": 4.721,
      "text": "imposttor thing because just tracing the"
    },
    {
      "start": 1270.4,
      "duration": 4.399,
      "text": "spiral manifold"
    },
    {
      "start": 1272.4,
      "duration": 4.399,
      "text": "but not continuing the pattern there's a"
    },
    {
      "start": 1274.799,
      "duration": 5.441,
      "text": "big difference between that. So from an"
    },
    {
      "start": 1276.799,
      "duration": 5.601,
      "text": "imposttor perspective just just tracing"
    },
    {
      "start": 1280.24,
      "duration": 5.04,
      "text": "the pattern is not learning it"
    },
    {
      "start": 1282.4,
      "duration": 4.639,
      "text": "abstractly or constructively. Right? If"
    },
    {
      "start": 1285.28,
      "duration": 3.44,
      "text": "we learned it constructively so we you"
    },
    {
      "start": 1287.039,
      "duration": 4,
      "text": "know you speak about this in your paper"
    },
    {
      "start": 1288.72,
      "duration": 4.48,
      "text": "this complexification the abstract"
    },
    {
      "start": 1291.039,
      "duration": 5.12,
      "text": "building blocks and you can do adaptive"
    },
    {
      "start": 1293.2,
      "duration": 4.479,
      "text": "computation. you understand the spiral."
    },
    {
      "start": 1296.159,
      "duration": 4.081,
      "text": "That means that with adaptive"
    },
    {
      "start": 1297.679,
      "duration": 4.161,
      "text": "computation, you can continue the spiral"
    },
    {
      "start": 1300.24,
      "duration": 3.76,
      "text": "and then you can update the model's"
    },
    {
      "start": 1301.84,
      "duration": 4.88,
      "text": "weights so it has adaptivity because"
    },
    {
      "start": 1304,
      "duration": 5.36,
      "text": "that's so important for intelligence. So"
    },
    {
      "start": 1306.72,
      "duration": 5.36,
      "text": "we know that we need models that can do"
    },
    {
      "start": 1309.36,
      "duration": 4.4,
      "text": "these things. But for some reason"
    },
    {
      "start": 1312.08,
      "duration": 3.28,
      "text": "they're they're so sick of fantic"
    },
    {
      "start": 1313.76,
      "duration": 3.6,
      "text": "they're almost better than an adaptive"
    },
    {
      "start": 1315.36,
      "duration": 4.24,
      "text": "intelligent system because they tell us"
    },
    {
      "start": 1317.36,
      "duration": 4.4,
      "text": "exactly what we want to hear. They seem"
    },
    {
      "start": 1319.6,
      "duration": 4.079,
      "text": "so intelligent, but we know that they're"
    },
    {
      "start": 1321.76,
      "duration": 5.12,
      "text": "missing these fundamental properties."
    },
    {
      "start": 1323.679,
      "duration": 5.681,
      "text": ">> I'm still fairly skeptical when I see"
    },
    {
      "start": 1326.88,
      "duration": 4.32,
      "text": "video generation models."
    },
    {
      "start": 1329.36,
      "duration": 3.92,
      "text": "You know, we went through a phase where"
    },
    {
      "start": 1331.2,
      "duration": 4,
      "text": "you could detect them because of the"
    },
    {
      "start": 1333.28,
      "duration": 3.2,
      "text": "number of fingers on somebody's hand,"
    },
    {
      "start": 1335.2,
      "duration": 3.52,
      "text": "right?"
    },
    {
      "start": 1336.48,
      "duration": 5.92,
      "text": "And yes,"
    },
    {
      "start": 1338.72,
      "duration": 7.04,
      "text": "with more data, with more compute, with"
    },
    {
      "start": 1342.4,
      "duration": 8,
      "text": "better training tricks, okay, they"
    },
    {
      "start": 1345.76,
      "duration": 8.72,
      "text": "submit. And now they usually do have"
    },
    {
      "start": 1350.4,
      "duration": 6.8,
      "text": "five fingers. But did we fix the problem"
    },
    {
      "start": 1354.48,
      "duration": 5.84,
      "text": "or did we just use more brute force to"
    },
    {
      "start": 1357.2,
      "duration": 5.92,
      "text": "just you know force the the neural"
    },
    {
      "start": 1360.32,
      "duration": 4.64,
      "text": "network to know it's five fingers where"
    },
    {
      "start": 1363.12,
      "duration": 4.4,
      "text": "something that actually had a much"
    },
    {
      "start": 1364.96,
      "duration": 4.079,
      "text": "better kind of representation space."
    },
    {
      "start": 1367.52,
      "duration": 3.279,
      "text": "It's almost mad that it's controversial"
    },
    {
      "start": 1369.039,
      "duration": 3.921,
      "text": "to say that we should represent a spiral"
    },
    {
      "start": 1370.799,
      "duration": 4.961,
      "text": "like a spiral. But, you know, something"
    },
    {
      "start": 1372.96,
      "duration": 4.64,
      "text": "that could do that generally that if if"
    },
    {
      "start": 1375.76,
      "duration": 4,
      "text": "it represented a human hand the way"
    },
    {
      "start": 1377.6,
      "duration": 3.68,
      "text": "that, you know, maybe I represent a"
    },
    {
      "start": 1379.76,
      "duration": 2.96,
      "text": "human hand, then maybe it would be much"
    },
    {
      "start": 1381.28,
      "duration": 4.399,
      "text": "easier to count how many fingers are on"
    },
    {
      "start": 1382.72,
      "duration": 5.199,
      "text": "a on a hand. It's unfortunate"
    },
    {
      "start": 1385.679,
      "duration": 4,
      "text": "that they work so well. It's unfortunate"
    },
    {
      "start": 1387.919,
      "duration": 5.041,
      "text": "that scaling works so well because it's"
    },
    {
      "start": 1389.679,
      "duration": 6.161,
      "text": "too easy for people to just sweep these"
    },
    {
      "start": 1392.96,
      "duration": 5.12,
      "text": "problems under the carpet. You guys have"
    },
    {
      "start": 1395.84,
      "duration": 4.16,
      "text": "possibly created what I think might be"
    },
    {
      "start": 1398.08,
      "duration": 4.479,
      "text": "the best paper of of the year. This"
    },
    {
      "start": 1400,
      "duration": 4.559,
      "text": "could actually be the innovation which"
    },
    {
      "start": 1402.559,
      "duration": 3.921,
      "text": "takes us to the next step. And you did"
    },
    {
      "start": 1404.559,
      "duration": 2.24,
      "text": "you get the spotlight in Europe as well?"
    },
    {
      "start": 1406.48,
      "duration": 2,
      "text": ">> Yeah."
    },
    {
      "start": 1406.799,
      "duration": 3.521,
      "text": ">> This year and congratulations on that."
    },
    {
      "start": 1408.48,
      "duration": 3.36,
      "text": "So I think that's testament to how"
    },
    {
      "start": 1410.32,
      "duration": 4.239,
      "text": "amazing this paper is."
    },
    {
      "start": 1411.84,
      "duration": 5.839,
      "text": ">> The CTM the continuous thought machine."
    },
    {
      "start": 1414.559,
      "duration": 4.801,
      "text": "It's actually not that far out outside"
    },
    {
      "start": 1417.679,
      "duration": 3.601,
      "text": "of the local minimum that we're stuck"
    },
    {
      "start": 1419.36,
      "duration": 4.319,
      "text": "in. Right? It's not as if we went and"
    },
    {
      "start": 1421.28,
      "duration": 6.96,
      "text": "found this completely new technology."
    },
    {
      "start": 1423.679,
      "duration": 8,
      "text": "Right? We took quite a um a simple"
    },
    {
      "start": 1428.24,
      "duration": 5.439,
      "text": "biologically inspired idea, right, of"
    },
    {
      "start": 1431.679,
      "duration": 4.88,
      "text": "these of of the fact that neurons"
    },
    {
      "start": 1433.679,
      "duration": 5.601,
      "text": "synchronize and not even necessarily in"
    },
    {
      "start": 1436.559,
      "duration": 5.441,
      "text": "a biologically plausible way, right?"
    },
    {
      "start": 1439.28,
      "duration": 4.24,
      "text": "Brains don't literally have all their"
    },
    {
      "start": 1442,
      "duration": 4.559,
      "text": "neurons wired together in a way that"
    },
    {
      "start": 1443.52,
      "duration": 5.12,
      "text": "they work out their synchronization."
    },
    {
      "start": 1446.559,
      "duration": 3.921,
      "text": "But it's"
    },
    {
      "start": 1448.64,
      "duration": 4.399,
      "text": "it's the sort of research that I want to"
    },
    {
      "start": 1450.48,
      "duration": 6.16,
      "text": "encourage people to do. And the way to"
    },
    {
      "start": 1453.039,
      "duration": 6.561,
      "text": "sell it is quite easy. I think at no"
    },
    {
      "start": 1456.64,
      "duration": 5.76,
      "text": "point did we have to worry about being"
    },
    {
      "start": 1459.6,
      "duration": 5.52,
      "text": "scooped, right? That stress was taken"
    },
    {
      "start": 1462.4,
      "duration": 5.6,
      "text": "away from us completely. So, and there"
    },
    {
      "start": 1465.12,
      "duration": 5.12,
      "text": "was so there was no pressure to sort of"
    },
    {
      "start": 1468,
      "duration": 3.36,
      "text": "rush out with this with this idea"
    },
    {
      "start": 1470.24,
      "duration": 2.4,
      "text": "because we're like, well, there's"
    },
    {
      "start": 1471.36,
      "duration": 3.919,
      "text": "probably somebody else working on"
    },
    {
      "start": 1472.64,
      "duration": 4.24,
      "text": "exactly this. And I think the reason"
    },
    {
      "start": 1475.279,
      "duration": 3.681,
      "text": "that we, you know, we were able to get a"
    },
    {
      "start": 1476.88,
      "duration": 4.56,
      "text": "spotlight is because we're able to"
    },
    {
      "start": 1478.96,
      "duration": 4.88,
      "text": "create such a polished paper. We took"
    },
    {
      "start": 1481.44,
      "duration": 4.719,
      "text": "the time to do the science properly to"
    },
    {
      "start": 1483.84,
      "duration": 5.6,
      "text": "get the the base the baselines that we"
    },
    {
      "start": 1486.159,
      "duration": 5.841,
      "text": "wanted and do all the the the the tasks"
    },
    {
      "start": 1489.44,
      "duration": 4.479,
      "text": "that we wanted to try. Encouraging"
    },
    {
      "start": 1492,
      "duration": 4.72,
      "text": "researchers to take a little bit more of"
    },
    {
      "start": 1493.919,
      "duration": 5.12,
      "text": "a of a risk, right? To try these"
    },
    {
      "start": 1496.72,
      "duration": 5.439,
      "text": "slightly more speculative long-term"
    },
    {
      "start": 1499.039,
      "duration": 5.281,
      "text": "ideas, I think is is the sad thing is I"
    },
    {
      "start": 1502.159,
      "duration": 6.161,
      "text": "don't think it's necessarily a very"
    },
    {
      "start": 1504.32,
      "duration": 7.12,
      "text": "difficult thing to sell. And I want to"
    },
    {
      "start": 1508.32,
      "duration": 6,
      "text": "have the CTM as like a poster child of"
    },
    {
      "start": 1511.44,
      "duration": 4,
      "text": "it works, right? It was a bit of a risk."
    },
    {
      "start": 1514.32,
      "duration": 3.12,
      "text": "We, you know, we didn't know if we were"
    },
    {
      "start": 1515.44,
      "duration": 3.68,
      "text": "going to find something interesting, but"
    },
    {
      "start": 1517.44,
      "duration": 2.96,
      "text": "you know, it was our first shot and we"
    },
    {
      "start": 1519.12,
      "duration": 3.84,
      "text": "did find something interesting and it"
    },
    {
      "start": 1520.4,
      "duration": 5.12,
      "text": "became a a successful paper. If if we do"
    },
    {
      "start": 1522.96,
      "duration": 5.52,
      "text": "find a system which can acquire"
    },
    {
      "start": 1525.52,
      "duration": 4.8,
      "text": "knowledge, design new architectures, do"
    },
    {
      "start": 1528.48,
      "duration": 4.4,
      "text": "the the open-ended type of science that"
    },
    {
      "start": 1530.32,
      "duration": 5.12,
      "text": "you're speaking to, can you see a future"
    },
    {
      "start": 1532.88,
      "duration": 4.96,
      "text": "where at some point the locus of"
    },
    {
      "start": 1535.44,
      "duration": 3.44,
      "text": "progress will be mostly driven by the"
    },
    {
      "start": 1537.84,
      "duration": 3.12,
      "text": "models themselves?"
    },
    {
      "start": 1538.88,
      "duration": 5.039,
      "text": ">> I think so. Whether or not that's going"
    },
    {
      "start": 1540.96,
      "duration": 5.28,
      "text": "to replace us completely, I go back and"
    },
    {
      "start": 1543.919,
      "duration": 4.481,
      "text": "forth on. Powerful algorithms are"
    },
    {
      "start": 1546.24,
      "duration": 3.919,
      "text": "finding uh helping us do research,"
    },
    {
      "start": 1548.4,
      "duration": 4.56,
      "text": "right? And I think it might just end up"
    },
    {
      "start": 1550.159,
      "duration": 4.961,
      "text": "being a more powerful version of that."
    },
    {
      "start": 1552.96,
      "duration": 5.599,
      "text": "Right? So I I know the the AI scientist"
    },
    {
      "start": 1555.12,
      "duration": 6.64,
      "text": "that we we released, we showed that you"
    },
    {
      "start": 1558.559,
      "duration": 6.48,
      "text": "could actually go end to end, right? Go"
    },
    {
      "start": 1561.76,
      "duration": 5.68,
      "text": "from seeding the system with an idea for"
    },
    {
      "start": 1565.039,
      "duration": 6.161,
      "text": "a research paper and then just take your"
    },
    {
      "start": 1567.44,
      "duration": 5.599,
      "text": "hands off and just let it go."
    },
    {
      "start": 1571.2,
      "duration": 3.52,
      "text": "Think about the idea, write the code,"
    },
    {
      "start": 1573.039,
      "duration": 4.321,
      "text": "run the code, collect the results, and"
    },
    {
      "start": 1574.72,
      "duration": 6.559,
      "text": "write the paper. uh to the point that we"
    },
    {
      "start": 1577.36,
      "duration": 5.439,
      "text": "were actually able to get it to um a"
    },
    {
      "start": 1581.279,
      "duration": 4.241,
      "text": "100%"
    },
    {
      "start": 1582.799,
      "duration": 6,
      "text": "AI generated paper accepted to to a"
    },
    {
      "start": 1585.52,
      "duration": 6,
      "text": "workshop recently, right?"
    },
    {
      "start": 1588.799,
      "duration": 4.961,
      "text": "But I think we did that to show that you"
    },
    {
      "start": 1591.52,
      "duration": 4.639,
      "text": "could do it right as a sort of"
    },
    {
      "start": 1593.76,
      "duration": 4.799,
      "text": "demonstration"
    },
    {
      "start": 1596.159,
      "duration": 4.961,
      "text": "in a real system. I think I would want"
    },
    {
      "start": 1598.559,
      "duration": 4,
      "text": "it to be much more interactive,"
    },
    {
      "start": 1601.12,
      "duration": 3.76,
      "text": "right? I would want to be able to seed"
    },
    {
      "start": 1602.559,
      "duration": 4.48,
      "text": "with an idea and then have it come back"
    },
    {
      "start": 1604.88,
      "duration": 4.72,
      "text": "with more ideas, have a discussion with"
    },
    {
      "start": 1607.039,
      "duration": 5.281,
      "text": "me, then go away to write the code. I"
    },
    {
      "start": 1609.6,
      "duration": 4.319,
      "text": "want look at the code and check it and"
    },
    {
      "start": 1612.32,
      "duration": 4.16,
      "text": "then discuss the results as they're"
    },
    {
      "start": 1613.919,
      "duration": 4.721,
      "text": "coming out. So that's the sort of"
    },
    {
      "start": 1616.48,
      "duration": 5.04,
      "text": "nearterm future that I that I would"
    },
    {
      "start": 1618.64,
      "duration": 4.399,
      "text": "envision or how I would like to do"
    },
    {
      "start": 1621.52,
      "duration": 3.279,
      "text": "research with an AI."
    },
    {
      "start": 1623.039,
      "duration": 4.721,
      "text": ">> And could you introspect on that? Is it"
    },
    {
      "start": 1624.799,
      "duration": 5.281,
      "text": "because you feel we need supervision"
    },
    {
      "start": 1627.76,
      "duration": 3.84,
      "text": "because the models don't yet understand?"
    },
    {
      "start": 1630.08,
      "duration": 3.76,
      "text": "You know there's this path dependence"
    },
    {
      "start": 1631.6,
      "duration": 4.24,
      "text": "idea. So we need to do supervision"
    },
    {
      "start": 1633.84,
      "duration": 3.28,
      "text": "because we have the path dependence so"
    },
    {
      "start": 1635.84,
      "duration": 3.04,
      "text": "we can guide the generation of the"
    },
    {
      "start": 1637.12,
      "duration": 3.28,
      "text": "language models. Maybe in the future the"
    },
    {
      "start": 1638.88,
      "duration": 3.36,
      "text": "language models will just understand"
    },
    {
      "start": 1640.4,
      "duration": 3.92,
      "text": "better themselves. But there's also the"
    },
    {
      "start": 1642.24,
      "duration": 4,
      "text": "output dimension which is that we want"
    },
    {
      "start": 1644.32,
      "duration": 4.479,
      "text": "to produce artifacts that extend the"
    },
    {
      "start": 1646.24,
      "duration": 4.08,
      "text": "fogyny of human interest. We want it to"
    },
    {
      "start": 1648.799,
      "duration": 3.281,
      "text": "be human relevant."
    },
    {
      "start": 1650.32,
      "duration": 4.239,
      "text": ">> Yeah. I I think it's more that you know"
    },
    {
      "start": 1652.08,
      "duration": 4.32,
      "text": "in that initial seed idea it's probably"
    },
    {
      "start": 1654.559,
      "duration": 4.161,
      "text": "impossible to actually describe exactly"
    },
    {
      "start": 1656.4,
      "duration": 5.279,
      "text": "what you want. It's exactly the same"
    },
    {
      "start": 1658.72,
      "duration": 5.28,
      "text": "with, you know, when I have an intern."
    },
    {
      "start": 1661.679,
      "duration": 3.921,
      "text": "I can't just have an intern come into"
    },
    {
      "start": 1664,
      "duration": 3.44,
      "text": "the company and I go, I have this mad"
    },
    {
      "start": 1665.6,
      "duration": 3.52,
      "text": "idea and then just explain it to them"
    },
    {
      "start": 1667.44,
      "duration": 3.28,
      "text": "and then just leave them alone for 4"
    },
    {
      "start": 1669.12,
      "duration": 4.24,
      "text": "months."
    },
    {
      "start": 1670.72,
      "duration": 4.64,
      "text": "There's a back and forth because I have"
    },
    {
      "start": 1673.36,
      "duration": 4.64,
      "text": "a particular idea that I want to explore"
    },
    {
      "start": 1675.36,
      "duration": 5.12,
      "text": "and I need to keep steering them in the"
    },
    {
      "start": 1678,
      "duration": 4.32,
      "text": "direction that I I you know that I had"
    },
    {
      "start": 1680.48,
      "duration": 4.96,
      "text": "in my my mind originally. So I think"
    },
    {
      "start": 1682.32,
      "duration": 5.12,
      "text": "it's more like that basically. You have"
    },
    {
      "start": 1685.44,
      "duration": 3.76,
      "text": "such a deep understanding. So you have"
    },
    {
      "start": 1687.44,
      "duration": 4.8,
      "text": "this rich provenence and history and"
    },
    {
      "start": 1689.2,
      "duration": 5.44,
      "text": "path dependence and that means you can"
    },
    {
      "start": 1692.24,
      "duration": 5.28,
      "text": "take creative steps intuitive steps for"
    },
    {
      "start": 1694.64,
      "duration": 4.56,
      "text": "you respect the fogyny. They respect all"
    },
    {
      "start": 1697.52,
      "duration": 4.399,
      "text": "of this deep abstract understanding that"
    },
    {
      "start": 1699.2,
      "duration": 5.04,
      "text": "you have and interns don't yet have that"
    },
    {
      "start": 1701.919,
      "duration": 3.12,
      "text": ">> but maybe AI models in the future will"
    },
    {
      "start": 1704.24,
      "duration": 2.88,
      "text": "have that."
    },
    {
      "start": 1705.039,
      "duration": 4,
      "text": ">> Yeah sure. If they if they get to the"
    },
    {
      "start": 1707.12,
      "duration": 3.439,
      "text": "point where my inputs becomes"
    },
    {
      "start": 1709.039,
      "duration": 4.401,
      "text": "detrimental"
    },
    {
      "start": 1710.559,
      "duration": 5.201,
      "text": "then yeah that'll be a thing. It's kind"
    },
    {
      "start": 1713.44,
      "duration": 6.959,
      "text": "of like chess, right? There was a point"
    },
    {
      "start": 1715.76,
      "duration": 8.399,
      "text": "at which chess engine and human fusion"
    },
    {
      "start": 1720.399,
      "duration": 5.681,
      "text": "actually beat chess engines. That's not"
    },
    {
      "start": 1724.159,
      "duration": 3.76,
      "text": "that's not true anymore, right? Adding a"
    },
    {
      "start": 1726.08,
      "duration": 2.959,
      "text": "human into the mix actually makes the"
    },
    {
      "start": 1727.919,
      "duration": 2.64,
      "text": "the bots worse."
    },
    {
      "start": 1729.039,
      "duration": 4.321,
      "text": ">> Oh, interesting. I wasn't aware of that."
    },
    {
      "start": 1730.559,
      "duration": 5.441,
      "text": ">> Yeah. So, so what to do when that day"
    },
    {
      "start": 1733.36,
      "duration": 5.52,
      "text": "comes for AI scientists is a is a is a"
    },
    {
      "start": 1736,
      "duration": 4.799,
      "text": "broader discussion. I think"
    },
    {
      "start": 1738.88,
      "duration": 3.44,
      "text": ">> I think now is a good segue to talk"
    },
    {
      "start": 1740.799,
      "duration": 3.12,
      "text": "about this paper in a little bit more"
    },
    {
      "start": 1742.32,
      "duration": 2.959,
      "text": "detail. So this continuous thought"
    },
    {
      "start": 1743.919,
      "duration": 4.48,
      "text": "machines you were just pointing to it"
    },
    {
      "start": 1745.279,
      "duration": 5.28,
      "text": "before. Luke first first of all first of"
    },
    {
      "start": 1748.399,
      "duration": 3.76,
      "text": "all mate introduce yourself"
    },
    {
      "start": 1750.559,
      "duration": 3.84,
      "text": ">> and set this thing up for us."
    },
    {
      "start": 1752.159,
      "duration": 5.361,
      "text": ">> My name is Luke. I am a research"
    },
    {
      "start": 1754.399,
      "duration": 6.081,
      "text": "scientist at Sakana AI [snorts] and uh"
    },
    {
      "start": 1757.52,
      "duration": 5.68,
      "text": "my primary sector of research is this"
    },
    {
      "start": 1760.48,
      "duration": 4.4,
      "text": "continuous thought machines. It's took"
    },
    {
      "start": 1763.2,
      "duration": 3.52,
      "text": "us somewhere in the region of about"
    },
    {
      "start": 1764.88,
      "duration": 4.799,
      "text": "eight months working on this project"
    },
    {
      "start": 1766.72,
      "duration": 4.8,
      "text": "with uh the whole team. Um I I did a lot"
    },
    {
      "start": 1769.679,
      "duration": 3.36,
      "text": "of the work uh but we also had a lot of"
    },
    {
      "start": 1771.52,
      "duration": 4.72,
      "text": "people in different areas and doing"
    },
    {
      "start": 1773.039,
      "duration": 5.36,
      "text": "different parts of it that I think an"
    },
    {
      "start": 1776.24,
      "duration": 4.559,
      "text": "8-month life cycle for a paper seems a"
    },
    {
      "start": 1778.399,
      "duration": 4.241,
      "text": "bit long for AI research at the moment."
    },
    {
      "start": 1780.799,
      "duration": 3.921,
      "text": "Um but yes to the to the actual"
    },
    {
      "start": 1782.64,
      "duration": 4,
      "text": "technical points of the paper. So we"
    },
    {
      "start": 1784.72,
      "duration": 3.28,
      "text": "call it continuous thought machines. It"
    },
    {
      "start": 1786.64,
      "duration": 2.88,
      "text": "originally had a different name. We"
    },
    {
      "start": 1788,
      "duration": 4.48,
      "text": "called it asynchronous thought machines"
    },
    {
      "start": 1789.52,
      "duration": 4.72,
      "text": "before but uh every single time people"
    },
    {
      "start": 1792.48,
      "duration": 4.64,
      "text": "asked us what's the asynchronous part it"
    },
    {
      "start": 1794.24,
      "duration": 5.039,
      "text": "became a bit confusing. So continuous"
    },
    {
      "start": 1797.12,
      "duration": 4.799,
      "text": "thought machines basically depends on"
    },
    {
      "start": 1799.279,
      "duration": 4.88,
      "text": "three novelties. Uh the first one is"
    },
    {
      "start": 1801.919,
      "duration": 4.721,
      "text": "having what we call a internal thought"
    },
    {
      "start": 1804.159,
      "duration": 4.721,
      "text": "dimension and this is not necessarily"
    },
    {
      "start": 1806.64,
      "duration": 5.6,
      "text": "something new. It's related conceptually"
    },
    {
      "start": 1808.88,
      "duration": 5.279,
      "text": "to the ideas of latent reasoning. Uh and"
    },
    {
      "start": 1812.24,
      "duration": 4.48,
      "text": "it's essentially applying compute in a"
    },
    {
      "start": 1814.159,
      "duration": 5.281,
      "text": "sequential dimension. And when you start"
    },
    {
      "start": 1816.72,
      "duration": 5.12,
      "text": "thinking about ideas and problems uh in"
    },
    {
      "start": 1819.44,
      "duration": 4.08,
      "text": "this domain and in in this framework,"
    },
    {
      "start": 1821.84,
      "duration": 4.24,
      "text": "you start understanding that many"
    },
    {
      "start": 1823.52,
      "duration": 4.08,
      "text": "problems that look like intell or"
    },
    {
      "start": 1826.08,
      "duration": 3.52,
      "text": "solutions to problems that look"
    },
    {
      "start": 1827.6,
      "duration": 4.24,
      "text": "intelligent are often solutions that"
    },
    {
      "start": 1829.6,
      "duration": 4,
      "text": "have a sequential nature. So for"
    },
    {
      "start": 1831.84,
      "duration": 3.839,
      "text": "instance, one of the primary tasks that"
    },
    {
      "start": 1833.6,
      "duration": 5.36,
      "text": "we tested in the continuous thought"
    },
    {
      "start": 1835.679,
      "duration": 6.401,
      "text": "machines was this maze solving task. And"
    },
    {
      "start": 1838.96,
      "duration": 6.56,
      "text": "solving mazes for deep learning is is"
    },
    {
      "start": 1842.08,
      "duration": 6.88,
      "text": "quite trivial. It's really easy to do if"
    },
    {
      "start": 1845.52,
      "duration": 5.92,
      "text": "you make the task easy for machines. And"
    },
    {
      "start": 1848.96,
      "duration": 6.319,
      "text": "one of the ways to do this is you give"
    },
    {
      "start": 1851.44,
      "duration": 6.239,
      "text": "an image of a maze to a neural network"
    },
    {
      "start": 1855.279,
      "duration": 5.921,
      "text": "like a convolutional neural network and"
    },
    {
      "start": 1857.679,
      "duration": 6.321,
      "text": "it outputs a image uh same size of the"
    },
    {
      "start": 1861.2,
      "duration": 4.479,
      "text": "maze and it's uh zeros where there isn't"
    },
    {
      "start": 1864,
      "duration": 3.44,
      "text": "a path and there's ones where there is a"
    },
    {
      "start": 1865.679,
      "duration": 3.681,
      "text": "path. There's some really brilliant work"
    },
    {
      "start": 1867.44,
      "duration": 3.92,
      "text": "showing how you can train these in a"
    },
    {
      "start": 1869.36,
      "duration": 3.84,
      "text": "careful way and scale them up"
    },
    {
      "start": 1871.36,
      "duration": 4.64,
      "text": "essentially indefinitely. And this is"
    },
    {
      "start": 1873.2,
      "duration": 5.68,
      "text": "fascinating and uh really interesting"
    },
    {
      "start": 1876,
      "duration": 5.039,
      "text": "idea of how to solve this. However, when"
    },
    {
      "start": 1878.88,
      "duration": 3.6,
      "text": "you take that uh approach out of the"
    },
    {
      "start": 1881.039,
      "duration": 3.201,
      "text": "picture and you ask what is a more human"
    },
    {
      "start": 1882.48,
      "duration": 4.64,
      "text": "way to solve this problem, it becomes a"
    },
    {
      "start": 1884.24,
      "duration": 5.6,
      "text": "sequential problem. You have to say well"
    },
    {
      "start": 1887.12,
      "duration": 4.559,
      "text": "go up, go right, go up, go left,"
    },
    {
      "start": 1889.84,
      "duration": 4,
      "text": "whatever the case may be to trace a"
    },
    {
      "start": 1891.679,
      "duration": 4.641,
      "text": "route from start to finish. And when you"
    },
    {
      "start": 1893.84,
      "duration": 5.6,
      "text": "constrain that simple"
    },
    {
      "start": 1896.32,
      "duration": 5.839,
      "text": "problem space uh and you you ask a"
    },
    {
      "start": 1899.44,
      "duration": 5.2,
      "text": "machine learning system to solve it like"
    },
    {
      "start": 1902.159,
      "duration": 4.4,
      "text": "that turns out to actually get much much"
    },
    {
      "start": 1904.64,
      "duration": 4.8,
      "text": "more challenging. So this became our"
    },
    {
      "start": 1906.559,
      "duration": 4.881,
      "text": "hello world problem for the CTM and"
    },
    {
      "start": 1909.44,
      "duration": 4.16,
      "text": "applying an internal sequential thought"
    },
    {
      "start": 1911.44,
      "duration": 4.079,
      "text": "dimension to this is how we went about"
    },
    {
      "start": 1913.6,
      "duration": 3.84,
      "text": "solving this."
    },
    {
      "start": 1915.519,
      "duration": 4.721,
      "text": "Uh two other novelties that we can touch"
    },
    {
      "start": 1917.44,
      "duration": 4.719,
      "text": "on and talk about. Uh we we sort of"
    },
    {
      "start": 1920.24,
      "duration": 4.08,
      "text": "rethought the idea of what neurons"
    },
    {
      "start": 1922.159,
      "duration": 4.24,
      "text": "should be. There is a lot of excellent"
    },
    {
      "start": 1924.32,
      "duration": 4.16,
      "text": "research in this world uh in cognitive"
    },
    {
      "start": 1926.399,
      "duration": 4.721,
      "text": "neuroscience particularly exploring how"
    },
    {
      "start": 1928.48,
      "duration": 4,
      "text": "neurons work in biological systems. And"
    },
    {
      "start": 1931.12,
      "duration": 3.12,
      "text": "then we get on the other side of the"
    },
    {
      "start": 1932.48,
      "duration": 3.919,
      "text": "scale how deep learning neurons work"
    },
    {
      "start": 1934.24,
      "duration": 5.919,
      "text": "which the quintessential example is a"
    },
    {
      "start": 1936.399,
      "duration": 6,
      "text": "relu. It's off or on in a sense. And"
    },
    {
      "start": 1940.159,
      "duration": 4.561,
      "text": "this very very high level abstraction of"
    },
    {
      "start": 1942.399,
      "duration": 4.721,
      "text": "neurons in the brains feels a little bit"
    },
    {
      "start": 1944.72,
      "duration": 5.199,
      "text": "myopic. So we approached this problem"
    },
    {
      "start": 1947.12,
      "duration": 5.84,
      "text": "and said well let's let's on a neuron by"
    },
    {
      "start": 1949.919,
      "duration": 6.561,
      "text": "neuron basis let this neuron be a little"
    },
    {
      "start": 1952.96,
      "duration": 5.199,
      "text": "model itself. And this ended up doing a"
    },
    {
      "start": 1956.48,
      "duration": 3.84,
      "text": "lot of interesting work on how to build"
    },
    {
      "start": 1958.159,
      "duration": 5.201,
      "text": "dynamics in the system. The third"
    },
    {
      "start": 1960.32,
      "duration": 5.28,
      "text": "novelty here is as I said before we have"
    },
    {
      "start": 1963.36,
      "duration": 4.559,
      "text": "this internal dimension over which"
    },
    {
      "start": 1965.6,
      "duration": 4.4,
      "text": "thinking happens. We ask the question,"
    },
    {
      "start": 1967.919,
      "duration": 4.48,
      "text": "well, what is the representation? What"
    },
    {
      "start": 1970,
      "duration": 4.159,
      "text": "is the representation for a biological"
    },
    {
      "start": 1972.399,
      "duration": 3.441,
      "text": "system when it's thinking? Is it just"
    },
    {
      "start": 1974.159,
      "duration": 5.041,
      "text": "the state of the neurons at any given"
    },
    {
      "start": 1975.84,
      "duration": 5.679,
      "text": "time? Does that capture a thought, if"
    },
    {
      "start": 1979.2,
      "duration": 5.52,
      "text": "you wish, if I can be controversial and"
    },
    {
      "start": 1981.519,
      "duration": 5.361,
      "text": "use the term thinking and thought and my"
    },
    {
      "start": 1984.72,
      "duration": 3.839,
      "text": "philosophy with this is no, it doesn't."
    },
    {
      "start": 1986.88,
      "duration": 4.08,
      "text": "That the concept of a thought is"
    },
    {
      "start": 1988.559,
      "duration": 4.641,
      "text": "something that exists over time. So, how"
    },
    {
      "start": 1990.96,
      "duration": 5.04,
      "text": "do we capture that in in engineering"
    },
    {
      "start": 1993.2,
      "duration": 5.44,
      "text": "speak? We instead of measuring the"
    },
    {
      "start": 1996,
      "duration": 5.44,
      "text": "states of the model that is recurrent,"
    },
    {
      "start": 1998.64,
      "duration": 5.12,
      "text": "we measure how it synchronizes how"
    },
    {
      "start": 2001.44,
      "duration": 4.56,
      "text": "neurons synchronize in pairs along with"
    },
    {
      "start": 2003.76,
      "duration": 4.639,
      "text": "other neurons. And this opens up the"
    },
    {
      "start": 2006,
      "duration": 4.399,
      "text": "door to a huge array of things that we"
    },
    {
      "start": 2008.399,
      "duration": 4.241,
      "text": "can do with this type of representation."
    },
    {
      "start": 2010.399,
      "duration": 5.76,
      "text": ">> You were talking about this um sort of"
    },
    {
      "start": 2012.64,
      "duration": 5.44,
      "text": "sequential nature of of reasoning and"
    },
    {
      "start": 2016.159,
      "duration": 5.041,
      "text": "devil's advocate. I mean there was that"
    },
    {
      "start": 2018.08,
      "duration": 6.319,
      "text": "anthropic biology paper and they were"
    },
    {
      "start": 2021.2,
      "duration": 4.64,
      "text": "talking about planning and thinking and"
    },
    {
      "start": 2024.399,
      "duration": 2.961,
      "text": "and they they were they were saying that"
    },
    {
      "start": 2025.84,
      "duration": 3.12,
      "text": "this thing is planning ahead because"
    },
    {
      "start": 2027.36,
      "duration": 4.08,
      "text": "because I think your system actually we"
    },
    {
      "start": 2028.96,
      "duration": 4.24,
      "text": "can say does planning it it's it's"
    },
    {
      "start": 2031.44,
      "duration": 3.359,
      "text": "actually different computationally can"
    },
    {
      "start": 2033.2,
      "duration": 3.359,
      "text": "you explain that"
    },
    {
      "start": 2034.799,
      "duration": 4.88,
      "text": ">> yes I think the boundary in terms of"
    },
    {
      "start": 2036.559,
      "duration": 5.201,
      "text": "computation from a a cheering machine"
    },
    {
      "start": 2039.679,
      "duration": 5.201,
      "text": "perspective if you wish uh is really"
    },
    {
      "start": 2041.76,
      "duration": 4.96,
      "text": "interesting because the notion of being"
    },
    {
      "start": 2044.88,
      "duration": 3.279,
      "text": "able to write your tape uh read from a"
    },
    {
      "start": 2046.72,
      "duration": 4.08,
      "text": "tape and then write again to be in a"
    },
    {
      "start": 2048.159,
      "duration": 6,
      "text": "Ting compute system ting complete system"
    },
    {
      "start": 2050.8,
      "duration": 7.039,
      "text": "is uh obviously an incredible idea that"
    },
    {
      "start": 2054.159,
      "duration": 5.841,
      "text": "has completely changed the world and I"
    },
    {
      "start": 2057.839,
      "duration": 3.921,
      "text": "think the primary difference with let's"
    },
    {
      "start": 2060,
      "duration": 4.159,
      "text": "talk about transformers versus what"
    },
    {
      "start": 2061.76,
      "duration": 5.76,
      "text": "we're trying to do with the CTM"
    },
    {
      "start": 2064.159,
      "duration": 5.361,
      "text": "is that the process that the CTM thinks"
    },
    {
      "start": 2067.52,
      "duration": 4.96,
      "text": "in we can apply that process that"
    },
    {
      "start": 2069.52,
      "duration": 4.96,
      "text": "internal process to uh breaking down a"
    },
    {
      "start": 2072.48,
      "duration": 4.32,
      "text": "problem. So the problem itself can be a"
    },
    {
      "start": 2074.48,
      "duration": 4.159,
      "text": "single there is a single solution to"
    },
    {
      "start": 2076.8,
      "duration": 4,
      "text": "this problem and you could do that in"
    },
    {
      "start": 2078.639,
      "duration": 3.601,
      "text": "one shot. You could as I explained with"
    },
    {
      "start": 2080.8,
      "duration": 3.44,
      "text": "the maze you could just process that in"
    },
    {
      "start": 2082.24,
      "duration": 4.96,
      "text": "one shot but there are certain phrasings"
    },
    {
      "start": 2084.24,
      "duration": 5.28,
      "text": "of problems that are real problems that"
    },
    {
      "start": 2087.2,
      "duration": 4.719,
      "text": "doing so becomes exponentially more"
    },
    {
      "start": 2089.52,
      "duration": 4.8,
      "text": "challenging. So in the maze task, a"
    },
    {
      "start": 2091.919,
      "duration": 5.841,
      "text": "really good example is that if you try"
    },
    {
      "start": 2094.32,
      "duration": 5.84,
      "text": "to predict 100 200 steps down the path"
    },
    {
      "start": 2097.76,
      "duration": 4.48,
      "text": "in one shot, no models that we could"
    },
    {
      "start": 2100.16,
      "duration": 3.52,
      "text": "train, not even our model could do that."
    },
    {
      "start": 2102.24,
      "duration": 3.28,
      "text": "And we needed to actually build an"
    },
    {
      "start": 2103.68,
      "duration": 3.439,
      "text": "autocurriculum system where the model"
    },
    {
      "start": 2105.52,
      "duration": 3.12,
      "text": "first predicted the first step and then"
    },
    {
      "start": 2107.119,
      "duration": 3.441,
      "text": "when it could predict the first step,"
    },
    {
      "start": 2108.64,
      "duration": 3.6,
      "text": "then it we started training it on the"
    },
    {
      "start": 2110.56,
      "duration": 3.76,
      "text": "second and third and fourth step. And"
    },
    {
      "start": 2112.24,
      "duration": 5.119,
      "text": "the sort of resultant behavior of this"
    },
    {
      "start": 2114.32,
      "duration": 4.48,
      "text": "is where it gets interesting. One of the"
    },
    {
      "start": 2117.359,
      "duration": 3.201,
      "text": "one of the ways that I like to do"
    },
    {
      "start": 2118.8,
      "duration": 4.08,
      "text": "research and that I encourage people who"
    },
    {
      "start": 2120.56,
      "duration": 5.12,
      "text": "work with me to do research is"
    },
    {
      "start": 2122.88,
      "duration": 5.04,
      "text": "understand the if you wish the behavior"
    },
    {
      "start": 2125.68,
      "duration": 5.04,
      "text": "of a model. We're getting to a point now"
    },
    {
      "start": 2127.92,
      "duration": 4.64,
      "text": "where the models that we build are"
    },
    {
      "start": 2130.72,
      "duration": 4.8,
      "text": "demonstrably intelligent in ways that"
    },
    {
      "start": 2132.56,
      "duration": 6.16,
      "text": "keep surprising us and breaking that"
    },
    {
      "start": 2135.52,
      "duration": 5.36,
      "text": "down into a single set of metrics or"
    },
    {
      "start": 2138.72,
      "duration": 5.04,
      "text": "even a finite single metric about"
    },
    {
      "start": 2140.88,
      "duration": 4.479,
      "text": "performance seems maybe not to be the"
    },
    {
      "start": 2143.76,
      "duration": 3.839,
      "text": "right way to do it for me. and"
    },
    {
      "start": 2145.359,
      "duration": 3.921,
      "text": "understanding the behavior and the"
    },
    {
      "start": 2147.599,
      "duration": 3.361,
      "text": "actions that those models take when you"
    },
    {
      "start": 2149.28,
      "duration": 4.64,
      "text": "put them in a system and train them in a"
    },
    {
      "start": 2150.96,
      "duration": 4.56,
      "text": "certain way uh seems to reveal more"
    },
    {
      "start": 2153.92,
      "duration": 2,
      "text": "about what's actually going on under the"
    },
    {
      "start": 2155.52,
      "duration": 1.839,
      "text": "hood."
    },
    {
      "start": 2155.92,
      "duration": 3.04,
      "text": ">> Very cool. And I think I didn't pick up"
    },
    {
      "start": 2157.359,
      "duration": 4.48,
      "text": "on this. So So you're you're doing a"
    },
    {
      "start": 2158.96,
      "duration": 5.52,
      "text": "fixed number of um steps so you have"
    },
    {
      "start": 2161.839,
      "duration": 5.52,
      "text": "like a a context window and did you say"
    },
    {
      "start": 2164.48,
      "duration": 5.2,
      "text": "that you've set that around 100 steps?"
    },
    {
      "start": 2167.359,
      "duration": 4.48,
      "text": ">> So for the for the maze task uh the"
    },
    {
      "start": 2169.68,
      "duration": 4.64,
      "text": "model always observes the full image at"
    },
    {
      "start": 2171.839,
      "duration": 4.801,
      "text": "every step. uh the CTM will absorb"
    },
    {
      "start": 2174.32,
      "duration": 3.92,
      "text": "observe the full image for argument sake"
    },
    {
      "start": 2176.64,
      "duration": 3.439,
      "text": "those images could be tokens from a"
    },
    {
      "start": 2178.24,
      "duration": 4.32,
      "text": "language uh the output of a language"
    },
    {
      "start": 2180.079,
      "duration": 4.241,
      "text": "model those uh inputs could be numbers"
    },
    {
      "start": 2182.56,
      "duration": 3.36,
      "text": "that the model has to sort whatever the"
    },
    {
      "start": 2184.32,
      "duration": 3.36,
      "text": "case may be it should be agnostic to"
    },
    {
      "start": 2185.92,
      "duration": 4.72,
      "text": "data that's how we've tried to build it"
    },
    {
      "start": 2187.68,
      "duration": 5.76,
      "text": "but in the maze task the model can"
    },
    {
      "start": 2190.64,
      "duration": 4.32,
      "text": "continuously just observe the data uh no"
    },
    {
      "start": 2193.44,
      "duration": 3.12,
      "text": "matter where it can look at the whole"
    },
    {
      "start": 2194.96,
      "duration": 4,
      "text": "image simultaneously but it uses"
    },
    {
      "start": 2196.56,
      "duration": 6.16,
      "text": "attention to retrieve information from"
    },
    {
      "start": 2198.96,
      "duration": 6.08,
      "text": "the data and it has let's call it 100"
    },
    {
      "start": 2202.72,
      "duration": 5.119,
      "text": "steps that it can think through. And"
    },
    {
      "start": 2205.04,
      "duration": 5.28,
      "text": "what we do is we pick up at some point"
    },
    {
      "start": 2207.839,
      "duration": 4.24,
      "text": "the model solves three steps through the"
    },
    {
      "start": 2210.32,
      "duration": 3.12,
      "text": "maze. So it says I'm going to go up, up,"
    },
    {
      "start": 2212.079,
      "duration": 3.201,
      "text": "and right. And then it's correct. But"
    },
    {
      "start": 2213.44,
      "duration": 4,
      "text": "then it makes the wrong turn. And at"
    },
    {
      "start": 2215.28,
      "duration": 4.4,
      "text": "that point, we stop supervision. We only"
    },
    {
      "start": 2217.44,
      "duration": 3.84,
      "text": "train it to solve the fourth step. So"
    },
    {
      "start": 2219.68,
      "duration": 3.2,
      "text": "one more than what it could. In"
    },
    {
      "start": 2221.28,
      "duration": 3.68,
      "text": "practice, we do it five, but the"
    },
    {
      "start": 2222.88,
      "duration": 4.4,
      "text": "principle holds. And when you do that,"
    },
    {
      "start": 2224.96,
      "duration": 4.879,
      "text": "it's a self bootstrapping mechanism. And"
    },
    {
      "start": 2227.28,
      "duration": 4.079,
      "text": "I think the uh intuitive listener will"
    },
    {
      "start": 2229.839,
      "duration": 3.76,
      "text": "understand how that extends to other"
    },
    {
      "start": 2231.359,
      "duration": 4.48,
      "text": "domains, other sequential domains for"
    },
    {
      "start": 2233.599,
      "duration": 5.52,
      "text": "instance like uh language prediction,"
    },
    {
      "start": 2235.839,
      "duration": 5.121,
      "text": "many tokens ahead, that sort of thing."
    },
    {
      "start": 2239.119,
      "duration": 4.801,
      "text": ">> So I'm really interested in this idea of"
    },
    {
      "start": 2240.96,
      "duration": 5.44,
      "text": "adaptive computation. So I I guess the"
    },
    {
      "start": 2243.92,
      "duration": 4.88,
      "text": "first question is how sensitive was the"
    },
    {
      "start": 2246.4,
      "duration": 4.4,
      "text": "performance to the number of steps and"
    },
    {
      "start": 2248.8,
      "duration": 4.559,
      "text": "then the next question would be could"
    },
    {
      "start": 2250.8,
      "duration": 4,
      "text": "you have an arbitrary number of steps"
    },
    {
      "start": 2253.359,
      "duration": 3.681,
      "text": "which means that you know perhaps based"
    },
    {
      "start": 2254.8,
      "duration": 5.039,
      "text": "on uncertainty or you know some kind of"
    },
    {
      "start": 2257.04,
      "duration": 4.88,
      "text": "criterion you could do fewer steps and"
    },
    {
      "start": 2259.839,
      "duration": 4.641,
      "text": "then the final question is could you"
    },
    {
      "start": 2261.92,
      "duration": 4.4,
      "text": "have potentially like an arbitrary or"
    },
    {
      "start": 2264.48,
      "duration": 4.32,
      "text": "unbounded number of steps"
    },
    {
      "start": 2266.32,
      "duration": 4.24,
      "text": ">> yeah uh really super question I think"
    },
    {
      "start": 2268.8,
      "duration": 3.68,
      "text": "that"
    },
    {
      "start": 2270.56,
      "duration": 3.92,
      "text": "I think that I'll answer the uncertainty"
    },
    {
      "start": 2272.48,
      "duration": 3.76,
      "text": "question first about the sensitivity to"
    },
    {
      "start": 2274.48,
      "duration": 3.599,
      "text": "steps. So a very good example of this is"
    },
    {
      "start": 2276.24,
      "duration": 4.16,
      "text": "we just trained the model on imageet"
    },
    {
      "start": 2278.079,
      "duration": 4.081,
      "text": "classification and our last function is"
    },
    {
      "start": 2280.4,
      "duration": 5.04,
      "text": "quite simple. What we do is we run it"
    },
    {
      "start": 2282.16,
      "duration": 5.04,
      "text": "for for example 50 steps and we pick up"
    },
    {
      "start": 2285.44,
      "duration": 3.52,
      "text": "two points two distinct points. The"
    },
    {
      "start": 2287.2,
      "duration": 4.48,
      "text": "first one is where is it performing the"
    },
    {
      "start": 2288.96,
      "duration": 4.56,
      "text": "best i.e. where is the loss the lowest"
    },
    {
      "start": 2291.68,
      "duration": 4.56,
      "text": "and the second one is where is it most"
    },
    {
      "start": 2293.52,
      "duration": 5.12,
      "text": "sure or where is it most certain and"
    },
    {
      "start": 2296.24,
      "duration": 5.52,
      "text": "those give us two indices uh between 0"
    },
    {
      "start": 2298.64,
      "duration": 6,
      "text": "and 49 inclusive and we apply cross"
    },
    {
      "start": 2301.76,
      "duration": 4.4,
      "text": "entropy at both of those points we just"
    },
    {
      "start": 2304.64,
      "duration": 3.439,
      "text": "make the last the average of the cross"
    },
    {
      "start": 2306.16,
      "duration": 4.16,
      "text": "entropy at those points. So what this"
    },
    {
      "start": 2308.079,
      "duration": 4.641,
      "text": "does is it induces a behavior where easy"
    },
    {
      "start": 2310.32,
      "duration": 4.32,
      "text": "examples are solved almost immediately"
    },
    {
      "start": 2312.72,
      "duration": 3.84,
      "text": "in one or two steps whereas more"
    },
    {
      "start": 2314.64,
      "duration": 4.08,
      "text": "challenging examples will naturally take"
    },
    {
      "start": 2316.56,
      "duration": 4.72,
      "text": "more thinking and it enables the model"
    },
    {
      "start": 2318.72,
      "duration": 4.399,
      "text": "to use the full breadth of time that it"
    },
    {
      "start": 2321.28,
      "duration": 3.44,
      "text": "has available to it just in a natural"
    },
    {
      "start": 2323.119,
      "duration": 4.24,
      "text": "fashion without having to force it to"
    },
    {
      "start": 2324.72,
      "duration": 4.72,
      "text": "happen. So you've decided to model every"
    },
    {
      "start": 2327.359,
      "duration": 4,
      "text": "neuron as an MLP which is really"
    },
    {
      "start": 2329.44,
      "duration": 4.08,
      "text": "fascinating. Talk about that but also"
    },
    {
      "start": 2331.359,
      "duration": 4.321,
      "text": "there's this notion of synchronization"
    },
    {
      "start": 2333.52,
      "duration": 4,
      "text": "and I think you use the inner product to"
    },
    {
      "start": 2335.68,
      "duration": 4.08,
      "text": "determine the extent to which the"
    },
    {
      "start": 2337.52,
      "duration": 4.4,
      "text": "parameters are are synchronized and this"
    },
    {
      "start": 2339.76,
      "duration": 3.92,
      "text": "kind of unfills over over time as as the"
    },
    {
      "start": 2341.92,
      "duration": 2.56,
      "text": "driving force. Can you explain that in a"
    },
    {
      "start": 2343.68,
      "duration": 3.12,
      "text": "bit more detail?"
    },
    {
      "start": 2344.48,
      "duration": 4.639,
      "text": ">> Absolutely. I think it's a it's a good"
    },
    {
      "start": 2346.8,
      "duration": 3.92,
      "text": "point to explain the uh neuron level"
    },
    {
      "start": 2349.119,
      "duration": 5.441,
      "text": "models as we call them in the paper or"
    },
    {
      "start": 2350.72,
      "duration": 5.92,
      "text": "NLM first because it ties into this. So"
    },
    {
      "start": 2354.56,
      "duration": 4.799,
      "text": "you can imagine a recurrent system is a"
    },
    {
      "start": 2356.64,
      "duration": 4.719,
      "text": "state vector, a state vector that is"
    },
    {
      "start": 2359.359,
      "duration": 4.401,
      "text": "being updated from step to step. We"
    },
    {
      "start": 2361.359,
      "duration": 4.72,
      "text": "track that state vector and that state"
    },
    {
      "start": 2363.76,
      "duration": 6.8,
      "text": "vector unfolds and for each individual"
    },
    {
      "start": 2366.079,
      "duration": 7.681,
      "text": "neuron, each uh I neuron in the system,"
    },
    {
      "start": 2370.56,
      "duration": 4.88,
      "text": "we have a unfolding time series. It's a"
    },
    {
      "start": 2373.76,
      "duration": 4.24,
      "text": "continuous time series. Well, it's"
    },
    {
      "start": 2375.44,
      "duration": 4.639,
      "text": "discreet, but it's a continuous value."
    },
    {
      "start": 2378,
      "duration": 4.48,
      "text": "And those time series define what we"
    },
    {
      "start": 2380.079,
      "duration": 4.481,
      "text": "call the activations over time. And"
    },
    {
      "start": 2382.48,
      "duration": 4.08,
      "text": "synchronization is quite simply just"
    },
    {
      "start": 2384.56,
      "duration": 4.32,
      "text": "measuring the dotproduct between two of"
    },
    {
      "start": 2386.56,
      "duration": 6,
      "text": "these time series. So you have a system"
    },
    {
      "start": 2388.88,
      "duration": 6.16,
      "text": "of d neurons and essentially you have d"
    },
    {
      "start": 2392.56,
      "duration": 5.2,
      "text": "over two squared different"
    },
    {
      "start": 2395.04,
      "duration": 4.4,
      "text": "synchronization pairs. So neuron one can"
    },
    {
      "start": 2397.76,
      "duration": 3.52,
      "text": "be related to neuron 2 by how they"
    },
    {
      "start": 2399.44,
      "duration": 5.36,
      "text": "synchronize and neuron one can also be"
    },
    {
      "start": 2401.28,
      "duration": 5.68,
      "text": "related to neuron 3 etc etc. The neuron"
    },
    {
      "start": 2404.8,
      "duration": 6.08,
      "text": "level models they function by taking in"
    },
    {
      "start": 2406.96,
      "duration": 5.84,
      "text": "a finite history like a FOQ of neuron of"
    },
    {
      "start": 2410.88,
      "duration": 4.16,
      "text": "activations coming in and instead of"
    },
    {
      "start": 2412.8,
      "duration": 5.52,
      "text": "being just a radio activation they use"
    },
    {
      "start": 2415.04,
      "duration": 6.079,
      "text": "that history as information to uh"
    },
    {
      "start": 2418.32,
      "duration": 4.32,
      "text": "process a single activation out and that"
    },
    {
      "start": 2421.119,
      "duration": 4.72,
      "text": "is what moves from what we call"
    },
    {
      "start": 2422.64,
      "duration": 5.68,
      "text": "pre-activations to post activations. And"
    },
    {
      "start": 2425.839,
      "duration": 4.321,
      "text": "the principle here is that this might"
    },
    {
      "start": 2428.32,
      "duration": 4,
      "text": "seem rather arbitrary and does it help"
    },
    {
      "start": 2430.16,
      "duration": 4.32,
      "text": "for performance? Turns out it does, but"
    },
    {
      "start": 2432.32,
      "duration": 4.16,
      "text": "that's not really the catch all solution"
    },
    {
      "start": 2434.48,
      "duration": 3.44,
      "text": "here. That's not what we're after. Uh"
    },
    {
      "start": 2436.48,
      "duration": 4.639,
      "text": "what we're after here is trying to do"
    },
    {
      "start": 2437.92,
      "duration": 5.919,
      "text": "something biologically plausible. Uh"
    },
    {
      "start": 2441.119,
      "duration": 4.161,
      "text": "find the line somewhere between biology,"
    },
    {
      "start": 2443.839,
      "duration": 3.76,
      "text": "which is how the brain implements things"
    },
    {
      "start": 2445.28,
      "duration": 4.319,
      "text": "in the biological substrate that we have"
    },
    {
      "start": 2447.599,
      "duration": 4.561,
      "text": "versus deep learning, which is highly"
    },
    {
      "start": 2449.599,
      "duration": 4.24,
      "text": "parallelizable, super fast to learn,"
    },
    {
      "start": 2452.16,
      "duration": 3.12,
      "text": "back propanable, all of the nice"
    },
    {
      "start": 2453.839,
      "duration": 3.681,
      "text": "properties of that that have got us this"
    },
    {
      "start": 2455.28,
      "duration": 3.839,
      "text": "far. and find a line somewhere where we"
    },
    {
      "start": 2457.52,
      "duration": 3.52,
      "text": "can take some sprinkling of biological"
    },
    {
      "start": 2459.119,
      "duration": 3.601,
      "text": "inspiration but still train it with deep"
    },
    {
      "start": 2461.04,
      "duration": 3.92,
      "text": "learning. And it turns out that neuron"
    },
    {
      "start": 2462.72,
      "duration": 4.72,
      "text": "level models is a nice interim that we"
    },
    {
      "start": 2464.96,
      "duration": 4.32,
      "text": "can do this with. The concept of"
    },
    {
      "start": 2467.44,
      "duration": 4.48,
      "text": "synchronization is applied on top of the"
    },
    {
      "start": 2469.28,
      "duration": 4.559,
      "text": "outputs of those neuron level models. So"
    },
    {
      "start": 2471.92,
      "duration": 5.28,
      "text": "on on this on the scaling the I think"
    },
    {
      "start": 2473.839,
      "duration": 5.041,
      "text": "the time complexity is quadratic in"
    },
    {
      "start": 2477.2,
      "duration": 4.159,
      "text": "respect of the dimension of the"
    },
    {
      "start": 2478.88,
      "duration": 4.16,
      "text": "synchronization matrix right and in your"
    },
    {
      "start": 2481.359,
      "duration": 3.841,
      "text": "paper you were talking about subsampling"
    },
    {
      "start": 2483.04,
      "duration": 4.72,
      "text": "to improve the performance but how how"
    },
    {
      "start": 2485.2,
      "duration": 4.159,
      "text": "did that affect the the stability and"
    },
    {
      "start": 2487.76,
      "duration": 3.599,
      "text": "the you know like were there any things"
    },
    {
      "start": 2489.359,
      "duration": 3.201,
      "text": "that that cost you doing that? Yeah,"
    },
    {
      "start": 2491.359,
      "duration": 3.441,
      "text": "it's a neat question. I think in terms"
    },
    {
      "start": 2492.56,
      "duration": 3.36,
      "text": "of stability, what's what we found was"
    },
    {
      "start": 2494.8,
      "duration": 3.36,
      "text": "kind of fun and this was a sentiment"
    },
    {
      "start": 2495.92,
      "duration": 4.24,
      "text": "that we had throughout the the"
    },
    {
      "start": 2498.16,
      "duration": 4.64,
      "text": "experiments that we ran with this paper"
    },
    {
      "start": 2500.16,
      "duration": 4.88,
      "text": "was it tended no matter what we tried it"
    },
    {
      "start": 2502.8,
      "duration": 4.64,
      "text": "on it it just kind of worked with all"
    },
    {
      "start": 2505.04,
      "duration": 3.84,
      "text": "spreads of hyperparameters. uh and this"
    },
    {
      "start": 2507.44,
      "duration": 2.96,
      "text": "the problems that you have with back"
    },
    {
      "start": 2508.88,
      "duration": 4.16,
      "text": "prop through time typically with"
    },
    {
      "start": 2510.4,
      "duration": 4.48,
      "text": "recurrence models like RNNs and LSTMs"
    },
    {
      "start": 2513.04,
      "duration": 3.279,
      "text": "it's a challenge and you run for many"
    },
    {
      "start": 2514.88,
      "duration": 3.84,
      "text": "internal ticks with the RNNs or the"
    },
    {
      "start": 2516.319,
      "duration": 5.121,
      "text": "LSTMs and the learning seems to break"
    },
    {
      "start": 2518.72,
      "duration": 4.639,
      "text": "down but the uh fact that we use"
    },
    {
      "start": 2521.44,
      "duration": 3.36,
      "text": "synchronization in some sense touches"
    },
    {
      "start": 2523.359,
      "duration": 3.361,
      "text": "all of the neurons through all of the"
    },
    {
      "start": 2524.8,
      "duration": 4.4,
      "text": "time so it really helps with gradient"
    },
    {
      "start": 2526.72,
      "duration": 4.32,
      "text": "propagation uh a nice interesting point"
    },
    {
      "start": 2529.2,
      "duration": 4.56,
      "text": "that's maybe a bit oblique to what you"
    },
    {
      "start": 2531.04,
      "duration": 4.48,
      "text": "asked about synchronization is we have a"
    },
    {
      "start": 2533.76,
      "duration": 2.88,
      "text": "system of d neurons and like I said"
    },
    {
      "start": 2535.52,
      "duration": 2.96,
      "text": "earlier there"
    },
    {
      "start": 2536.64,
      "duration": 3.36,
      "text": "d over two squared possible"
    },
    {
      "start": 2538.48,
      "duration": 3.359,
      "text": "combinations."
    },
    {
      "start": 2540,
      "duration": 3.68,
      "text": "This essentially means that our"
    },
    {
      "start": 2541.839,
      "duration": 4.401,
      "text": "underlying state or underlying"
    },
    {
      "start": 2543.68,
      "duration": 4.399,
      "text": "representation to the system is quite a"
    },
    {
      "start": 2546.24,
      "duration": 4.32,
      "text": "lot larger than what you would get with"
    },
    {
      "start": 2548.079,
      "duration": 4.24,
      "text": "just taking those D neurons. And as to"
    },
    {
      "start": 2550.56,
      "duration": 3.2,
      "text": "what that means in terms of downstream"
    },
    {
      "start": 2552.319,
      "duration": 3.201,
      "text": "computation and performance and the"
    },
    {
      "start": 2553.76,
      "duration": 3.359,
      "text": "things that we can do with this is what"
    },
    {
      "start": 2555.52,
      "duration": 4.48,
      "text": "we're actively exploring right now."
    },
    {
      "start": 2557.119,
      "duration": 4.48,
      "text": ">> You guys used an exponential decay rate."
    },
    {
      "start": 2560,
      "duration": 4.88,
      "text": ">> You have the system that unfolds over"
    },
    {
      "start": 2561.599,
      "duration": 6.081,
      "text": "time. it would be maybe a little bit too"
    },
    {
      "start": 2564.88,
      "duration": 4.719,
      "text": "constrained if the synchronization"
    },
    {
      "start": 2567.68,
      "duration": 4.88,
      "text": "between any two neurons depended on the"
    },
    {
      "start": 2569.599,
      "duration": 4.161,
      "text": "same time scale. So for instance, there"
    },
    {
      "start": 2572.56,
      "duration": 3.12,
      "text": "are neurons in your brain that are"
    },
    {
      "start": 2573.76,
      "duration": 3.76,
      "text": "firing over very long time scales and"
    },
    {
      "start": 2575.68,
      "duration": 4.32,
      "text": "very short time scales. The way that"
    },
    {
      "start": 2577.52,
      "duration": 4.48,
      "text": "they fire together impacts other neurons"
    },
    {
      "start": 2580,
      "duration": 3.839,
      "text": "and causes those neurons to fire. But"
    },
    {
      "start": 2582,
      "duration": 4.4,
      "text": "everything in biological brains happens"
    },
    {
      "start": 2583.839,
      "duration": 5.041,
      "text": "at diverse time scales. It's why we have"
    },
    {
      "start": 2586.4,
      "duration": 5.28,
      "text": "uh different brain waves for different"
    },
    {
      "start": 2588.88,
      "duration": 4.56,
      "text": "thinking states for instance. Uh but"
    },
    {
      "start": 2591.68,
      "duration": 4.159,
      "text": "beside that point, what we do with the"
    },
    {
      "start": 2593.44,
      "duration": 4.879,
      "text": "exponential decay in the continuous"
    },
    {
      "start": 2595.839,
      "duration": 4.24,
      "text": "thought machines is it allows us for a"
    },
    {
      "start": 2598.319,
      "duration": 3.841,
      "text": "very sharp decay to say that these two"
    },
    {
      "start": 2600.079,
      "duration": 4.161,
      "text": "neurons that are pairing together, what"
    },
    {
      "start": 2602.16,
      "duration": 4.159,
      "text": "only really matters is how they fire"
    },
    {
      "start": 2604.24,
      "duration": 4.16,
      "text": "together right now. Right? But if we had"
    },
    {
      "start": 2606.319,
      "duration": 3.841,
      "text": "a very long and slow decay, essentially"
    },
    {
      "start": 2608.4,
      "duration": 3.199,
      "text": "that's capturing a global sense of how"
    },
    {
      "start": 2610.16,
      "duration": 3.84,
      "text": "those neurons are firing over an"
    },
    {
      "start": 2611.599,
      "duration": 5.76,
      "text": "extremely long period of time. So this"
    },
    {
      "start": 2614,
      "duration": 6.64,
      "text": "was essentially a way of us uh capturing"
    },
    {
      "start": 2617.359,
      "duration": 4.96,
      "text": "this idea of how different neurons could"
    },
    {
      "start": 2620.64,
      "duration": 3.6,
      "text": "maybe fire together very quickly and"
    },
    {
      "start": 2622.319,
      "duration": 4.641,
      "text": "other neurons can fire together very"
    },
    {
      "start": 2624.24,
      "duration": 4.4,
      "text": "slowly or not at all. And this lets that"
    },
    {
      "start": 2626.96,
      "duration": 4.24,
      "text": "representation space that I spoke about"
    },
    {
      "start": 2628.64,
      "duration": 4.719,
      "text": "that D over2 squ representation space"
    },
    {
      "start": 2631.2,
      "duration": 4.48,
      "text": "lets it again become more rich and we"
    },
    {
      "start": 2633.359,
      "duration": 3.681,
      "text": "can enrich that space with more subtle"
    },
    {
      "start": 2635.68,
      "duration": 2.88,
      "text": "tweaks to how we compute those"
    },
    {
      "start": 2637.04,
      "duration": 2.559,
      "text": "representations."
    },
    {
      "start": 2638.56,
      "duration": 3.6,
      "text": "So we were speaking about this"
    },
    {
      "start": 2639.599,
      "duration": 4.561,
      "text": "yesterday, Luke, that um when folks"
    },
    {
      "start": 2642.16,
      "duration": 3.28,
      "text": "apply transformers to things like the"
    },
    {
      "start": 2644.16,
      "duration": 3.439,
      "text": "ARC challenge or things that need"
    },
    {
      "start": 2645.44,
      "duration": 4.24,
      "text": "reasoning. Um we need to do lots of"
    },
    {
      "start": 2647.599,
      "duration": 3.76,
      "text": "domain specific hacks. So the architects"
    },
    {
      "start": 2649.68,
      "duration": 3.84,
      "text": "who were the winners of last year's"
    },
    {
      "start": 2651.359,
      "duration": 4.561,
      "text": "challenge, they did um depth first"
    },
    {
      "start": 2653.52,
      "duration": 4.079,
      "text": "search sampling and some folks have been"
    },
    {
      "start": 2655.92,
      "duration": 3.76,
      "text": "experimenting with using language"
    },
    {
      "start": 2657.599,
      "duration": 5.601,
      "text": "representations or you know using um"
    },
    {
      "start": 2659.68,
      "duration": 6.32,
      "text": "DSLs and some part of this is to do with"
    },
    {
      "start": 2663.2,
      "duration": 5.04,
      "text": "the the the reachability um of language"
    },
    {
      "start": 2666,
      "duration": 3.04,
      "text": "right and and language is is quite dense"
    },
    {
      "start": 2668.24,
      "duration": 3.28,
      "text": "which means you can kind of"
    },
    {
      "start": 2669.04,
      "duration": 4.319,
      "text": "monotonically um increase but if I"
    },
    {
      "start": 2671.52,
      "duration": 3.28,
      "text": "understand correctly your system might"
    },
    {
      "start": 2673.359,
      "duration": 3.601,
      "text": "have some interesting properties for"
    },
    {
      "start": 2674.8,
      "duration": 4.64,
      "text": "reasoning and for discrete and sparse"
    },
    {
      "start": 2676.96,
      "duration": 3.76,
      "text": "domains and also for sample efficiency"
    },
    {
      "start": 2679.44,
      "duration": 3.36,
      "text": "because we want we want to build a"
    },
    {
      "start": 2680.72,
      "duration": 4,
      "text": "system that can actually do well on"
    },
    {
      "start": 2682.8,
      "duration": 3.84,
      "text": "things like the arc challenge. But can"
    },
    {
      "start": 2684.72,
      "duration": 4.639,
      "text": "you kind of explain in simple terms why"
    },
    {
      "start": 2686.64,
      "duration": 4.4,
      "text": "you think this architecture could be"
    },
    {
      "start": 2689.359,
      "duration": 2.72,
      "text": "significantly better than transformers"
    },
    {
      "start": 2691.04,
      "duration": 3.12,
      "text": "for doing those things?"
    },
    {
      "start": 2692.079,
      "duration": 3.76,
      "text": ">> I think a lot of the really fascinating"
    },
    {
      "start": 2694.16,
      "duration": 3.84,
      "text": "work in the last few years that I found"
    },
    {
      "start": 2695.839,
      "duration": 4.961,
      "text": "fascinating in the literature of"
    },
    {
      "start": 2698,
      "duration": 4.72,
      "text": "language models has been related to what"
    },
    {
      "start": 2700.8,
      "duration": 4.96,
      "text": "one can actually call a new scaling"
    },
    {
      "start": 2702.72,
      "duration": 5.76,
      "text": "dimension. I in some sense see continue"
    },
    {
      "start": 2705.76,
      "duration": 5.04,
      "text": "uh chain of thought reasoning as a way"
    },
    {
      "start": 2708.48,
      "duration": 4.8,
      "text": "of adding more compute to a system."
    },
    {
      "start": 2710.8,
      "duration": 3.92,
      "text": "That's obviously just one small part of"
    },
    {
      "start": 2713.28,
      "duration": 3.28,
      "text": "what that really is and what that really"
    },
    {
      "start": 2714.72,
      "duration": 4.96,
      "text": "means. But I think it's quite a profound"
    },
    {
      "start": 2716.56,
      "duration": 5.6,
      "text": "breakthrough uh in some sense. Now what"
    },
    {
      "start": 2719.68,
      "duration": 5.439,
      "text": "we're trying to do is is have that"
    },
    {
      "start": 2722.16,
      "duration": 5.36,
      "text": "reasoning component be entirely internal"
    },
    {
      "start": 2725.119,
      "duration": 4.881,
      "text": "yet still running in some sort of"
    },
    {
      "start": 2727.52,
      "duration": 4.559,
      "text": "sequential manner. And I think that"
    },
    {
      "start": 2730,
      "duration": 5.28,
      "text": "that's rather important. And you spoke"
    },
    {
      "start": 2732.079,
      "duration": 4.881,
      "text": "earlier about Gemini's diffusion"
    },
    {
      "start": 2735.28,
      "duration": 2.88,
      "text": "language modeling and I think that there"
    },
    {
      "start": 2736.96,
      "duration": 3.52,
      "text": "are a lot of different directions that"
    },
    {
      "start": 2738.16,
      "duration": 3.52,
      "text": "are exploring this right now. uh I do"
    },
    {
      "start": 2740.48,
      "duration": 2.96,
      "text": "think that the continuous thought"
    },
    {
      "start": 2741.68,
      "duration": 3.919,
      "text": "machine with the ideas of"
    },
    {
      "start": 2743.44,
      "duration": 5.28,
      "text": "synchronization and multi-hierarchical"
    },
    {
      "start": 2745.599,
      "duration": 5.681,
      "text": "temporal representations gives a certain"
    },
    {
      "start": 2748.72,
      "duration": 5.2,
      "text": "flexibility on that space that uh other"
    },
    {
      "start": 2751.28,
      "duration": 4.48,
      "text": "people are not yet exploring and that"
    },
    {
      "start": 2753.92,
      "duration": 3.84,
      "text": "richness of that space being able to"
    },
    {
      "start": 2755.76,
      "duration": 4.48,
      "text": "project the next step to solve the arc"
    },
    {
      "start": 2757.76,
      "duration": 4.559,
      "text": "challenge and the next 100 the next 200"
    },
    {
      "start": 2760.24,
      "duration": 5.2,
      "text": "steps to be able to break that down into"
    },
    {
      "start": 2762.319,
      "duration": 5.681,
      "text": "a process that a model can then uh very"
    },
    {
      "start": 2765.44,
      "duration": 5.12,
      "text": "quickly search that process in its"
    },
    {
      "start": 2768,
      "duration": 4.319,
      "text": "highdimensional latent case becomes"
    },
    {
      "start": 2770.56,
      "duration": 2.799,
      "text": "something that feels like a good"
    },
    {
      "start": 2772.319,
      "duration": 2.961,
      "text": "approach to take."
    },
    {
      "start": 2773.359,
      "duration": 4.48,
      "text": ">> Do you see any relationship between this"
    },
    {
      "start": 2775.28,
      "duration": 4.64,
      "text": "architecture and you know Alex Graves"
    },
    {
      "start": 2777.839,
      "duration": 5.441,
      "text": "neuro touring machine?"
    },
    {
      "start": 2779.92,
      "duration": 6,
      "text": ">> Yes, that's really interesting. Um I do."
    },
    {
      "start": 2783.28,
      "duration": 4.88,
      "text": "I think that the one of the the most"
    },
    {
      "start": 2785.92,
      "duration": 4.88,
      "text": "challenging parts about uh working with"
    },
    {
      "start": 2788.16,
      "duration": 4.24,
      "text": "a neural neural touring machine is the"
    },
    {
      "start": 2790.8,
      "duration": 3.44,
      "text": "concept of writing to memory and reading"
    },
    {
      "start": 2792.4,
      "duration": 6,
      "text": "to memory because it is a discrete"
    },
    {
      "start": 2794.24,
      "duration": 7.76,
      "text": "action. Um and that's that has its own"
    },
    {
      "start": 2798.4,
      "duration": 6.56,
      "text": "challenges associated with it and"
    },
    {
      "start": 2802,
      "duration": 4.88,
      "text": "yes uh I wouldn't go so far as to say"
    },
    {
      "start": 2804.96,
      "duration": 4.72,
      "text": "that the continuous thought machine is"
    },
    {
      "start": 2806.88,
      "duration": 5.28,
      "text": "definitively nearing Tur incomplete but"
    },
    {
      "start": 2809.68,
      "duration": 5.52,
      "text": "the notion of [clears throat] the notion"
    },
    {
      "start": 2812.16,
      "duration": 5.52,
      "text": "of doing reasoning in a space that is uh"
    },
    {
      "start": 2815.2,
      "duration": 5.28,
      "text": "latent and letting that space unfold in"
    },
    {
      "start": 2817.68,
      "duration": 5.04,
      "text": "a way that is uh rich towards a"
    },
    {
      "start": 2820.48,
      "duration": 4.24,
      "text": "different set of tasks. And this this"
    },
    {
      "start": 2822.72,
      "duration": 3.92,
      "text": "actually brings me to a point that I"
    },
    {
      "start": 2824.72,
      "duration": 3.92,
      "text": "find quite interesting um that I'd like"
    },
    {
      "start": 2826.64,
      "duration": 4.479,
      "text": "to share with you. Consider again the"
    },
    {
      "start": 2828.64,
      "duration": 4.24,
      "text": "imageet task or any sort of uh"
    },
    {
      "start": 2831.119,
      "duration": 5.361,
      "text": "classification task. It's it's a nice"
    },
    {
      "start": 2832.88,
      "duration": 5.76,
      "text": "test bed. There are many images that are"
    },
    {
      "start": 2836.48,
      "duration": 4.48,
      "text": "really easy and there are many images"
    },
    {
      "start": 2838.64,
      "duration": 6.08,
      "text": "that are really difficult. When we train"
    },
    {
      "start": 2840.96,
      "duration": 5.52,
      "text": "for instance a vit or a CNN uh to do"
    },
    {
      "start": 2844.72,
      "duration": 3.68,
      "text": "this task,"
    },
    {
      "start": 2846.48,
      "duration": 4.879,
      "text": "it has to nest all of that reasoning in"
    },
    {
      "start": 2848.4,
      "duration": 5.28,
      "text": "the same space. It has to put all of its"
    },
    {
      "start": 2851.359,
      "duration": 5.281,
      "text": "decision-m process for a very simple"
    },
    {
      "start": 2853.68,
      "duration": 5.04,
      "text": "obvious cat versus some complex weird"
    },
    {
      "start": 2856.64,
      "duration": 4.8,
      "text": "underrepresented class in that system in"
    },
    {
      "start": 2858.72,
      "duration": 5.44,
      "text": "that data set and it has to nest it all"
    },
    {
      "start": 2861.44,
      "duration": 5.44,
      "text": "in parallel in a way that is we get to"
    },
    {
      "start": 2864.16,
      "duration": 5.76,
      "text": "the last layer and then we classify. Um"
    },
    {
      "start": 2866.88,
      "duration": 6,
      "text": "I I think breaking that down where you"
    },
    {
      "start": 2869.92,
      "duration": 5.36,
      "text": "have different points in time where you"
    },
    {
      "start": 2872.88,
      "duration": 4.64,
      "text": "can say now I'm done I can stop versus"
    },
    {
      "start": 2875.28,
      "duration": 4.64,
      "text": "now I'm done I can stop let you take a"
    },
    {
      "start": 2877.52,
      "duration": 5.04,
      "text": "data set or take a task and actually"
    },
    {
      "start": 2879.92,
      "duration": 4.88,
      "text": "naturally segment it into its easy to"
    },
    {
      "start": 2882.56,
      "duration": 4,
      "text": "difficult components. And I think we"
    },
    {
      "start": 2884.8,
      "duration": 4.16,
      "text": "know that curriculum learning and"
    },
    {
      "start": 2886.56,
      "duration": 3.84,
      "text": "learning in this continuous sense again"
    },
    {
      "start": 2888.96,
      "duration": 4.159,
      "text": "seems to be a good idea. It's it's how"
    },
    {
      "start": 2890.4,
      "duration": 4.719,
      "text": "humans learn. And if we can get at that"
    },
    {
      "start": 2893.119,
      "duration": 4.72,
      "text": "architecturally and just have that fall"
    },
    {
      "start": 2895.119,
      "duration": 4.561,
      "text": "out in a model, again, this seems like a"
    },
    {
      "start": 2897.839,
      "duration": 3.52,
      "text": "something worth exploring. Uh I'm not"
    },
    {
      "start": 2899.68,
      "duration": 3.679,
      "text": "sure if you know much about model"
    },
    {
      "start": 2901.359,
      "duration": 3.281,
      "text": "calibration and how neural networks tend"
    },
    {
      "start": 2903.359,
      "duration": 4,
      "text": "to be poorly calibrated."
    },
    {
      "start": 2904.64,
      "duration": 4.16,
      "text": ">> Oh, go for it, Tommy. Um it's it's a bit"
    },
    {
      "start": 2907.359,
      "duration": 3.521,
      "text": "of an old finding, but if you train a"
    },
    {
      "start": 2908.8,
      "duration": 3.2,
      "text": "neural network for long enough and it"
    },
    {
      "start": 2910.88,
      "duration": 2.8,
      "text": "fits really really well and you've"
    },
    {
      "start": 2912,
      "duration": 3.28,
      "text": "regularized it regularized it really"
    },
    {
      "start": 2913.68,
      "duration": 3.84,
      "text": "really well, you'll find that the model"
    },
    {
      "start": 2915.28,
      "duration": 6.24,
      "text": "is unccalibrated, which essentially"
    },
    {
      "start": 2917.52,
      "duration": 6.16,
      "text": "means that it is very certain uh about"
    },
    {
      "start": 2921.52,
      "duration": 3.76,
      "text": "some components where some classes where"
    },
    {
      "start": 2923.68,
      "duration": 3.52,
      "text": "it's wrong and uncertain for some"
    },
    {
      "start": 2925.28,
      "duration": 3.6,
      "text": "classes where it's correct. Essentially"
    },
    {
      "start": 2927.2,
      "duration": 4,
      "text": "what you want for a perfectly calibrated"
    },
    {
      "start": 2928.88,
      "duration": 4.56,
      "text": "model is if it predicts a uh probability"
    },
    {
      "start": 2931.2,
      "duration": 5.84,
      "text": "that this is in class the correct class"
    },
    {
      "start": 2933.44,
      "duration": 5.76,
      "text": "with 50%. 50% of the time you want it to"
    },
    {
      "start": 2937.04,
      "duration": 4,
      "text": "be correct about that class and so on"
    },
    {
      "start": 2939.2,
      "duration": 3.6,
      "text": "and so forth. So a well-c calibrated"
    },
    {
      "start": 2941.04,
      "duration": 6.559,
      "text": "model if it's predicting a probability"
    },
    {
      "start": 2942.8,
      "duration": 7.84,
      "text": "of 0.9 that it is a cat then 90% of the"
    },
    {
      "start": 2947.599,
      "duration": 4.881,
      "text": "time it should be correct. And it's"
    },
    {
      "start": 2950.64,
      "duration": 3.199,
      "text": "actually turns out that most models that"
    },
    {
      "start": 2952.48,
      "duration": 3.04,
      "text": "you train for long enough get poorly"
    },
    {
      "start": 2953.839,
      "duration": 4.48,
      "text": "calibrated. And there are loads of post"
    },
    {
      "start": 2955.52,
      "duration": 4.319,
      "text": "hawk tricks uh to fixing this. We"
    },
    {
      "start": 2958.319,
      "duration": 3.361,
      "text": "measured the calibration of the CTM"
    },
    {
      "start": 2959.839,
      "duration": 3.921,
      "text": "after training and it was nearly"
    },
    {
      "start": 2961.68,
      "duration": 4.159,
      "text": "perfectly calibrated which is again a"
    },
    {
      "start": 2963.76,
      "duration": 4,
      "text": "little bit of a smoking gun that this"
    },
    {
      "start": 2965.839,
      "duration": 4.48,
      "text": "actually seems to be probably a better"
    },
    {
      "start": 2967.76,
      "duration": 5.359,
      "text": "way to do things. The flavor of this"
    },
    {
      "start": 2970.319,
      "duration": 5.361,
      "text": "kind of research is such that we didn't"
    },
    {
      "start": 2973.119,
      "duration": 5.761,
      "text": "actually go out and actually try to"
    },
    {
      "start": 2975.68,
      "duration": 5.04,
      "text": "create a very well-c calibrated model,"
    },
    {
      "start": 2978.88,
      "duration": 4.239,
      "text": "right? And we didn't even try to create"
    },
    {
      "start": 2980.72,
      "duration": 5.119,
      "text": "a model that was necessarily going to be"
    },
    {
      "start": 2983.119,
      "duration": 6.801,
      "text": "able to do some kind of adaptive"
    },
    {
      "start": 2985.839,
      "duration": 7.52,
      "text": "computation time, right? Um I was um a"
    },
    {
      "start": 2989.92,
      "duration": 5.6,
      "text": "very big fan of the the paper um uh yeah"
    },
    {
      "start": 2993.359,
      "duration": 5.921,
      "text": "adapted computation time was Alex Graves"
    },
    {
      "start": 2995.52,
      "duration": 5.839,
      "text": "was it? But that paper um it had a"
    },
    {
      "start": 2999.28,
      "duration": 6,
      "text": "massive amount of hyperparameter sweeps"
    },
    {
      "start": 3001.359,
      "duration": 6.72,
      "text": "in it because in that paper he needed to"
    },
    {
      "start": 3005.28,
      "duration": 4.799,
      "text": "have a loss on the amount of computation"
    },
    {
      "start": 3008.079,
      "duration": 4.961,
      "text": "that was being done."
    },
    {
      "start": 3010.079,
      "duration": 5.921,
      "text": ">> Because anytime you try to do some sort"
    },
    {
      "start": 3013.04,
      "duration": 6.319,
      "text": "of adaptive computation time research,"
    },
    {
      "start": 3016,
      "duration": 6.96,
      "text": "what you're fighting is the fact that"
    },
    {
      "start": 3019.359,
      "duration": 5.601,
      "text": "neural networks are greedy,"
    },
    {
      "start": 3022.96,
      "duration": 4.24,
      "text": "right? because obviously the way to get"
    },
    {
      "start": 3024.96,
      "duration": 5.2,
      "text": "the lowest loss is to use all the"
    },
    {
      "start": 3027.2,
      "duration": 4.72,
      "text": "computation that you have access to. So"
    },
    {
      "start": 3030.16,
      "duration": 4.399,
      "text": "unless you had like an extra loss that"
    },
    {
      "start": 3031.92,
      "duration": 3.84,
      "text": "had a penalty that said okay actually"
    },
    {
      "start": 3034.559,
      "duration": 3.921,
      "text": "you're not allowed to use all the"
    },
    {
      "start": 3035.76,
      "duration": 5.52,
      "text": "computation that's and and very very"
    },
    {
      "start": 3038.48,
      "duration": 5.28,
      "text": "carefully balance loss that's when you"
    },
    {
      "start": 3041.28,
      "duration": 4.559,
      "text": "actually got the interesting dynamic"
    },
    {
      "start": 3043.76,
      "duration": 4.64,
      "text": "computation time behavior falling out of"
    },
    {
      "start": 3045.839,
      "duration": 4.961,
      "text": "the the model in that paper."
    },
    {
      "start": 3048.4,
      "duration": 5.52,
      "text": "But was really gratifying to see with"
    },
    {
      "start": 3050.8,
      "duration": 4.799,
      "text": "the the continuous thought machine is"
    },
    {
      "start": 3053.92,
      "duration": 4.56,
      "text": "that because of the way that we set up"
    },
    {
      "start": 3055.599,
      "duration": 5.121,
      "text": "the loss that Luke described earlier,"
    },
    {
      "start": 3058.48,
      "duration": 5.04,
      "text": "adaptive computation times seem to just"
    },
    {
      "start": 3060.72,
      "duration": 6.08,
      "text": "fall out naturally."
    },
    {
      "start": 3063.52,
      "duration": 6.079,
      "text": "So that's more the way that I think"
    },
    {
      "start": 3066.8,
      "duration": 4.4,
      "text": "research should go."
    },
    {
      "start": 3069.599,
      "duration": 4.24,
      "text": ">> Okay? because we we don't actually have"
    },
    {
      "start": 3071.2,
      "duration": 5.44,
      "text": "like a specific goal"
    },
    {
      "start": 3073.839,
      "duration": 4.72,
      "text": "um like or a specific problem we're"
    },
    {
      "start": 3076.64,
      "duration": 4.64,
      "text": "trying to fix like that or something"
    },
    {
      "start": 3078.559,
      "duration": 5.04,
      "text": "we're trying to invent. It's more that"
    },
    {
      "start": 3081.28,
      "duration": 4.24,
      "text": "we have this interesting architecture"
    },
    {
      "start": 3083.599,
      "duration": 3.601,
      "text": "and that we're just following the"
    },
    {
      "start": 3085.52,
      "duration": 3.76,
      "text": "gradients of interestingness."
    },
    {
      "start": 3087.2,
      "duration": 3.84,
      "text": ">> Yes. And on on that point, I I think"
    },
    {
      "start": 3089.28,
      "duration": 3.039,
      "text": "maybe the most exciting thing about your"
    },
    {
      "start": 3091.04,
      "duration": 5.279,
      "text": "paper is, you know, we were talking"
    },
    {
      "start": 3092.319,
      "duration": 5.76,
      "text": "about path dependence and um having this"
    },
    {
      "start": 3096.319,
      "duration": 4.881,
      "text": "understanding which is built step by"
    },
    {
      "start": 3098.079,
      "duration": 5.841,
      "text": "step, this process of complexification"
    },
    {
      "start": 3101.2,
      "duration": 5.119,
      "text": "and u I mean maybe this is this is um"
    },
    {
      "start": 3103.92,
      "duration": 4.8,
      "text": "apppropo in in the theme of world models"
    },
    {
      "start": 3106.319,
      "duration": 4.161,
      "text": "in in general and also active inference"
    },
    {
      "start": 3108.72,
      "duration": 3.28,
      "text": "and I say active inference in big quotes"
    },
    {
      "start": 3110.48,
      "duration": 2.8,
      "text": "because it's not KL Friston's active you"
    },
    {
      "start": 3112,
      "duration": 2.559,
      "text": "know maybe adaptive inference or"
    },
    {
      "start": 3113.28,
      "duration": 3.76,
      "text": "something like that but we want to build"
    },
    {
      "start": 3114.559,
      "duration": 5.52,
      "text": "agents that can continue to learn that"
    },
    {
      "start": 3117.04,
      "duration": 6.559,
      "text": "can update their parameters and most"
    },
    {
      "start": 3120.079,
      "duration": 6.401,
      "text": "importantly can construct path dependent"
    },
    {
      "start": 3123.599,
      "duration": 4.48,
      "text": "understanding and because it that's"
    },
    {
      "start": 3126.48,
      "duration": 3.68,
      "text": "completely different to just"
    },
    {
      "start": 3128.079,
      "duration": 4.081,
      "text": "understanding what the thing is. It's"
    },
    {
      "start": 3130.16,
      "duration": 4.159,
      "text": "how you got there is very important and"
    },
    {
      "start": 3132.16,
      "duration": 5.199,
      "text": "this architecture potentially allows"
    },
    {
      "start": 3134.319,
      "duration": 5.921,
      "text": "these agents using this algorithm to"
    },
    {
      "start": 3137.359,
      "duration": 5.2,
      "text": "explore trajectories in spaces find the"
    },
    {
      "start": 3140.24,
      "duration": 4.24,
      "text": "best trajectories and actually construct"
    },
    {
      "start": 3142.559,
      "duration": 4.241,
      "text": "an understanding which carves the world"
    },
    {
      "start": 3144.48,
      "duration": 3.599,
      "text": "up by the joints. Yeah, that's a that's"
    },
    {
      "start": 3146.8,
      "duration": 3.36,
      "text": "a really neat perspective. I haven't"
    },
    {
      "start": 3148.079,
      "duration": 5.681,
      "text": "actually thought about it like that, but"
    },
    {
      "start": 3150.16,
      "duration": 6.48,
      "text": "yes, I think um that particular stance"
    },
    {
      "start": 3153.76,
      "duration": 6.48,
      "text": "becomes really interesting when you"
    },
    {
      "start": 3156.64,
      "duration": 5.919,
      "text": "think about ambiguous problems because"
    },
    {
      "start": 3160.24,
      "duration": 4.56,
      "text": "carving the world up in one way is as"
    },
    {
      "start": 3162.559,
      "duration": 2.721,
      "text": "performant as carving it up in another"
    },
    {
      "start": 3164.8,
      "duration": 2.08,
      "text": "way."
    },
    {
      "start": 3165.28,
      "duration": 3.76,
      "text": ">> Yeah. uh you know perhaps the"
    },
    {
      "start": 3166.88,
      "duration": 5.76,
      "text": "hallucination in language models is"
    },
    {
      "start": 3169.04,
      "duration": 5.76,
      "text": "carving the world up in some fine way"
    },
    {
      "start": 3172.64,
      "duration": 3.76,
      "text": "but it's just not performance in our"
    },
    {
      "start": 3174.8,
      "duration": 4.16,
      "text": "measure of this is hallucination and"
    },
    {
      "start": 3176.4,
      "duration": 5.199,
      "text": "actually that's not true but in some"
    },
    {
      "start": 3178.96,
      "duration": 4.24,
      "text": "other trace down the path of wanting to"
    },
    {
      "start": 3181.599,
      "duration": 4.081,
      "text": "carve the world up through a auto"
    },
    {
      "start": 3183.2,
      "duration": 5.04,
      "text": "reggressive generation of tokens you end"
    },
    {
      "start": 3185.68,
      "duration": 4.56,
      "text": "up in a different carve up of that world"
    },
    {
      "start": 3188.24,
      "duration": 4.879,
      "text": "and being able to train a model that can"
    },
    {
      "start": 3190.24,
      "duration": 4.4,
      "text": "be implicitly aware of the fact that it"
    },
    {
      "start": 3193.119,
      "duration": 4.081,
      "text": "is actually carving up the world in a"
    },
    {
      "start": 3194.64,
      "duration": 6,
      "text": "different way and and explore those"
    },
    {
      "start": 3197.2,
      "duration": 5.359,
      "text": "manners, those uh descents down the"
    },
    {
      "start": 3200.64,
      "duration": 3.76,
      "text": "carve up is something that we're after"
    },
    {
      "start": 3202.559,
      "duration": 4.8,
      "text": "and I think it's quite an exciting"
    },
    {
      "start": 3204.4,
      "duration": 6.719,
      "text": "approach to be trying to take a stance"
    },
    {
      "start": 3207.359,
      "duration": 6.24,
      "text": "of let's let's break up this problem"
    },
    {
      "start": 3211.119,
      "duration": 4.641,
      "text": "into small solvable parts and learn to"
    },
    {
      "start": 3213.599,
      "duration": 5.201,
      "text": "do it like that and how can we do this"
    },
    {
      "start": 3215.76,
      "duration": 4.72,
      "text": "in a natural way without too many hacks."
    },
    {
      "start": 3218.8,
      "duration": 4.08,
      "text": "Yeah, it's something I've been thinking"
    },
    {
      "start": 3220.48,
      "duration": 4.079,
      "text": "about because um Shalet as much as I"
    },
    {
      "start": 3222.88,
      "duration": 4.959,
      "text": "love his measure of intelligence um"
    },
    {
      "start": 3224.559,
      "duration": 6.8,
      "text": "ideas is for him adapting to novelty is"
    },
    {
      "start": 3227.839,
      "duration": 6,
      "text": "getting the right answer and the reason"
    },
    {
      "start": 3231.359,
      "duration": 4.48,
      "text": "why you gave that answer is very very"
    },
    {
      "start": 3233.839,
      "duration": 3.681,
      "text": "important and in machine learning we"
    },
    {
      "start": 3235.839,
      "duration": 4.401,
      "text": "have this problem that we we come up"
    },
    {
      "start": 3237.52,
      "duration": 5.12,
      "text": "with this kind of cost function that"
    },
    {
      "start": 3240.24,
      "duration": 4.079,
      "text": "rather leads to this shortcut problem"
    },
    {
      "start": 3242.64,
      "duration": 4.32,
      "text": "but you know we could just build a"
    },
    {
      "start": 3244.319,
      "duration": 5.441,
      "text": "symbolic system we could be gi and and"
    },
    {
      "start": 3246.96,
      "duration": 5.119,
      "text": "we could say okay we need do this um"
    },
    {
      "start": 3249.76,
      "duration": 3.92,
      "text": "principled kind of construction of"
    },
    {
      "start": 3252.079,
      "duration": 2.801,
      "text": "knowledge maintaining semantics. Well,"
    },
    {
      "start": 3253.68,
      "duration": 3.6,
      "text": "we're not doing that. We're doing a"
    },
    {
      "start": 3254.88,
      "duration": 5.199,
      "text": "hybrid system. But there must be some"
    },
    {
      "start": 3257.28,
      "duration": 5.68,
      "text": "natural way of doing reasoning where in"
    },
    {
      "start": 3260.079,
      "duration": 5.28,
      "text": "spite of the end objective being this"
    },
    {
      "start": 3262.96,
      "duration": 4.399,
      "text": "cost function that because of the way"
    },
    {
      "start": 3265.359,
      "duration": 4.161,
      "text": "that we traversed these open-ended"
    },
    {
      "start": 3267.359,
      "duration": 4.561,
      "text": "spaces that we can actually have more"
    },
    {
      "start": 3269.52,
      "duration": 5.68,
      "text": "confidence mechanistically that we're"
    },
    {
      "start": 3271.92,
      "duration": 5.199,
      "text": "doing reasoning which is aligned to the"
    },
    {
      "start": 3275.2,
      "duration": 4.56,
      "text": "world. I think that's a great way of"
    },
    {
      "start": 3277.119,
      "duration": 4.72,
      "text": "seeing this particular uh avenue of"
    },
    {
      "start": 3279.76,
      "duration": 3.44,
      "text": "research and I think that obviously"
    },
    {
      "start": 3281.839,
      "duration": 2.72,
      "text": "we're not the only people thinking like"
    },
    {
      "start": 3283.2,
      "duration": 4.32,
      "text": "this and we're not the only ones trying"
    },
    {
      "start": 3284.559,
      "duration": 5.601,
      "text": "to do this. Um what we have is an"
    },
    {
      "start": 3287.52,
      "duration": 5.76,
      "text": "architecture that's amanable to it and"
    },
    {
      "start": 3290.16,
      "duration": 5.439,
      "text": "surprisingly so it wasn't again wasn't"
    },
    {
      "start": 3293.28,
      "duration": 3.839,
      "text": "the goal. It's not the goal to to do"
    },
    {
      "start": 3295.599,
      "duration": 3.121,
      "text": "this type of research. It's not the goal"
    },
    {
      "start": 3297.119,
      "duration": 4.48,
      "text": "to be able to break the world down into"
    },
    {
      "start": 3298.72,
      "duration": 4.96,
      "text": "these small uh chunks that we can"
    },
    {
      "start": 3301.599,
      "duration": 6.321,
      "text": "actually reason over in in a way that"
    },
    {
      "start": 3303.68,
      "duration": 6.8,
      "text": "seems natural. Instead, what we did was"
    },
    {
      "start": 3307.92,
      "duration": 5.679,
      "text": "pay respect to the brain, pay respect to"
    },
    {
      "start": 3310.48,
      "duration": 5.119,
      "text": "nature and say, well, if we build these"
    },
    {
      "start": 3313.599,
      "duration": 4.321,
      "text": "inspired things, what what actually"
    },
    {
      "start": 3315.599,
      "duration": 5.921,
      "text": "happens? What what different ways of"
    },
    {
      "start": 3317.92,
      "duration": 5.84,
      "text": "approaching a problem emerge? And then"
    },
    {
      "start": 3321.52,
      "duration": 5.28,
      "text": "when those different ways of approaching"
    },
    {
      "start": 3323.76,
      "duration": 5.04,
      "text": "a problem emerge, what big philosophical"
    },
    {
      "start": 3326.8,
      "duration": 4.48,
      "text": "and uh intelligence-based questions can"
    },
    {
      "start": 3328.8,
      "duration": 5.039,
      "text": "we then start to ask? And that's where"
    },
    {
      "start": 3331.28,
      "duration": 4.64,
      "text": "we're at right now. So it might feel at"
    },
    {
      "start": 3333.839,
      "duration": 4,
      "text": "times, especially for me, uh too many"
    },
    {
      "start": 3335.92,
      "duration": 5.12,
      "text": "questions and too few hands to answer"
    },
    {
      "start": 3337.839,
      "duration": 4.801,
      "text": "those questions. But I think the fun and"
    },
    {
      "start": 3341.04,
      "duration": 3.76,
      "text": "exciting thing and the encouraging thing"
    },
    {
      "start": 3342.64,
      "duration": 3.919,
      "text": "that I I can you know try to encourage"
    },
    {
      "start": 3344.8,
      "duration": 4.96,
      "text": "other younger researchers out there is"
    },
    {
      "start": 3346.559,
      "duration": 6,
      "text": "that uh you know do what you're passion"
    },
    {
      "start": 3349.76,
      "duration": 5.12,
      "text": "passionate about and figure out how to"
    },
    {
      "start": 3352.559,
      "duration": 4.24,
      "text": "build the things that you care about and"
    },
    {
      "start": 3354.88,
      "duration": 4.32,
      "text": "then see what that does. See what doors"
    },
    {
      "start": 3356.799,
      "duration": 4.241,
      "text": "that opens up and see how to explore"
    },
    {
      "start": 3359.2,
      "duration": 3.119,
      "text": "deeper into those domains."
    },
    {
      "start": 3361.04,
      "duration": 3.759,
      "text": ">> We were talking about this yesterday,"
    },
    {
      "start": 3362.319,
      "duration": 4.721,
      "text": "weren't we? That you can think of"
    },
    {
      "start": 3364.799,
      "duration": 4.401,
      "text": "language as being a kind of maze."
    },
    {
      "start": 3367.04,
      "duration": 4.48,
      "text": ">> Yes. like what is to stop us from taking"
    },
    {
      "start": 3369.2,
      "duration": 5.44,
      "text": "this architecture and building the next"
    },
    {
      "start": 3371.52,
      "duration": 5.2,
      "text": "generation language model with it. I"
    },
    {
      "start": 3374.64,
      "duration": 3.6,
      "text": "mean that that's honestly as you know"
    },
    {
      "start": 3376.72,
      "duration": 4.32,
      "text": "something that I am actively trying to"
    },
    {
      "start": 3378.24,
      "duration": 6,
      "text": "explore right now and uh yeah I think"
    },
    {
      "start": 3381.04,
      "duration": 5.279,
      "text": "the maze the maze task gets really"
    },
    {
      "start": 3384.24,
      "duration": 3.599,
      "text": "interesting when you add ambiguity to it"
    },
    {
      "start": 3386.319,
      "duration": 3.04,
      "text": "when there are many ways to solve the"
    },
    {
      "start": 3387.839,
      "duration": 3.041,
      "text": "maze and honestly this isn't something"
    },
    {
      "start": 3389.359,
      "duration": 4,
      "text": "I've tried yet and maybe it's something"
    },
    {
      "start": 3390.88,
      "duration": 4.719,
      "text": "I should try next week but it's"
    },
    {
      "start": 3393.359,
      "duration": 4,
      "text": "essentially you can imagine an agent or"
    },
    {
      "start": 3395.599,
      "duration": 4.321,
      "text": "the CTM in this case observing the maze"
    },
    {
      "start": 3397.359,
      "duration": 4.881,
      "text": "and taking a trajectory and surprisingly"
    },
    {
      "start": 3399.92,
      "duration": 4.96,
      "text": "we saw this we have a section in our"
    },
    {
      "start": 3402.24,
      "duration": 4.64,
      "text": "recently updated paper on AR archive the"
    },
    {
      "start": 3404.88,
      "duration": 3.84,
      "text": "final camera ready version of this paper"
    },
    {
      "start": 3406.88,
      "duration": 3.6,
      "text": "where we added an extra supplementary"
    },
    {
      "start": 3408.72,
      "duration": 4.24,
      "text": "section that is not in the main"
    },
    {
      "start": 3410.48,
      "duration": 4.48,
      "text": "technical report and that supplementary"
    },
    {
      "start": 3412.96,
      "duration": 5.28,
      "text": "section is basically hey we saw this"
    },
    {
      "start": 3414.96,
      "duration": 4.48,
      "text": "cool stuff happen and we list I think 14"
    },
    {
      "start": 3418.24,
      "duration": 2.48,
      "text": "different interesting things that"
    },
    {
      "start": 3419.44,
      "duration": 3.52,
      "text": "happened while we were doing the"
    },
    {
      "start": 3420.72,
      "duration": 3.839,
      "text": "research um that obviously didn't make"
    },
    {
      "start": 3422.96,
      "duration": 3.52,
      "text": "it into the paper but we wanted people"
    },
    {
      "start": 3424.559,
      "duration": 3.28,
      "text": "to know about these strange things that"
    },
    {
      "start": 3426.48,
      "duration": 4.879,
      "text": "happened and this is one of the strange"
    },
    {
      "start": 3427.839,
      "duration": 6.24,
      "text": "things where uh"
    },
    {
      "start": 3431.359,
      "duration": 3.921,
      "text": "we watched during training what was"
    },
    {
      "start": 3434.079,
      "duration": 3.04,
      "text": "happening. And at some time during"
    },
    {
      "start": 3435.28,
      "duration": 4.079,
      "text": "training, maybe halfway through the"
    },
    {
      "start": 3437.119,
      "duration": 4.321,
      "text": "training run, we could see what the"
    },
    {
      "start": 3439.359,
      "duration": 3.921,
      "text": "model would do is it would start going"
    },
    {
      "start": 3441.44,
      "duration": 3.52,
      "text": "one path in the maze and then suddenly"
    },
    {
      "start": 3443.28,
      "duration": 3.68,
      "text": "it would realize, oh no, damn, I'm"
    },
    {
      "start": 3444.96,
      "duration": 3.76,
      "text": "wrong. And would backtrack and then take"
    },
    {
      "start": 3446.96,
      "duration": 4.399,
      "text": "another path. But eventually it gets"
    },
    {
      "start": 3448.72,
      "duration": 4.879,
      "text": "really good and it does you some sort of"
    },
    {
      "start": 3451.359,
      "duration": 3.841,
      "text": "distributed learning in this because"
    },
    {
      "start": 3453.599,
      "duration": 2.96,
      "text": "it's got a attention mechanism with"
    },
    {
      "start": 3455.2,
      "duration": 3.04,
      "text": "multiple heads. So it can actually just"
    },
    {
      "start": 3456.559,
      "duration": 4.081,
      "text": "figure out how to do this pretty well"
    },
    {
      "start": 3458.24,
      "duration": 4.96,
      "text": "and refine its solution. But sometime"
    },
    {
      "start": 3460.64,
      "duration": 4.08,
      "text": "early on in the the learning it descends"
    },
    {
      "start": 3463.2,
      "duration": 4.159,
      "text": "multiple paths and comes back and"
    },
    {
      "start": 3464.72,
      "duration": 5.28,
      "text": "backtracks. We have a really fascinating"
    },
    {
      "start": 3467.359,
      "duration": 3.76,
      "text": "set of experiments that also showed and"
    },
    {
      "start": 3470,
      "duration": 3.359,
      "text": "this this we actually have some"
    },
    {
      "start": 3471.119,
      "duration": 4.401,
      "text": "supplementary material online showing"
    },
    {
      "start": 3473.359,
      "duration": 3.281,
      "text": "this where uh and I don't really know"
    },
    {
      "start": 3475.52,
      "duration": 2.72,
      "text": "what this says. It's kind of a deep"
    },
    {
      "start": 3476.64,
      "duration": 2.8,
      "text": "philosophical thing but if you're trying"
    },
    {
      "start": 3478.24,
      "duration": 4.96,
      "text": "to solve a maze but you don't have"
    },
    {
      "start": 3479.44,
      "duration": 6.32,
      "text": "enough time. Turns out that there's a"
    },
    {
      "start": 3483.2,
      "duration": 4.48,
      "text": "there's a foster algorithm to do it. And"
    },
    {
      "start": 3485.76,
      "duration": 3.839,
      "text": "this was this blew my mind when I saw"
    },
    {
      "start": 3487.68,
      "duration": 3.439,
      "text": "it. So if we constrain the amount of"
    },
    {
      "start": 3489.599,
      "duration": 3.52,
      "text": "thinking time that the model has but"
    },
    {
      "start": 3491.119,
      "duration": 4.401,
      "text": "still get it to try solve a long maze"
    },
    {
      "start": 3493.119,
      "duration": 4.881,
      "text": "instead of tracing out that maze, what"
    },
    {
      "start": 3495.52,
      "duration": 3.92,
      "text": "it does is it quickly jumps ahead to"
    },
    {
      "start": 3498,
      "duration": 4,
      "text": "approximately where it needs to be and"
    },
    {
      "start": 3499.44,
      "duration": 5.119,
      "text": "it traces backwards and it fills in that"
    },
    {
      "start": 3502,
      "duration": 5.119,
      "text": "path backwards and then it jumps forward"
    },
    {
      "start": 3504.559,
      "duration": 4.081,
      "text": "again leaprogs over the top and traces"
    },
    {
      "start": 3507.119,
      "duration": 3.361,
      "text": "that section backwards and then leap"
    },
    {
      "start": 3508.64,
      "duration": 3.76,
      "text": "frogs and it does this fascinating"
    },
    {
      "start": 3510.48,
      "duration": 4.879,
      "text": "leaprogging behavior that is based on"
    },
    {
      "start": 3512.4,
      "duration": 4.48,
      "text": "the constraint of the system. And again,"
    },
    {
      "start": 3515.359,
      "duration": 3.841,
      "text": "you know, this is just an observation we"
    },
    {
      "start": 3516.88,
      "duration": 5.04,
      "text": "made and what that means uh in a deep"
    },
    {
      "start": 3519.2,
      "duration": 4.879,
      "text": "sense and how it's related to uh giving"
    },
    {
      "start": 3521.92,
      "duration": 3.919,
      "text": "a model time to think versus not and is"
    },
    {
      "start": 3524.079,
      "duration": 3.441,
      "text": "it enough time to think? What happens?"
    },
    {
      "start": 3525.839,
      "duration": 3.841,
      "text": "What different algorithms does the model"
    },
    {
      "start": 3527.52,
      "duration": 3.839,
      "text": "learn when you constrain it in this way?"
    },
    {
      "start": 3529.68,
      "duration": 4.24,
      "text": "I find that quite fascinating and an"
    },
    {
      "start": 3531.359,
      "duration": 3.76,
      "text": "interesting thing to explore. Does it"
    },
    {
      "start": 3533.92,
      "duration": 2.8,
      "text": "tell us something about how humans"
    },
    {
      "start": 3535.119,
      "duration": 3.68,
      "text": "think? Does it tell us something about"
    },
    {
      "start": 3536.72,
      "duration": 4.72,
      "text": "how how we think under constrained"
    },
    {
      "start": 3538.799,
      "duration": 4.081,
      "text": "settings versus open-ended settings?"
    },
    {
      "start": 3541.44,
      "duration": 2.639,
      "text": "There's a number of cool questions you"
    },
    {
      "start": 3542.88,
      "duration": 3.439,
      "text": "can ask on this front."
    },
    {
      "start": 3544.079,
      "duration": 3.921,
      "text": ">> You you guys are both huge fans of um"
    },
    {
      "start": 3546.319,
      "duration": 3.841,
      "text": "you know population methods and"
    },
    {
      "start": 3548,
      "duration": 3.92,
      "text": "collective intelligence and because we"
    },
    {
      "start": 3550.16,
      "duration": 4.08,
      "text": "can we can scale this thing up and we"
    },
    {
      "start": 3551.92,
      "duration": 4.399,
      "text": "can scale it out and what would it mean"
    },
    {
      "start": 3554.24,
      "duration": 4.079,
      "text": "to scale this thing out not only just in"
    },
    {
      "start": 3556.319,
      "duration": 3.841,
      "text": "a kind of um what do they call it"
    },
    {
      "start": 3558.319,
      "duration": 4.24,
      "text": "trivial paralization but in terms of"
    },
    {
      "start": 3560.16,
      "duration": 5.12,
      "text": "having some kind of weight sharing"
    },
    {
      "start": 3562.559,
      "duration": 4.401,
      "text": "between parallel models and so on. What"
    },
    {
      "start": 3565.28,
      "duration": 2.559,
      "text": "what what would uh what would that give"
    },
    {
      "start": 3566.96,
      "duration": 2.639,
      "text": "you potentially?"
    },
    {
      "start": 3567.839,
      "duration": 4.801,
      "text": ">> Uh this is this is a fun area of"
    },
    {
      "start": 3569.599,
      "duration": 4.48,
      "text": "research. So one of the active things"
    },
    {
      "start": 3572.64,
      "duration": 4.159,
      "text": "that we're trying to explore in our team"
    },
    {
      "start": 3574.079,
      "duration": 4,
      "text": "is uh concepts of memory long-term"
    },
    {
      "start": 3576.799,
      "duration": 3.52,
      "text": "memory and what what does this mean for"
    },
    {
      "start": 3578.079,
      "duration": 4.48,
      "text": "a system like this? So an experiment"
    },
    {
      "start": 3580.319,
      "duration": 5.76,
      "text": "that one can construct for instance is"
    },
    {
      "start": 3582.559,
      "duration": 6,
      "text": "to put some agents in a maze and let"
    },
    {
      "start": 3586.079,
      "duration": 4.24,
      "text": "them try solve this maze not not how we"
    },
    {
      "start": 3588.559,
      "duration": 3.921,
      "text": "did it in the paper but in a very"
    },
    {
      "start": 3590.319,
      "duration": 5.441,
      "text": "constrained setting where a agent can"
    },
    {
      "start": 3592.48,
      "duration": 6.319,
      "text": "only see maybe a 5x5 region around it"
    },
    {
      "start": 3595.76,
      "duration": 6,
      "text": "and we give that agent some mechanism"
    },
    {
      "start": 3598.799,
      "duration": 6.081,
      "text": "for saving and retrieving memories and"
    },
    {
      "start": 3601.76,
      "duration": 5.28,
      "text": "the task if you wish is to solve that"
    },
    {
      "start": 3604.88,
      "duration": 3.76,
      "text": "maze find your way to the end and the"
    },
    {
      "start": 3607.04,
      "duration": 2.48,
      "text": "model needs to learn how to construct"
    },
    {
      "start": 3608.64,
      "duration": 3.199,
      "text": "memory"
    },
    {
      "start": 3609.52,
      "duration": 4.4,
      "text": "such that it can get back to a point"
    },
    {
      "start": 3611.839,
      "duration": 3.601,
      "text": "where it's seen before and know I did"
    },
    {
      "start": 3613.92,
      "duration": 4.08,
      "text": "the wrong thing last time and go a"
    },
    {
      "start": 3615.44,
      "duration": 4.879,
      "text": "different route and you can then see"
    },
    {
      "start": 3618,
      "duration": 5.119,
      "text": "this with uh parallel agents in the same"
    },
    {
      "start": 3620.319,
      "duration": 4.961,
      "text": "maze with a shared memory structure and"
    },
    {
      "start": 3623.119,
      "duration": 3.841,
      "text": "see what actually happens when you can"
    },
    {
      "start": 3625.28,
      "duration": 4.16,
      "text": "all access that memory structure and"
    },
    {
      "start": 3626.96,
      "duration": 4.32,
      "text": "have a shared global like almost like a"
    },
    {
      "start": 3629.44,
      "duration": 4.56,
      "text": "cultural memory that we can access and"
    },
    {
      "start": 3631.28,
      "duration": 5.519,
      "text": "solve this global task by having many"
    },
    {
      "start": 3634,
      "duration": 4.72,
      "text": "agents trying to use this memory system"
    },
    {
      "start": 3636.799,
      "duration": 4,
      "text": "and I do think that memory is going to"
    },
    {
      "start": 3638.72,
      "duration": 4.56,
      "text": "be a very key element to what we need to"
    },
    {
      "start": 3640.799,
      "duration": 5.76,
      "text": "do in the future for AI in general."
    },
    {
      "start": 3643.28,
      "duration": 7.039,
      "text": ">> So the subject of uh reasoning came up"
    },
    {
      "start": 3646.559,
      "duration": 7.28,
      "text": "just a second ago and I think there's a"
    },
    {
      "start": 3650.319,
      "duration": 6.161,
      "text": "perception that recently we made a lot"
    },
    {
      "start": 3653.839,
      "duration": 4.401,
      "text": "of progress in reasoning right because"
    },
    {
      "start": 3656.48,
      "duration": 4.24,
      "text": "it's actually one of the main things"
    },
    {
      "start": 3658.24,
      "duration": 6.16,
      "text": "that I think people are are working on."
    },
    {
      "start": 3660.72,
      "duration": 6.32,
      "text": "We released a data set recently called"
    },
    {
      "start": 3664.4,
      "duration": 4.88,
      "text": "uh Sudoku bench and I was actually quite"
    },
    {
      "start": 3667.04,
      "duration": 4.277,
      "text": "happy to see it come up organically on"
    },
    {
      "start": 3669.28,
      "duration": 2.16,
      "text": "your uh podcast a few weeks ago."
    },
    {
      "start": 3671.317,
      "duration": 0.923,
      "text": "[snorts]"
    },
    {
      "start": 3671.44,
      "duration": 1.28,
      "text": ">> Chris Moore,"
    },
    {
      "start": 3672.24,
      "duration": 3.04,
      "text": ">> right?"
    },
    {
      "start": 3672.72,
      "duration": 4.16,
      "text": ">> Yes. So,"
    },
    {
      "start": 3675.28,
      "duration": 5.039,
      "text": "I I wanted to tell you a little bit"
    },
    {
      "start": 3676.88,
      "duration": 5.52,
      "text": "about this benchmark because"
    },
    {
      "start": 3680.319,
      "duration": 4.721,
      "text": "I think I've been having a little bit of"
    },
    {
      "start": 3682.4,
      "duration": 4.56,
      "text": "issue promoting it because it doesn't on"
    },
    {
      "start": 3685.04,
      "duration": 5.68,
      "text": "the surface sound particularly"
    },
    {
      "start": 3686.96,
      "duration": 7.119,
      "text": "interesting because Sudoku has a sort of"
    },
    {
      "start": 3690.72,
      "duration": 6.32,
      "text": "a feeling that it's already been solved,"
    },
    {
      "start": 3694.079,
      "duration": 5.04,
      "text": "right? So, how interesting can a"
    },
    {
      "start": 3697.04,
      "duration": 4.799,
      "text": "collection of of Sudokus be for"
    },
    {
      "start": 3699.119,
      "duration": 5.761,
      "text": "reasoning? Exactly. We're not talking"
    },
    {
      "start": 3701.839,
      "duration": 6.48,
      "text": "about normal sedokus."
    },
    {
      "start": 3704.88,
      "duration": 7.04,
      "text": "We're talking about variant sodokas. And"
    },
    {
      "start": 3708.319,
      "duration": 5.361,
      "text": "what variant sodokas are are usually"
    },
    {
      "start": 3711.92,
      "duration": 3.76,
      "text": "normal sedokus, right? So put the"
    },
    {
      "start": 3713.68,
      "duration": 4.56,
      "text": "numbers one to nine in the row, the"
    },
    {
      "start": 3715.68,
      "duration": 6.8,
      "text": "column, and the box,"
    },
    {
      "start": 3718.24,
      "duration": 6.64,
      "text": "but then literally any additional rules"
    },
    {
      "start": 3722.48,
      "duration": 6.319,
      "text": "on top of that."
    },
    {
      "start": 3724.88,
      "duration": 6.08,
      "text": "And they're all handcrafted."
    },
    {
      "start": 3728.799,
      "duration": 4.32,
      "text": "they all have extremely different"
    },
    {
      "start": 3730.96,
      "duration": 5.44,
      "text": "constraints."
    },
    {
      "start": 3733.119,
      "duration": 4.96,
      "text": "Um constraints that actually require"
    },
    {
      "start": 3736.4,
      "duration": 3.199,
      "text": "very strong natural language"
    },
    {
      "start": 3738.079,
      "duration": 4.161,
      "text": "understanding."
    },
    {
      "start": 3739.599,
      "duration": 5.76,
      "text": "So for example, there's one puzzle in"
    },
    {
      "start": 3742.24,
      "duration": 5.04,
      "text": "the data set where"
    },
    {
      "start": 3745.359,
      "duration": 3.841,
      "text": "it tells you the constraints of the"
    },
    {
      "start": 3747.28,
      "duration": 3.6,
      "text": "puzzle in natural language and then"
    },
    {
      "start": 3749.2,
      "duration": 4.48,
      "text": "says, \"Oh, by the way, one of the"
    },
    {
      "start": 3750.88,
      "duration": 4.959,
      "text": "numbers in that description is wrong.\""
    },
    {
      "start": 3753.68,
      "duration": 4.639,
      "text": "Right? So you have to be able to meta"
    },
    {
      "start": 3755.839,
      "duration": 6.641,
      "text": "reason about the rules themselves even"
    },
    {
      "start": 3758.319,
      "duration": 7.441,
      "text": "before you start uh solving the puzzle."
    },
    {
      "start": 3762.48,
      "duration": 4.8,
      "text": "There are other puzzles where you have"
    },
    {
      "start": 3765.76,
      "duration": 4.88,
      "text": "um"
    },
    {
      "start": 3767.28,
      "duration": 5.519,
      "text": "a maze overlaid on the sodoku and the"
    },
    {
      "start": 3770.64,
      "duration": 5.04,
      "text": "rat has to work out a way through the"
    },
    {
      "start": 3772.799,
      "duration": 4.641,
      "text": "maze by following uh a path to the"
    },
    {
      "start": 3775.68,
      "duration": 3.6,
      "text": "cheese. But then there are constraints"
    },
    {
      "start": 3777.44,
      "duration": 4.96,
      "text": "on the path that it takes of like what"
    },
    {
      "start": 3779.28,
      "duration": 8.4,
      "text": "numbers and what they can be add up to."
    },
    {
      "start": 3782.4,
      "duration": 8.24,
      "text": "Um it's difficult to really describe how"
    },
    {
      "start": 3787.68,
      "duration": 6.639,
      "text": "varied these these uh these variants"
    },
    {
      "start": 3790.64,
      "duration": 5.36,
      "text": "sedokas are and I think they're so"
    },
    {
      "start": 3794.319,
      "duration": 3.28,
      "text": "varied"
    },
    {
      "start": 3796,
      "duration": 4.16,
      "text": "that"
    },
    {
      "start": 3797.599,
      "duration": 5.361,
      "text": "if anyone was actually be able to beat"
    },
    {
      "start": 3800.16,
      "duration": 5.28,
      "text": "our benchmark they would necessarily"
    },
    {
      "start": 3802.96,
      "duration": 5.52,
      "text": "have to have created an extremely"
    },
    {
      "start": 3805.44,
      "duration": 6.8,
      "text": "powerful reasoning system."
    },
    {
      "start": 3808.48,
      "duration": 8.639,
      "text": "Right now, the best models"
    },
    {
      "start": 3812.24,
      "duration": 8.559,
      "text": "um get around 15%, but they're only the"
    },
    {
      "start": 3817.119,
      "duration": 8.24,
      "text": "very very simplest and the very uh"
    },
    {
      "start": 3820.799,
      "duration": 6.721,
      "text": "smallest Sudoka puzzles in in the set."
    },
    {
      "start": 3825.359,
      "duration": 5.841,
      "text": "Um we're going to be putting out a blog"
    },
    {
      "start": 3827.52,
      "duration": 7.599,
      "text": "post about um GPT5's performance and it"
    },
    {
      "start": 3831.2,
      "duration": 7.28,
      "text": "is a jump but it's still completely"
    },
    {
      "start": 3835.119,
      "duration": 6.48,
      "text": "unable to solve puzzles which are you"
    },
    {
      "start": 3838.48,
      "duration": 5.119,
      "text": "know humans can can solve."
    },
    {
      "start": 3841.599,
      "duration": 5.601,
      "text": "And what I really like about this data"
    },
    {
      "start": 3843.599,
      "duration": 5.2,
      "text": "uh data set um and actually was the"
    },
    {
      "start": 3847.2,
      "duration": 4.879,
      "text": "catalyst for me creating it in the first"
    },
    {
      "start": 3848.799,
      "duration": 6.481,
      "text": "place it was that there was a there was"
    },
    {
      "start": 3852.079,
      "duration": 4.881,
      "text": "a quote by Andre Kapathy saying okay so"
    },
    {
      "start": 3855.28,
      "duration": 3.519,
      "text": "we have all this data it's from the"
    },
    {
      "start": 3856.96,
      "duration": 4.879,
      "text": "internet"
    },
    {
      "start": 3858.799,
      "duration": 6.721,
      "text": "um but what you really want right if you"
    },
    {
      "start": 3861.839,
      "duration": 5.601,
      "text": "wanted AGI you wouldn't want all of the"
    },
    {
      "start": 3865.52,
      "duration": 4.16,
      "text": "text that humans have ever created you"
    },
    {
      "start": 3867.44,
      "duration": 5.359,
      "text": "would actually want the thought traces"
    },
    {
      "start": 3869.68,
      "duration": 5.919,
      "text": "in their head as they were creating the"
    },
    {
      "start": 3872.799,
      "duration": 5.361,
      "text": "text, right? If you could actually learn"
    },
    {
      "start": 3875.599,
      "duration": 4.561,
      "text": "from that, then you would get something"
    },
    {
      "start": 3878.16,
      "duration": 4.959,
      "text": "really powerful."
    },
    {
      "start": 3880.16,
      "duration": 6.24,
      "text": "And I thought to myself, well, that data"
    },
    {
      "start": 3883.119,
      "duration": 7.361,
      "text": "must exist somewhere."
    },
    {
      "start": 3886.4,
      "duration": 6.959,
      "text": "My first thought was maybe"
    },
    {
      "start": 3890.48,
      "duration": 4.4,
      "text": "philosophy like uh you know there's"
    },
    {
      "start": 3893.359,
      "duration": 3.281,
      "text": "there's a type of philosophy where you"
    },
    {
      "start": 3894.88,
      "duration": 2.959,
      "text": "just write down your thoughts without"
    },
    {
      "start": 3896.64,
      "duration": 2.719,
      "text": "thinking like just stream of"
    },
    {
      "start": 3897.839,
      "duration": 4.401,
      "text": "consciousness."
    },
    {
      "start": 3899.359,
      "duration": 4.561,
      "text": "I thought maybe that could work. Um, but"
    },
    {
      "start": 3902.24,
      "duration": 3.76,
      "text": "then when I wasn't thinking about it and"
    },
    {
      "start": 3903.92,
      "duration": 4.399,
      "text": "I was, you know, in my leisure time, I"
    },
    {
      "start": 3906,
      "duration": 3.599,
      "text": "was watching a YouTube channel called"
    },
    {
      "start": 3908.319,
      "duration": 1.76,
      "text": "Cracking the Cryptic."
    },
    {
      "start": 3909.599,
      "duration": 2.561,
      "text": ">> Yes."
    },
    {
      "start": 3910.079,
      "duration": 5.841,
      "text": ">> Where these uh these two British"
    },
    {
      "start": 3912.16,
      "duration": 6.639,
      "text": "gentlemen will solve these extremely"
    },
    {
      "start": 3915.92,
      "duration": 5.52,
      "text": "difficult Sudoku puzzles for you. Right."
    },
    {
      "start": 3918.799,
      "duration": 3.921,
      "text": "Sometimes their their videos are four"
    },
    {
      "start": 3921.44,
      "duration": 3.919,
      "text": "hours long and they they're"
    },
    {
      "start": 3922.72,
      "duration": 6,
      "text": "professionals like this is their job."
    },
    {
      "start": 3925.359,
      "duration": 6.72,
      "text": "And what was perfect I realized is they"
    },
    {
      "start": 3928.72,
      "duration": 8,
      "text": "tell you in agonizing detail"
    },
    {
      "start": 3932.079,
      "duration": 7.28,
      "text": "exactly what reasoning they used"
    },
    {
      "start": 3936.72,
      "duration": 6.24,
      "text": "to solve those particular puzzles."
    },
    {
      "start": 3939.359,
      "duration": 5.44,
      "text": "Right? So we with their permission took"
    },
    {
      "start": 3942.96,
      "duration": 5.04,
      "text": "all of their videos which represents"
    },
    {
      "start": 3944.799,
      "duration": 7.361,
      "text": "thousands of hours of very high quality"
    },
    {
      "start": 3948,
      "duration": 6.16,
      "text": "human reasoning like thought traces"
    },
    {
      "start": 3952.16,
      "duration": 5.199,
      "text": "and"
    },
    {
      "start": 3954.16,
      "duration": 8.08,
      "text": "scraped them and made that available for"
    },
    {
      "start": 3957.359,
      "duration": 7.68,
      "text": "imitation learning. Right? Um we did try"
    },
    {
      "start": 3962.24,
      "duration": 4.559,
      "text": "to do this internally. Turns out that I"
    },
    {
      "start": 3965.039,
      "duration": 3.441,
      "text": "did a little bit too much of a good job"
    },
    {
      "start": 3966.799,
      "duration": 3.921,
      "text": "of really creating a very difficult"
    },
    {
      "start": 3968.48,
      "duration": 3.599,
      "text": "benchmark. Right. So, we're still trying"
    },
    {
      "start": 3970.72,
      "duration": 2.96,
      "text": "to get that stuff working and we'll"
    },
    {
      "start": 3972.079,
      "duration": 5.361,
      "text": "publish it that if we if we have some"
    },
    {
      "start": 3973.68,
      "duration": 5.439,
      "text": "success. Um,"
    },
    {
      "start": 3977.44,
      "duration": 3.359,
      "text": "yeah, I want to I want to really sell"
    },
    {
      "start": 3979.119,
      "duration": 4.401,
      "text": "the fact that this this reasoning"
    },
    {
      "start": 3980.799,
      "duration": 4.32,
      "text": "benchmark really is different, right?"
    },
    {
      "start": 3983.52,
      "duration": 3.599,
      "text": "Not only do you get something that's"
    },
    {
      "start": 3985.119,
      "duration": 3.92,
      "text": "super grounded, like you know exactly if"
    },
    {
      "start": 3987.119,
      "duration": 5.041,
      "text": "it's right or wrong, so you can do RL to"
    },
    {
      "start": 3989.039,
      "duration": 7.52,
      "text": "your heart's consent,"
    },
    {
      "start": 3992.16,
      "duration": 7.76,
      "text": "but you can't generalize very easily."
    },
    {
      "start": 3996.559,
      "duration": 8.641,
      "text": "Each puzzle is deliberately designed by"
    },
    {
      "start": 3999.92,
      "duration": 8.56,
      "text": "hand to have a new and unique twist on"
    },
    {
      "start": 4005.2,
      "duration": 6.32,
      "text": "the rules called a breakin that you have"
    },
    {
      "start": 4008.48,
      "duration": 7.92,
      "text": "to understand. And right now, despite"
    },
    {
      "start": 4011.52,
      "duration": 7.519,
      "text": "all the progress we've made,"
    },
    {
      "start": 4016.4,
      "duration": 6.159,
      "text": "the current AI models can't take that"
    },
    {
      "start": 4019.039,
      "duration": 5.361,
      "text": "leap. They can't find these breakins,"
    },
    {
      "start": 4022.559,
      "duration": 3.841,
      "text": "right? They'll fall back to, okay, I'll"
    },
    {
      "start": 4024.4,
      "duration": 4.08,
      "text": "try no, I'll try five, I'll try six,"
    },
    {
      "start": 4026.4,
      "duration": 4.56,
      "text": "I'll try seven,"
    },
    {
      "start": 4028.48,
      "duration": 5.119,
      "text": "right? The the reasoning becomes really"
    },
    {
      "start": 4030.96,
      "duration": 4.24,
      "text": "boring and nothing like what you see in"
    },
    {
      "start": 4033.599,
      "duration": 3.121,
      "text": "the transcripts that we've we've open"
    },
    {
      "start": 4035.2,
      "duration": 4.159,
      "text": "sourced from this from this YouTube"
    },
    {
      "start": 4036.72,
      "duration": 4.48,
      "text": "channel. So I just want to put the"
    },
    {
      "start": 4039.359,
      "duration": 4.24,
      "text": "challenge out there right that this this"
    },
    {
      "start": 4041.2,
      "duration": 4.8,
      "text": "is a a really difficult benchmark and I"
    },
    {
      "start": 4043.599,
      "duration": 5.841,
      "text": "think progress on this benchmark will"
    },
    {
      "start": 4046,
      "duration": 4.88,
      "text": "really mean progress in AI generally."
    },
    {
      "start": 4049.44,
      "duration": 3.599,
      "text": ">> Could you reflect a bit so after"
    },
    {
      "start": 4050.88,
      "duration": 4.959,
      "text": "watching this um Cracking the Cryptic"
    },
    {
      "start": 4053.039,
      "duration": 4.241,
      "text": "YouTube channel? How diverse were the"
    },
    {
      "start": 4055.839,
      "duration": 3.28,
      "text": "patterns? Because um Chris was saying to"
    },
    {
      "start": 4057.28,
      "duration": 4.079,
      "text": "me, oh you know these guys they go on"
    },
    {
      "start": 4059.119,
      "duration": 6.881,
      "text": "Discord servers, they get these creative"
    },
    {
      "start": 4061.359,
      "duration": 6.48,
      "text": "crazy ideas and I'm I'm obsessed. Maybe"
    },
    {
      "start": 4066,
      "duration": 3.68,
      "text": "it maybe I'm just being idealistic, but"
    },
    {
      "start": 4067.839,
      "duration": 5.041,
      "text": "I love this idea of there being a"
    },
    {
      "start": 4069.68,
      "duration": 6.08,
      "text": "deductive closure of knowledge, right?"
    },
    {
      "start": 4072.88,
      "duration": 4.959,
      "text": "That that there's this big tree of of"
    },
    {
      "start": 4075.76,
      "duration": 3.92,
      "text": "reasoning and we're all in possession of"
    },
    {
      "start": 4077.839,
      "duration": 3.681,
      "text": "different parts of the tree to different"
    },
    {
      "start": 4079.68,
      "duration": 3.2,
      "text": "depths. So the smarter and the more"
    },
    {
      "start": 4081.52,
      "duration": 4,
      "text": "knowledgeable you are, the deeper down"
    },
    {
      "start": 4082.88,
      "duration": 5.919,
      "text": "the tree you go. But in this idealized"
    },
    {
      "start": 4085.52,
      "duration": 5.68,
      "text": "form, there is one tree and all"
    },
    {
      "start": 4088.799,
      "duration": 4.56,
      "text": "knowledge kind of, you know, originates"
    },
    {
      "start": 4091.2,
      "duration": 4.88,
      "text": "or emanates from these abstract"
    },
    {
      "start": 4093.359,
      "duration": 5.521,
      "text": "principles. And we could in principle"
    },
    {
      "start": 4096.08,
      "duration": 4.88,
      "text": "build reasoning engines that could just"
    },
    {
      "start": 4098.88,
      "duration": 5.12,
      "text": "reason from first principles and it"
    },
    {
      "start": 4100.96,
      "duration": 4.879,
      "text": "might be um computationally irreducible."
    },
    {
      "start": 4104,
      "duration": 3.52,
      "text": "So so you have to perform all of the"
    },
    {
      "start": 4105.839,
      "duration": 3.52,
      "text": "steps. And it feels like because we're"
    },
    {
      "start": 4107.52,
      "duration": 4.319,
      "text": "not in possession of the full tree. What"
    },
    {
      "start": 4109.359,
      "duration": 4.561,
      "text": "we need to do is kind of fish around. We"
    },
    {
      "start": 4111.839,
      "duration": 3.84,
      "text": "fish around to find Lego blocks. Oh,"
    },
    {
      "start": 4113.92,
      "duration": 4.48,
      "text": "that's a good Lego block. I can apply"
    },
    {
      "start": 4115.679,
      "duration": 4.881,
      "text": "that to this problem. And maybe that's"
    },
    {
      "start": 4118.4,
      "duration": 3.759,
      "text": "just what we need to do in AI for the"
    },
    {
      "start": 4120.56,
      "duration": 3.36,
      "text": "time being is is is we need to just"
    },
    {
      "start": 4122.159,
      "duration": 3.6,
      "text": "acquire as much of the tree as possible."
    },
    {
      "start": 4123.92,
      "duration": 2.64,
      "text": "But could could we just do it all the"
    },
    {
      "start": 4125.759,
      "duration": 4.641,
      "text": "way down?"
    },
    {
      "start": 4126.56,
      "duration": 7.759,
      "text": ">> Yeah, fascinating question."
    },
    {
      "start": 4130.4,
      "duration": 9.279,
      "text": "That tree is probably massive, right?"
    },
    {
      "start": 4134.319,
      "duration": 8.88,
      "text": ">> And as a human is solving these puzzles,"
    },
    {
      "start": 4139.679,
      "duration": 6.48,
      "text": "they're definitely learning in real time"
    },
    {
      "start": 4143.199,
      "duration": 5.361,
      "text": "and discovering new parts of this tree."
    },
    {
      "start": 4146.159,
      "duration": 5.6,
      "text": "And it's it's sort of a meta task,"
    },
    {
      "start": 4148.56,
      "duration": 5.92,
      "text": "right? Because it's not just reasoning,"
    },
    {
      "start": 4151.759,
      "duration": 6,
      "text": "you're reasoning about the reasoning."
    },
    {
      "start": 4154.48,
      "duration": 5.44,
      "text": "And I don't think we can. We have that"
    },
    {
      "start": 4157.759,
      "duration": 4.48,
      "text": "in AI right now. Because if you watch"
    },
    {
      "start": 4159.92,
      "duration": 5.2,
      "text": "the videos, they'll say something like,"
    },
    {
      "start": 4162.239,
      "duration": 5.841,
      "text": "\"Okay, this looks like a parask or this"
    },
    {
      "start": 4165.12,
      "duration": 5.76,
      "text": "is a set theoretic problem or, you know,"
    },
    {
      "start": 4168.08,
      "duration": 6.239,
      "text": "maybe I should get my path tool out and"
    },
    {
      "start": 4170.88,
      "duration": 6.879,
      "text": "trace this this around.\" And of course"
    },
    {
      "start": 4174.319,
      "duration": 7.44,
      "text": "the professionals they do have this this"
    },
    {
      "start": 4177.759,
      "duration": 6.161,
      "text": "already massive collection of reasoning"
    },
    {
      "start": 4181.759,
      "duration": 4.801,
      "text": "Lego blocks as you say in their head. So"
    },
    {
      "start": 4183.92,
      "duration": 5.2,
      "text": "they'll recognize okay that type of rule"
    },
    {
      "start": 4186.56,
      "duration": 4.56,
      "text": "usually needs this kind of Lego block."
    },
    {
      "start": 4189.12,
      "duration": 3.92,
      "text": "It's actually fascinating to watch how"
    },
    {
      "start": 4191.12,
      "duration": 4.8,
      "text": "good they are at just intuitively"
    },
    {
      "start": 4193.04,
      "duration": 4.96,
      "text": "knowing where you know someone like me"
    },
    {
      "start": 4195.92,
      "duration": 3.92,
      "text": "haven't solved as many needs to spend a"
    },
    {
      "start": 4198,
      "duration": 3.04,
      "text": "lot of time looking around like okay"
    },
    {
      "start": 4199.84,
      "duration": 3.76,
      "text": "maybe I should try this or maybe I try"
    },
    {
      "start": 4201.04,
      "duration": 5.52,
      "text": "this one. Um, but even they're not"
    },
    {
      "start": 4203.6,
      "duration": 5.68,
      "text": "perfect. So, you can watch them take a"
    },
    {
      "start": 4206.56,
      "duration": 5.2,
      "text": "certain kind of reasoning and start"
    },
    {
      "start": 4209.28,
      "duration": 7.36,
      "text": "building up. Okay, maybe we should solve"
    },
    {
      "start": 4211.76,
      "duration": 6.8,
      "text": "it like this and then go and know that"
    },
    {
      "start": 4216.64,
      "duration": 4.88,
      "text": "doesn't disambiguate it enough and then"
    },
    {
      "start": 4218.56,
      "duration": 5.679,
      "text": "backtrack and then go down another path."
    },
    {
      "start": 4221.52,
      "duration": 5.28,
      "text": "Again, something that we do not see"
    },
    {
      "start": 4224.239,
      "duration": 5.521,
      "text": "current AI doing when they're trying to"
    },
    {
      "start": 4226.8,
      "duration": 4.56,
      "text": "solve uh this this benchmark. the the"
    },
    {
      "start": 4229.76,
      "duration": 4.24,
      "text": "tree is very big and I guess the"
    },
    {
      "start": 4231.36,
      "duration": 4.879,
      "text": "phoggenetic distance between many of"
    },
    {
      "start": 4234,
      "duration": 4.08,
      "text": "these motifs in in the tree is just so"
    },
    {
      "start": 4236.239,
      "duration": 4,
      "text": "large. So it's so difficult to jump"
    },
    {
      "start": 4238.08,
      "duration": 4.8,
      "text": "between and and and I and I think that's"
    },
    {
      "start": 4240.239,
      "duration": 4.401,
      "text": "why as a collective intelligence we work"
    },
    {
      "start": 4242.88,
      "duration": 4.56,
      "text": "so well together because we actually"
    },
    {
      "start": 4244.64,
      "duration": 4.32,
      "text": "find ways to jump to different parts of"
    },
    {
      "start": 4247.44,
      "duration": 3.36,
      "text": "the tree,"
    },
    {
      "start": 4248.96,
      "duration": 6,
      "text": ">> right? And I and I think that's probably"
    },
    {
      "start": 4250.8,
      "duration": 5.76,
      "text": "why the RL the the current state of the"
    },
    {
      "start": 4254.96,
      "duration": 5.52,
      "text": "RL algorithms that we're trying to apply"
    },
    {
      "start": 4256.56,
      "duration": 5.84,
      "text": "to this just isn't working because"
    },
    {
      "start": 4260.48,
      "duration": 4.56,
      "text": "in order to learn how to get these"
    },
    {
      "start": 4262.4,
      "duration": 5.12,
      "text": "breakthroughs to to understand what the"
    },
    {
      "start": 4265.04,
      "duration": 4,
      "text": "sort of nuance reasoning is to get these"
    },
    {
      "start": 4267.52,
      "duration": 3.84,
      "text": "puzzles,"
    },
    {
      "start": 4269.04,
      "duration": 6.32,
      "text": "you have to sample them. And that it's"
    },
    {
      "start": 4271.36,
      "duration": 6.24,
      "text": "it's such a rare space, you know, it's"
    },
    {
      "start": 4275.36,
      "duration": 3.92,
      "text": "it's such an specific kind of reasoning"
    },
    {
      "start": 4277.6,
      "duration": 5.494,
      "text": "that's required to get to the the"
    },
    {
      "start": 4279.28,
      "duration": 6.399,
      "text": "specific breakthrough that this kind of"
    },
    {
      "start": 4283.094,
      "duration": 4.026,
      "text": "[snorts] technique doesn't work, right?"
    },
    {
      "start": 4285.679,
      "duration": 3.681,
      "text": "And there's definitely a feeling in the"
    },
    {
      "start": 4287.12,
      "duration": 4,
      "text": "community like, okay, this is how you"
    },
    {
      "start": 4289.36,
      "duration": 3.44,
      "text": "just solve things now. Like we have RL,"
    },
    {
      "start": 4291.12,
      "duration": 4.079,
      "text": "yes, we can get these language models to"
    },
    {
      "start": 4292.8,
      "duration": 4.48,
      "text": "do what we want. It doesn't work for"
    },
    {
      "start": 4295.199,
      "duration": 3.52,
      "text": "this for this data set."
    },
    {
      "start": 4297.28,
      "duration": 4.24,
      "text": ">> Guys, it's been an absolute honor having"
    },
    {
      "start": 4298.719,
      "duration": 5.041,
      "text": "you on the show. Just before we go, are"
    },
    {
      "start": 4301.52,
      "duration": 4.56,
      "text": "you hiring? Because we've got a we've"
    },
    {
      "start": 4303.76,
      "duration": 5.6,
      "text": "got a great audience of ML engineers and"
    },
    {
      "start": 4306.08,
      "duration": 5.84,
      "text": "scientists and um I think working for"
    },
    {
      "start": 4309.36,
      "duration": 4.96,
      "text": "Zakano would be the dream job."
    },
    {
      "start": 4311.92,
      "duration": 5.52,
      "text": ">> That's very kind of you. Yes, we are"
    },
    {
      "start": 4314.32,
      "duration": 5.2,
      "text": "definitely hiring and as I said earlier"
    },
    {
      "start": 4317.44,
      "duration": 4.16,
      "text": "in this interview,"
    },
    {
      "start": 4319.52,
      "duration": 4.159,
      "text": "I honestly"
    },
    {
      "start": 4321.6,
      "duration": 4.48,
      "text": "want to give people as much research"
    },
    {
      "start": 4323.679,
      "duration": 6.081,
      "text": "freedom as possible. I'm willing to make"
    },
    {
      "start": 4326.08,
      "duration": 5.04,
      "text": "that bet, right? I think things that are"
    },
    {
      "start": 4329.76,
      "duration": 3.439,
      "text": "very interesting will come out of this."
    },
    {
      "start": 4331.12,
      "duration": 3.76,
      "text": "And I think we've already seen plenty of"
    },
    {
      "start": 4333.199,
      "duration": 3.841,
      "text": "interesting things coming out of this."
    },
    {
      "start": 4334.88,
      "duration": 5.04,
      "text": "So if you want to work on what you think"
    },
    {
      "start": 4337.04,
      "duration": 4.08,
      "text": "is interesting and important, come to"
    },
    {
      "start": 4339.92,
      "duration": 3.04,
      "text": "Japan."
    },
    {
      "start": 4341.12,
      "duration": 3.545,
      "text": ">> And Japan just happens to be the most"
    },
    {
      "start": 4342.96,
      "duration": 1.84,
      "text": "civilized culture in the world."
    },
    {
      "start": 4344.665,
      "duration": 0.775,
      "text": "[laughter]"
    },
    {
      "start": 4344.8,
      "duration": 2.08,
      "text": ">> All right."
    },
    {
      "start": 4345.44,
      "duration": 3.84,
      "text": ">> It might be the opportunity of a"
    },
    {
      "start": 4346.88,
      "duration": 4.48,
      "text": "lifetime, folks. So um yeah, get in"
    },
    {
      "start": 4349.28,
      "duration": 3.36,
      "text": "touch, guys. Seriously, thank you so"
    },
    {
      "start": 4351.36,
      "duration": 2.319,
      "text": "much. It's been an honor having you both"
    },
    {
      "start": 4352.64,
      "duration": 1.84,
      "text": "on the show."
    },
    {
      "start": 4353.679,
      "duration": 4.721,
      "text": ">> Thank you very much."
    },
    {
      "start": 4354.48,
      "duration": 3.92,
      "text": ">> Thank you so much. It's been great."
    }
  ],
  "fullText": "despite the fact that I was involved in inventing the Transformer luckily um no one's been working on them as long as I have rights with maybe the exception of the other se seven authors. So I actually made the decision uh earlier this year that I'm going to drastically reduce the amounts of of research that I'm doing specifically on the transformer because of the feeling that I have that it's it's an oversaturated space, right? It's not that there's no more interesting things to be done with them. And I'm going to make use of the opportunity to do something different, right? To actually turn up the amount of exploration that I'm doing in my research. We just released the continuous thought machine. It's a spotlight at Europe's 2025 this year. You should care about it because it has native adaptive compute. It's a new way of building a recurrent model that uses [music] higher level concepts for neurons and a synchronization as a representation that lets us solve problems in ways that seem more human by being biologically and nature inspired. The atmosphere in AI research was actually quite different back during the Transformer uh years um because it doesn't feel like something [music] similar could actually happen right now. because of the reduced amount of freedom that we have, right? [music] The Transformers was very very bottom up, right? It's not that somebody had this grand plan that came down from on high that this is what we should be working on. It was a bunch of people talking over lunch, thinking about [music] what the current problems are and how to solve them and having the freedom to have, you know, literally months to dedicate to just trying this [music] idea and having this this new architecture fall out. [music] We've spent hundreds of millions of dollars. The biggest sort of evolution based search is probably in the tens of thousands. We have all this compute. What happens? What happens if you scale up these search algorithms? And I'm sure you'll find something interesting, you know, when someone eventually does bite that bullet and really scale [music] up these evolutionary sort of a life experiments because I pitched it in an environment where people were just going all in on this one technology. I got zero interest. So now I have my own company and I can pursue those directions. This podcast is supported by Cyber Fund. >> Hey folks, I'm Omar, product and design lead at Google DeepMind. We just launched a revamped vibe coding experience in AI Studio that lets you mix and match AI capabilities [music] to turn your ideas into reality faster than ever. Just describe your app and Gemini will automatically wire up the right models and APIs for you. And if you need a spark, hit I'm feeling lucky and we'll help you get started. Head to a.studio/build studio/build to create your first app. >> Two for AI Labs is a research [music] lab based in Zurich. They've got a team of amazing ML engineers and research scientists. They're doing some really cool stuff. If you look at their website, [music] for example, you can see what their approach was for winning the ARC AGI 3 pub uh competition which closed out a few months ago and they are [music] hiring amazing ML engineers and research scientists. They also care deeply about AI safety. So if any of that is a fit for you, please go to Two for [music] AOLABS and uh give it a go. The audience will know I'm a huge fan of Kenneth Stanley's ideas. So his book, Why Greatness Cannot Be Planned, changed my life. It was absolutely insane. And what he was speaking to is that we need to allow people to follow their own gradient of interest unfettered by objectives and committees and and so on. Because that is how we do epistemic foraging. that when you have too many agendas involved in the mix, you kind of end up with a gray goo and you don't discover, you know, interesting novelty and diversity. And I suppose that's basically the thesis of of your company, Sakana, is to lean into those ideas. >> Yes, exactly. Um, at the company, we're a massive fan of that book. We're we're hoping to have him come and talk at our company next week, actually. And um it's a philosophy that we we do talk about internally, right? We have copies of the books in including the the recent Japanese translation. As you know, one of the co-founders, one of my my main jobs, one of the main things that I have to keep doing for this company is making sure that we protect the freedom that the researchers currently have, right? Because it's it's it's a it's a privilege really that we have the resources to be able to do that. And inevitably, as I've seen happen, as the company grows, more and more pressure comes in and it narrows the freedom. But I think because, you know, we we believe in this philosophy so strongly, I'm hoping that we can give people all the research freedom that we do now um for as long as possible. >> And what are those processes that curtail freedom as a company matures? I mean, how would you describe that? It's great that there's never been so much interest and people and talent and resources and money in the industry, but unfortunately that just increases the amount of pressure people have in order to compete with all the other people working on it and trying to get the the value out of this technology and making money. And I think that's what just happens, right? As a startup, you have a a feeling of, you know, excitement and trying something new. And right at the beginning, you have a bit of a runway. So, you have the freedom to try different things. But inevitably, people are starting to ask for returns on their investments or they're expecting you to churn out some product. And this just unfortunately reduces the uh the the creativity that that researchers have because you know the the the the pressures to publish or the pressure to to create technology that's actually useful for the products that we have goes up and so the feeling of autonomy I think starts to go down. But you know I literally tell people when they start working for the company I want you to work on what you think is interesting and important and I mean it there there is I mean in YouTube there's a phenomenon called audience capture >> right >> and I think there might be a phenomenon called technology capture which is that in the early days of Google it was quite open-ended and I mean transformers is now the ubiquitous backbone of all AI technology and it's a huge achievement that that you're involved in But I mean there's a similar story with with Open AI. They're now starting to see all of these commercialization opportunities. They they can I mean they're going to become LinkedIn. They're going to become an application platform. They're going to become a search platform. They're going to become a social network. And and I guess this could happen to you guys that there's a very strong chance, especially with your new paper that we're going to talk about today, this continuous thought machines. It it could be a revolutionary technology, but then it will become obvious how it could be commercialized. And that's how those pressures come in. >> I I like the I like the audience capture analogy. I think um there's definitely been some kind of capture by large language models, right? They they worked so well that everyone wanted to work on them. And I'm really worried that we're kind of stuck in this local minimum now, right? and we sort of need to try to try to escape it. So, we spoke about the transformers, but there's a there's a time just before the transformers that I'd like to talk about because I think it's quite illustrative. So, of course, the the main technology before transformers was recurrent neural networks, right? And there was a similar feeling, right? When recurrent neural networks came in and we we you know, we discovered this new sort of sequence of sequence learning, that was also a massive breakthrough, right? the the the the the translation quality went up massively, right? Um voice recognition uh quality went up massively. And there was this a similar sort of feeling then of like okay yes we've you know we found the technology and we just need to sort of perfect this technology and back then even my my favorite uh task was uh character level language modeling right so every time a new RNN based character level language modeling paper came out I got quite excited right um I you know I'd want to like quickly read the paper like okay how did they you know how did they get the improvements But the papers were always these just these slight modifications on the same architecture, right? It was LSTMs and GRUs and maybe um initializing it with the identity matrix to so that you could use the relu function or like maybe if you put the gate in a different place or if you if you layer them in a slightly different way or if you had gating going upwards as well as as sideways. Um, and I remember one of my favorites was this uh like hierarchical LSTM where it would actually decide to compute or not compute the different layers. And if you trained on Wikipedia and you looked at the structure of when it was decided to compute or not compute, it kind of looked like the structure of of the the sentences were actually being picked up by the model. And I used to love that sort of stuff, right? Um, but the the the the improvements were always like 1.26 bits per character, 1.25 bits per character, 1.24. That was a result that was publishable, right? That was exciting. But then after the transformer the team that I went on to afterwards right we applied for the first time very deep transformer models decoder only transformer models to language modeling and we immediately got something like 1.1 uh right so so something that was so good that people actually come to our desk and politely tell us like uh I think you you made a error like a calculation do you think it's nats not bits per character and we're like no no no we you know it really is the the the correct the correct number. What struck me later is that all of a sudden all of that research and to be clear very good research was suddenly made completely redundant. >> Yes. >> Right. All of those endless permutations to to RNN's were suddenly seemingly a waste of time. We're kind of in the situation right now where a lot of the papers are just taking the same architecture and making these endless amount of different tweaks of like you know where to put them normalization layer and slightly different ways of training them and and we might be wasting the time in exactly the same way right like I personally don't think we're done right I don't think that this is the final architecture and we just need to keep scaling up there's some breakthrough that will occur at some point and then it will once again become obvious that we're kind of wasting a lot of time right now. >> Yeah. So we are a victim of our own success and this basin of attraction there are so many basins of attraction. Sarah Hooker spoke about the hardware lottery and this is a kind of architecture lottery and it it it actually made me think of the um agricultural revolution which is that this kind of phase change happened and all of the folks that had these skills that were so necessary, these diverse skills for living and surviving, they died out. And that's actually quite paradoxical because we need those skills to take the next step. M >> and so we we're now in this regime we've got the term foundation model and the implication is that you can do anything with a foundation model in the corporate world we used to have data scientists you know they were ML engineers doing these architectural tweaks even in you know midsize enterprise and now we just have AI engineers who are just doing prompt engineering and so on. So you're saying that the fundamental skills that we need to be diverse to think of new solutions and new architectures, they're dying out. I think I'm going to disagree with that. I think the problem is we have plenty of very talented uh very creative researchers out there, but they're not using their talents. Right? For example, you know, if you're in academia, there's pressure to publish, right? And if there's pressure to publish, you think to yourself, okay, well, I have this really cool idea, but it might not work. It might be too weird, right? It might be difficult to get it accepted because I have to sort of like sell the idea more. Or I can just try this new positional embedding, right? The problem is that the current environment both in academia and in companies are not actually giving people the freedom that they need to do the research that they probably want to do. I >> mean there's also this interesting thing that even in spite of great new research I mean I was speaking to Seb Hoger and he's got all of these new architectural ideas and open AI aren't implementing them. I mean Google are doing this diffusion language model which is quite cool. And I I'd like to know your opinion on why that is. So there's a few philosophies floating around like this concept of a universal representation that there are universal patterns and the the transformer representations resemble those in the brain. And it's rather led to this idea of well we don't need to use different architectures because if we just have more scale and more compute then all roads lead to Rome. So why would we bother doing it any differently? >> There's actually better right? There is actually already architectures that have been shown in the research to work better than transformers. Okay. But not better enough in order to move the entire industry away from such an established architecture where you're familiar with it. You know how to train it. You know how it works. You know how the internals work, right? You know how to fine-tune them. You have all this software is already set up for training transformers. fine gening transformers inference. So if you want to move the industry away from that, being better is not good enough. It has to be obviously crushingly better. Transformers were that much better over RNNs. Okay, transformers where you just applied it to a new problem and it just was so so much faster to train and you just got such higher accuracy that you just had to move. And I think the deep the deep learning revolution was also another example of that, right? Where you had plenty of skeptics and people were pushing um neural networks even back then and people are going, \"No, we think symbolic stuff will work better.\" But then they demonstrated it as being so much better that you couldn't ignore it. This fact makes finding the next thing even harder. Right? That's the gravitational pole of always pull pulling you back to, oh, okay, but a transformer is good enough. And yeah, you made a cool little architecture over here that yeah, it looks like it's it's got better accuracy, but OpenAI over here just made it 10 times bigger and it beats that. So, let's just keep going. May I also submit that there could be an additional reason which is you know I love that fractured entangled representations paper. Um there's there's this shortcut learning problem and I think that there's a little bit of a mirage going on here and there there might be problems with these language models that we don't you know that we're not fully aware of and there's also this thing that we're seeing that we are starting to bastardize the architecture. So we know we need to have adaptive computation for reasoning. We know we want things like uncertainty quantification and what we're doing is is we're bolting these things on top rather than having an architecture which intrinsically does all of these things that we know we need. >> Yeah. And I and I think the the our continuous thought machine is is an attempt at addressing those um more directly, right? Which which Luke will be able to tell you more about later. There's something still not quite right with this the current technology, right? I I think the the phrase that's becoming popular is jagged intelligence, right? That the fact that you can ask an LLM something and it can solve literally like a PhD level problem and then you know in the next sentence it can say something just so clearly obviously wrong that it it's it's jarring, right? And I think this is actually a reflection of something probably quite fundamentally wrong with the current architecture. As amazing as they are, the current technology is actually too good. Okay. Another reason why it's it's difficult to move away from them, right? So they're too good in in in the following sense. And you you spoke about the fact that we have these foundation models. That's okay. so that we have the foundation that we can do anything with them. Yes, I think current neural networks are so powerful that if you have enough patience and enough compute and enough data, you can make them do anything. But I don't necessarily think that they want to, right? we're sort of forcing them like they're universal pro approximators but I think there are probably a space of you know function approximators that will more want to represent things in the way that a human represents them. So there's actually quite an obscure paper that is my poster child for this. It's called intelligence matrix exponentiation >> and I think it was actually rejected. So, you know, you can probably project uh the image of a figure one, but there's an image of it's solving, you know, the classical spiral data set of needing to separate the two classes in the spiral. >> Yes. >> And it has the decision boundary for a for both a classic RNN uh multi-layer perceptron and a tanh multi-layer perceptron. And you can see they both solve it, right? Technically, they both solve the problem because they they they classify all the points correctly and get a very good test score on this on this very simple data set. And then they show you the decision boundary for the for the M layer that they built in this paper and it's a spiral. The layer represented the spiral as a spiral. Sh shouldn't we should you know if the data is a spiral shouldn't we represent it as a spiral? And then if you look back at the decision boundaries for for the spiral and the classic relu multi-layer perceptron, it's clear that you just have these tiny little peacewise linear separations. Um, and that's what I mean. Yes, if you know if you train these things enough and you push these little peacewise linear boundaries around enough, it can it can fit the spiral and get a high accuracy. But there's no feeling when I look at those that that image that the relu version actually understands that it is a spiral, right? And when you represent it as a spiral, it actually extrapolates correctly because the spiral just keeps going out. >> You're touching on something fascinating there because, you know, we were talking about the need for adaptivity and um adaptive computation. Um I'm really inspired by Randall Bisreerero's spline theory of of neural networks and we we've had them on many times and you can look on the TensorFlow playground. You can look what happens when you have a ReLU network on on this, you know, spiral manifold. And, you know, you'd be forgiven for thinking that these things are basically a locality sensitive hashing table, right? Because they they do they they they they partition the space and and they they can predict the spiral manifold, right? But we want to do something a little bit more different than that. And it also comes into this imposttor thing because just tracing the spiral manifold but not continuing the pattern there's a big difference between that. So from an imposttor perspective just just tracing the pattern is not learning it abstractly or constructively. Right? If we learned it constructively so we you know you speak about this in your paper this complexification the abstract building blocks and you can do adaptive computation. you understand the spiral. That means that with adaptive computation, you can continue the spiral and then you can update the model's weights so it has adaptivity because that's so important for intelligence. So we know that we need models that can do these things. But for some reason they're they're so sick of fantic they're almost better than an adaptive intelligent system because they tell us exactly what we want to hear. They seem so intelligent, but we know that they're missing these fundamental properties. >> I'm still fairly skeptical when I see video generation models. You know, we went through a phase where you could detect them because of the number of fingers on somebody's hand, right? And yes, with more data, with more compute, with better training tricks, okay, they submit. And now they usually do have five fingers. But did we fix the problem or did we just use more brute force to just you know force the the neural network to know it's five fingers where something that actually had a much better kind of representation space. It's almost mad that it's controversial to say that we should represent a spiral like a spiral. But, you know, something that could do that generally that if if it represented a human hand the way that, you know, maybe I represent a human hand, then maybe it would be much easier to count how many fingers are on a on a hand. It's unfortunate that they work so well. It's unfortunate that scaling works so well because it's too easy for people to just sweep these problems under the carpet. You guys have possibly created what I think might be the best paper of of the year. This could actually be the innovation which takes us to the next step. And you did you get the spotlight in Europe as well? >> Yeah. >> This year and congratulations on that. So I think that's testament to how amazing this paper is. >> The CTM the continuous thought machine. It's actually not that far out outside of the local minimum that we're stuck in. Right? It's not as if we went and found this completely new technology. Right? We took quite a um a simple biologically inspired idea, right, of these of of the fact that neurons synchronize and not even necessarily in a biologically plausible way, right? Brains don't literally have all their neurons wired together in a way that they work out their synchronization. But it's it's the sort of research that I want to encourage people to do. And the way to sell it is quite easy. I think at no point did we have to worry about being scooped, right? That stress was taken away from us completely. So, and there was so there was no pressure to sort of rush out with this with this idea because we're like, well, there's probably somebody else working on exactly this. And I think the reason that we, you know, we were able to get a spotlight is because we're able to create such a polished paper. We took the time to do the science properly to get the the base the baselines that we wanted and do all the the the the tasks that we wanted to try. Encouraging researchers to take a little bit more of a of a risk, right? To try these slightly more speculative long-term ideas, I think is is the sad thing is I don't think it's necessarily a very difficult thing to sell. And I want to have the CTM as like a poster child of it works, right? It was a bit of a risk. We, you know, we didn't know if we were going to find something interesting, but you know, it was our first shot and we did find something interesting and it became a a successful paper. If if we do find a system which can acquire knowledge, design new architectures, do the the open-ended type of science that you're speaking to, can you see a future where at some point the locus of progress will be mostly driven by the models themselves? >> I think so. Whether or not that's going to replace us completely, I go back and forth on. Powerful algorithms are finding uh helping us do research, right? And I think it might just end up being a more powerful version of that. Right? So I I know the the AI scientist that we we released, we showed that you could actually go end to end, right? Go from seeding the system with an idea for a research paper and then just take your hands off and just let it go. Think about the idea, write the code, run the code, collect the results, and write the paper. uh to the point that we were actually able to get it to um a 100% AI generated paper accepted to to a workshop recently, right? But I think we did that to show that you could do it right as a sort of demonstration in a real system. I think I would want it to be much more interactive, right? I would want to be able to seed with an idea and then have it come back with more ideas, have a discussion with me, then go away to write the code. I want look at the code and check it and then discuss the results as they're coming out. So that's the sort of nearterm future that I that I would envision or how I would like to do research with an AI. >> And could you introspect on that? Is it because you feel we need supervision because the models don't yet understand? You know there's this path dependence idea. So we need to do supervision because we have the path dependence so we can guide the generation of the language models. Maybe in the future the language models will just understand better themselves. But there's also the output dimension which is that we want to produce artifacts that extend the fogyny of human interest. We want it to be human relevant. >> Yeah. I I think it's more that you know in that initial seed idea it's probably impossible to actually describe exactly what you want. It's exactly the same with, you know, when I have an intern. I can't just have an intern come into the company and I go, I have this mad idea and then just explain it to them and then just leave them alone for 4 months. There's a back and forth because I have a particular idea that I want to explore and I need to keep steering them in the direction that I I you know that I had in my my mind originally. So I think it's more like that basically. You have such a deep understanding. So you have this rich provenence and history and path dependence and that means you can take creative steps intuitive steps for you respect the fogyny. They respect all of this deep abstract understanding that you have and interns don't yet have that >> but maybe AI models in the future will have that. >> Yeah sure. If they if they get to the point where my inputs becomes detrimental then yeah that'll be a thing. It's kind of like chess, right? There was a point at which chess engine and human fusion actually beat chess engines. That's not that's not true anymore, right? Adding a human into the mix actually makes the the bots worse. >> Oh, interesting. I wasn't aware of that. >> Yeah. So, so what to do when that day comes for AI scientists is a is a is a broader discussion. I think >> I think now is a good segue to talk about this paper in a little bit more detail. So this continuous thought machines you were just pointing to it before. Luke first first of all first of all mate introduce yourself >> and set this thing up for us. >> My name is Luke. I am a research scientist at Sakana AI [snorts] and uh my primary sector of research is this continuous thought machines. It's took us somewhere in the region of about eight months working on this project with uh the whole team. Um I I did a lot of the work uh but we also had a lot of people in different areas and doing different parts of it that I think an 8-month life cycle for a paper seems a bit long for AI research at the moment. Um but yes to the to the actual technical points of the paper. So we call it continuous thought machines. It originally had a different name. We called it asynchronous thought machines before but uh every single time people asked us what's the asynchronous part it became a bit confusing. So continuous thought machines basically depends on three novelties. Uh the first one is having what we call a internal thought dimension and this is not necessarily something new. It's related conceptually to the ideas of latent reasoning. Uh and it's essentially applying compute in a sequential dimension. And when you start thinking about ideas and problems uh in this domain and in in this framework, you start understanding that many problems that look like intell or solutions to problems that look intelligent are often solutions that have a sequential nature. So for instance, one of the primary tasks that we tested in the continuous thought machines was this maze solving task. And solving mazes for deep learning is is quite trivial. It's really easy to do if you make the task easy for machines. And one of the ways to do this is you give an image of a maze to a neural network like a convolutional neural network and it outputs a image uh same size of the maze and it's uh zeros where there isn't a path and there's ones where there is a path. There's some really brilliant work showing how you can train these in a careful way and scale them up essentially indefinitely. And this is fascinating and uh really interesting idea of how to solve this. However, when you take that uh approach out of the picture and you ask what is a more human way to solve this problem, it becomes a sequential problem. You have to say well go up, go right, go up, go left, whatever the case may be to trace a route from start to finish. And when you constrain that simple problem space uh and you you ask a machine learning system to solve it like that turns out to actually get much much more challenging. So this became our hello world problem for the CTM and applying an internal sequential thought dimension to this is how we went about solving this. Uh two other novelties that we can touch on and talk about. Uh we we sort of rethought the idea of what neurons should be. There is a lot of excellent research in this world uh in cognitive neuroscience particularly exploring how neurons work in biological systems. And then we get on the other side of the scale how deep learning neurons work which the quintessential example is a relu. It's off or on in a sense. And this very very high level abstraction of neurons in the brains feels a little bit myopic. So we approached this problem and said well let's let's on a neuron by neuron basis let this neuron be a little model itself. And this ended up doing a lot of interesting work on how to build dynamics in the system. The third novelty here is as I said before we have this internal dimension over which thinking happens. We ask the question, well, what is the representation? What is the representation for a biological system when it's thinking? Is it just the state of the neurons at any given time? Does that capture a thought, if you wish, if I can be controversial and use the term thinking and thought and my philosophy with this is no, it doesn't. That the concept of a thought is something that exists over time. So, how do we capture that in in engineering speak? We instead of measuring the states of the model that is recurrent, we measure how it synchronizes how neurons synchronize in pairs along with other neurons. And this opens up the door to a huge array of things that we can do with this type of representation. >> You were talking about this um sort of sequential nature of of reasoning and devil's advocate. I mean there was that anthropic biology paper and they were talking about planning and thinking and and they they were they were saying that this thing is planning ahead because because I think your system actually we can say does planning it it's it's actually different computationally can you explain that >> yes I think the boundary in terms of computation from a a cheering machine perspective if you wish uh is really interesting because the notion of being able to write your tape uh read from a tape and then write again to be in a Ting compute system ting complete system is uh obviously an incredible idea that has completely changed the world and I think the primary difference with let's talk about transformers versus what we're trying to do with the CTM is that the process that the CTM thinks in we can apply that process that internal process to uh breaking down a problem. So the problem itself can be a single there is a single solution to this problem and you could do that in one shot. You could as I explained with the maze you could just process that in one shot but there are certain phrasings of problems that are real problems that doing so becomes exponentially more challenging. So in the maze task, a really good example is that if you try to predict 100 200 steps down the path in one shot, no models that we could train, not even our model could do that. And we needed to actually build an autocurriculum system where the model first predicted the first step and then when it could predict the first step, then it we started training it on the second and third and fourth step. And the sort of resultant behavior of this is where it gets interesting. One of the one of the ways that I like to do research and that I encourage people who work with me to do research is understand the if you wish the behavior of a model. We're getting to a point now where the models that we build are demonstrably intelligent in ways that keep surprising us and breaking that down into a single set of metrics or even a finite single metric about performance seems maybe not to be the right way to do it for me. and understanding the behavior and the actions that those models take when you put them in a system and train them in a certain way uh seems to reveal more about what's actually going on under the hood. >> Very cool. And I think I didn't pick up on this. So So you're you're doing a fixed number of um steps so you have like a a context window and did you say that you've set that around 100 steps? >> So for the for the maze task uh the model always observes the full image at every step. uh the CTM will absorb observe the full image for argument sake those images could be tokens from a language uh the output of a language model those uh inputs could be numbers that the model has to sort whatever the case may be it should be agnostic to data that's how we've tried to build it but in the maze task the model can continuously just observe the data uh no matter where it can look at the whole image simultaneously but it uses attention to retrieve information from the data and it has let's call it 100 steps that it can think through. And what we do is we pick up at some point the model solves three steps through the maze. So it says I'm going to go up, up, and right. And then it's correct. But then it makes the wrong turn. And at that point, we stop supervision. We only train it to solve the fourth step. So one more than what it could. In practice, we do it five, but the principle holds. And when you do that, it's a self bootstrapping mechanism. And I think the uh intuitive listener will understand how that extends to other domains, other sequential domains for instance like uh language prediction, many tokens ahead, that sort of thing. >> So I'm really interested in this idea of adaptive computation. So I I guess the first question is how sensitive was the performance to the number of steps and then the next question would be could you have an arbitrary number of steps which means that you know perhaps based on uncertainty or you know some kind of criterion you could do fewer steps and then the final question is could you have potentially like an arbitrary or unbounded number of steps >> yeah uh really super question I think that I think that I'll answer the uncertainty question first about the sensitivity to steps. So a very good example of this is we just trained the model on imageet classification and our last function is quite simple. What we do is we run it for for example 50 steps and we pick up two points two distinct points. The first one is where is it performing the best i.e. where is the loss the lowest and the second one is where is it most sure or where is it most certain and those give us two indices uh between 0 and 49 inclusive and we apply cross entropy at both of those points we just make the last the average of the cross entropy at those points. So what this does is it induces a behavior where easy examples are solved almost immediately in one or two steps whereas more challenging examples will naturally take more thinking and it enables the model to use the full breadth of time that it has available to it just in a natural fashion without having to force it to happen. So you've decided to model every neuron as an MLP which is really fascinating. Talk about that but also there's this notion of synchronization and I think you use the inner product to determine the extent to which the parameters are are synchronized and this kind of unfills over over time as as the driving force. Can you explain that in a bit more detail? >> Absolutely. I think it's a it's a good point to explain the uh neuron level models as we call them in the paper or NLM first because it ties into this. So you can imagine a recurrent system is a state vector, a state vector that is being updated from step to step. We track that state vector and that state vector unfolds and for each individual neuron, each uh I neuron in the system, we have a unfolding time series. It's a continuous time series. Well, it's discreet, but it's a continuous value. And those time series define what we call the activations over time. And synchronization is quite simply just measuring the dotproduct between two of these time series. So you have a system of d neurons and essentially you have d over two squared different synchronization pairs. So neuron one can be related to neuron 2 by how they synchronize and neuron one can also be related to neuron 3 etc etc. The neuron level models they function by taking in a finite history like a FOQ of neuron of activations coming in and instead of being just a radio activation they use that history as information to uh process a single activation out and that is what moves from what we call pre-activations to post activations. And the principle here is that this might seem rather arbitrary and does it help for performance? Turns out it does, but that's not really the catch all solution here. That's not what we're after. Uh what we're after here is trying to do something biologically plausible. Uh find the line somewhere between biology, which is how the brain implements things in the biological substrate that we have versus deep learning, which is highly parallelizable, super fast to learn, back propanable, all of the nice properties of that that have got us this far. and find a line somewhere where we can take some sprinkling of biological inspiration but still train it with deep learning. And it turns out that neuron level models is a nice interim that we can do this with. The concept of synchronization is applied on top of the outputs of those neuron level models. So on on this on the scaling the I think the time complexity is quadratic in respect of the dimension of the synchronization matrix right and in your paper you were talking about subsampling to improve the performance but how how did that affect the the stability and the you know like were there any things that that cost you doing that? Yeah, it's a neat question. I think in terms of stability, what's what we found was kind of fun and this was a sentiment that we had throughout the the experiments that we ran with this paper was it tended no matter what we tried it on it it just kind of worked with all spreads of hyperparameters. uh and this the problems that you have with back prop through time typically with recurrence models like RNNs and LSTMs it's a challenge and you run for many internal ticks with the RNNs or the LSTMs and the learning seems to break down but the uh fact that we use synchronization in some sense touches all of the neurons through all of the time so it really helps with gradient propagation uh a nice interesting point that's maybe a bit oblique to what you asked about synchronization is we have a system of d neurons and like I said earlier there d over two squared possible combinations. This essentially means that our underlying state or underlying representation to the system is quite a lot larger than what you would get with just taking those D neurons. And as to what that means in terms of downstream computation and performance and the things that we can do with this is what we're actively exploring right now. >> You guys used an exponential decay rate. >> You have the system that unfolds over time. it would be maybe a little bit too constrained if the synchronization between any two neurons depended on the same time scale. So for instance, there are neurons in your brain that are firing over very long time scales and very short time scales. The way that they fire together impacts other neurons and causes those neurons to fire. But everything in biological brains happens at diverse time scales. It's why we have uh different brain waves for different thinking states for instance. Uh but beside that point, what we do with the exponential decay in the continuous thought machines is it allows us for a very sharp decay to say that these two neurons that are pairing together, what only really matters is how they fire together right now. Right? But if we had a very long and slow decay, essentially that's capturing a global sense of how those neurons are firing over an extremely long period of time. So this was essentially a way of us uh capturing this idea of how different neurons could maybe fire together very quickly and other neurons can fire together very slowly or not at all. And this lets that representation space that I spoke about that D over2 squ representation space lets it again become more rich and we can enrich that space with more subtle tweaks to how we compute those representations. So we were speaking about this yesterday, Luke, that um when folks apply transformers to things like the ARC challenge or things that need reasoning. Um we need to do lots of domain specific hacks. So the architects who were the winners of last year's challenge, they did um depth first search sampling and some folks have been experimenting with using language representations or you know using um DSLs and some part of this is to do with the the the reachability um of language right and and language is is quite dense which means you can kind of monotonically um increase but if I understand correctly your system might have some interesting properties for reasoning and for discrete and sparse domains and also for sample efficiency because we want we want to build a system that can actually do well on things like the arc challenge. But can you kind of explain in simple terms why you think this architecture could be significantly better than transformers for doing those things? >> I think a lot of the really fascinating work in the last few years that I found fascinating in the literature of language models has been related to what one can actually call a new scaling dimension. I in some sense see continue uh chain of thought reasoning as a way of adding more compute to a system. That's obviously just one small part of what that really is and what that really means. But I think it's quite a profound breakthrough uh in some sense. Now what we're trying to do is is have that reasoning component be entirely internal yet still running in some sort of sequential manner. And I think that that's rather important. And you spoke earlier about Gemini's diffusion language modeling and I think that there are a lot of different directions that are exploring this right now. uh I do think that the continuous thought machine with the ideas of synchronization and multi-hierarchical temporal representations gives a certain flexibility on that space that uh other people are not yet exploring and that richness of that space being able to project the next step to solve the arc challenge and the next 100 the next 200 steps to be able to break that down into a process that a model can then uh very quickly search that process in its highdimensional latent case becomes something that feels like a good approach to take. >> Do you see any relationship between this architecture and you know Alex Graves neuro touring machine? >> Yes, that's really interesting. Um I do. I think that the one of the the most challenging parts about uh working with a neural neural touring machine is the concept of writing to memory and reading to memory because it is a discrete action. Um and that's that has its own challenges associated with it and yes uh I wouldn't go so far as to say that the continuous thought machine is definitively nearing Tur incomplete but the notion of [clears throat] the notion of doing reasoning in a space that is uh latent and letting that space unfold in a way that is uh rich towards a different set of tasks. And this this actually brings me to a point that I find quite interesting um that I'd like to share with you. Consider again the imageet task or any sort of uh classification task. It's it's a nice test bed. There are many images that are really easy and there are many images that are really difficult. When we train for instance a vit or a CNN uh to do this task, it has to nest all of that reasoning in the same space. It has to put all of its decision-m process for a very simple obvious cat versus some complex weird underrepresented class in that system in that data set and it has to nest it all in parallel in a way that is we get to the last layer and then we classify. Um I I think breaking that down where you have different points in time where you can say now I'm done I can stop versus now I'm done I can stop let you take a data set or take a task and actually naturally segment it into its easy to difficult components. And I think we know that curriculum learning and learning in this continuous sense again seems to be a good idea. It's it's how humans learn. And if we can get at that architecturally and just have that fall out in a model, again, this seems like a something worth exploring. Uh I'm not sure if you know much about model calibration and how neural networks tend to be poorly calibrated. >> Oh, go for it, Tommy. Um it's it's a bit of an old finding, but if you train a neural network for long enough and it fits really really well and you've regularized it regularized it really really well, you'll find that the model is unccalibrated, which essentially means that it is very certain uh about some components where some classes where it's wrong and uncertain for some classes where it's correct. Essentially what you want for a perfectly calibrated model is if it predicts a uh probability that this is in class the correct class with 50%. 50% of the time you want it to be correct about that class and so on and so forth. So a well-c calibrated model if it's predicting a probability of 0.9 that it is a cat then 90% of the time it should be correct. And it's actually turns out that most models that you train for long enough get poorly calibrated. And there are loads of post hawk tricks uh to fixing this. We measured the calibration of the CTM after training and it was nearly perfectly calibrated which is again a little bit of a smoking gun that this actually seems to be probably a better way to do things. The flavor of this kind of research is such that we didn't actually go out and actually try to create a very well-c calibrated model, right? And we didn't even try to create a model that was necessarily going to be able to do some kind of adaptive computation time, right? Um I was um a very big fan of the the paper um uh yeah adapted computation time was Alex Graves was it? But that paper um it had a massive amount of hyperparameter sweeps in it because in that paper he needed to have a loss on the amount of computation that was being done. >> Because anytime you try to do some sort of adaptive computation time research, what you're fighting is the fact that neural networks are greedy, right? because obviously the way to get the lowest loss is to use all the computation that you have access to. So unless you had like an extra loss that had a penalty that said okay actually you're not allowed to use all the computation that's and and very very carefully balance loss that's when you actually got the interesting dynamic computation time behavior falling out of the the model in that paper. But was really gratifying to see with the the continuous thought machine is that because of the way that we set up the loss that Luke described earlier, adaptive computation times seem to just fall out naturally. So that's more the way that I think research should go. >> Okay? because we we don't actually have like a specific goal um like or a specific problem we're trying to fix like that or something we're trying to invent. It's more that we have this interesting architecture and that we're just following the gradients of interestingness. >> Yes. And on on that point, I I think maybe the most exciting thing about your paper is, you know, we were talking about path dependence and um having this understanding which is built step by step, this process of complexification and u I mean maybe this is this is um apppropo in in the theme of world models in in general and also active inference and I say active inference in big quotes because it's not KL Friston's active you know maybe adaptive inference or something like that but we want to build agents that can continue to learn that can update their parameters and most importantly can construct path dependent understanding and because it that's completely different to just understanding what the thing is. It's how you got there is very important and this architecture potentially allows these agents using this algorithm to explore trajectories in spaces find the best trajectories and actually construct an understanding which carves the world up by the joints. Yeah, that's a that's a really neat perspective. I haven't actually thought about it like that, but yes, I think um that particular stance becomes really interesting when you think about ambiguous problems because carving the world up in one way is as performant as carving it up in another way. >> Yeah. uh you know perhaps the hallucination in language models is carving the world up in some fine way but it's just not performance in our measure of this is hallucination and actually that's not true but in some other trace down the path of wanting to carve the world up through a auto reggressive generation of tokens you end up in a different carve up of that world and being able to train a model that can be implicitly aware of the fact that it is actually carving up the world in a different way and and explore those manners, those uh descents down the carve up is something that we're after and I think it's quite an exciting approach to be trying to take a stance of let's let's break up this problem into small solvable parts and learn to do it like that and how can we do this in a natural way without too many hacks. Yeah, it's something I've been thinking about because um Shalet as much as I love his measure of intelligence um ideas is for him adapting to novelty is getting the right answer and the reason why you gave that answer is very very important and in machine learning we have this problem that we we come up with this kind of cost function that rather leads to this shortcut problem but you know we could just build a symbolic system we could be gi and and we could say okay we need do this um principled kind of construction of knowledge maintaining semantics. Well, we're not doing that. We're doing a hybrid system. But there must be some natural way of doing reasoning where in spite of the end objective being this cost function that because of the way that we traversed these open-ended spaces that we can actually have more confidence mechanistically that we're doing reasoning which is aligned to the world. I think that's a great way of seeing this particular uh avenue of research and I think that obviously we're not the only people thinking like this and we're not the only ones trying to do this. Um what we have is an architecture that's amanable to it and surprisingly so it wasn't again wasn't the goal. It's not the goal to to do this type of research. It's not the goal to be able to break the world down into these small uh chunks that we can actually reason over in in a way that seems natural. Instead, what we did was pay respect to the brain, pay respect to nature and say, well, if we build these inspired things, what what actually happens? What what different ways of approaching a problem emerge? And then when those different ways of approaching a problem emerge, what big philosophical and uh intelligence-based questions can we then start to ask? And that's where we're at right now. So it might feel at times, especially for me, uh too many questions and too few hands to answer those questions. But I think the fun and exciting thing and the encouraging thing that I I can you know try to encourage other younger researchers out there is that uh you know do what you're passion passionate about and figure out how to build the things that you care about and then see what that does. See what doors that opens up and see how to explore deeper into those domains. >> We were talking about this yesterday, weren't we? That you can think of language as being a kind of maze. >> Yes. like what is to stop us from taking this architecture and building the next generation language model with it. I mean that that's honestly as you know something that I am actively trying to explore right now and uh yeah I think the maze the maze task gets really interesting when you add ambiguity to it when there are many ways to solve the maze and honestly this isn't something I've tried yet and maybe it's something I should try next week but it's essentially you can imagine an agent or the CTM in this case observing the maze and taking a trajectory and surprisingly we saw this we have a section in our recently updated paper on AR archive the final camera ready version of this paper where we added an extra supplementary section that is not in the main technical report and that supplementary section is basically hey we saw this cool stuff happen and we list I think 14 different interesting things that happened while we were doing the research um that obviously didn't make it into the paper but we wanted people to know about these strange things that happened and this is one of the strange things where uh we watched during training what was happening. And at some time during training, maybe halfway through the training run, we could see what the model would do is it would start going one path in the maze and then suddenly it would realize, oh no, damn, I'm wrong. And would backtrack and then take another path. But eventually it gets really good and it does you some sort of distributed learning in this because it's got a attention mechanism with multiple heads. So it can actually just figure out how to do this pretty well and refine its solution. But sometime early on in the the learning it descends multiple paths and comes back and backtracks. We have a really fascinating set of experiments that also showed and this this we actually have some supplementary material online showing this where uh and I don't really know what this says. It's kind of a deep philosophical thing but if you're trying to solve a maze but you don't have enough time. Turns out that there's a there's a foster algorithm to do it. And this was this blew my mind when I saw it. So if we constrain the amount of thinking time that the model has but still get it to try solve a long maze instead of tracing out that maze, what it does is it quickly jumps ahead to approximately where it needs to be and it traces backwards and it fills in that path backwards and then it jumps forward again leaprogs over the top and traces that section backwards and then leap frogs and it does this fascinating leaprogging behavior that is based on the constraint of the system. And again, you know, this is just an observation we made and what that means uh in a deep sense and how it's related to uh giving a model time to think versus not and is it enough time to think? What happens? What different algorithms does the model learn when you constrain it in this way? I find that quite fascinating and an interesting thing to explore. Does it tell us something about how humans think? Does it tell us something about how how we think under constrained settings versus open-ended settings? There's a number of cool questions you can ask on this front. >> You you guys are both huge fans of um you know population methods and collective intelligence and because we can we can scale this thing up and we can scale it out and what would it mean to scale this thing out not only just in a kind of um what do they call it trivial paralization but in terms of having some kind of weight sharing between parallel models and so on. What what what would uh what would that give you potentially? >> Uh this is this is a fun area of research. So one of the active things that we're trying to explore in our team is uh concepts of memory long-term memory and what what does this mean for a system like this? So an experiment that one can construct for instance is to put some agents in a maze and let them try solve this maze not not how we did it in the paper but in a very constrained setting where a agent can only see maybe a 5x5 region around it and we give that agent some mechanism for saving and retrieving memories and the task if you wish is to solve that maze find your way to the end and the model needs to learn how to construct memory such that it can get back to a point where it's seen before and know I did the wrong thing last time and go a different route and you can then see this with uh parallel agents in the same maze with a shared memory structure and see what actually happens when you can all access that memory structure and have a shared global like almost like a cultural memory that we can access and solve this global task by having many agents trying to use this memory system and I do think that memory is going to be a very key element to what we need to do in the future for AI in general. >> So the subject of uh reasoning came up just a second ago and I think there's a perception that recently we made a lot of progress in reasoning right because it's actually one of the main things that I think people are are working on. We released a data set recently called uh Sudoku bench and I was actually quite happy to see it come up organically on your uh podcast a few weeks ago. [snorts] >> Chris Moore, >> right? >> Yes. So, I I wanted to tell you a little bit about this benchmark because I think I've been having a little bit of issue promoting it because it doesn't on the surface sound particularly interesting because Sudoku has a sort of a feeling that it's already been solved, right? So, how interesting can a collection of of Sudokus be for reasoning? Exactly. We're not talking about normal sedokus. We're talking about variant sodokas. And what variant sodokas are are usually normal sedokus, right? So put the numbers one to nine in the row, the column, and the box, but then literally any additional rules on top of that. And they're all handcrafted. they all have extremely different constraints. Um constraints that actually require very strong natural language understanding. So for example, there's one puzzle in the data set where it tells you the constraints of the puzzle in natural language and then says, \"Oh, by the way, one of the numbers in that description is wrong.\" Right? So you have to be able to meta reason about the rules themselves even before you start uh solving the puzzle. There are other puzzles where you have um a maze overlaid on the sodoku and the rat has to work out a way through the maze by following uh a path to the cheese. But then there are constraints on the path that it takes of like what numbers and what they can be add up to. Um it's difficult to really describe how varied these these uh these variants sedokas are and I think they're so varied that if anyone was actually be able to beat our benchmark they would necessarily have to have created an extremely powerful reasoning system. Right now, the best models um get around 15%, but they're only the very very simplest and the very uh smallest Sudoka puzzles in in the set. Um we're going to be putting out a blog post about um GPT5's performance and it is a jump but it's still completely unable to solve puzzles which are you know humans can can solve. And what I really like about this data uh data set um and actually was the catalyst for me creating it in the first place it was that there was a there was a quote by Andre Kapathy saying okay so we have all this data it's from the internet um but what you really want right if you wanted AGI you wouldn't want all of the text that humans have ever created you would actually want the thought traces in their head as they were creating the text, right? If you could actually learn from that, then you would get something really powerful. And I thought to myself, well, that data must exist somewhere. My first thought was maybe philosophy like uh you know there's there's a type of philosophy where you just write down your thoughts without thinking like just stream of consciousness. I thought maybe that could work. Um, but then when I wasn't thinking about it and I was, you know, in my leisure time, I was watching a YouTube channel called Cracking the Cryptic. >> Yes. >> Where these uh these two British gentlemen will solve these extremely difficult Sudoku puzzles for you. Right. Sometimes their their videos are four hours long and they they're professionals like this is their job. And what was perfect I realized is they tell you in agonizing detail exactly what reasoning they used to solve those particular puzzles. Right? So we with their permission took all of their videos which represents thousands of hours of very high quality human reasoning like thought traces and scraped them and made that available for imitation learning. Right? Um we did try to do this internally. Turns out that I did a little bit too much of a good job of really creating a very difficult benchmark. Right. So, we're still trying to get that stuff working and we'll publish it that if we if we have some success. Um, yeah, I want to I want to really sell the fact that this this reasoning benchmark really is different, right? Not only do you get something that's super grounded, like you know exactly if it's right or wrong, so you can do RL to your heart's consent, but you can't generalize very easily. Each puzzle is deliberately designed by hand to have a new and unique twist on the rules called a breakin that you have to understand. And right now, despite all the progress we've made, the current AI models can't take that leap. They can't find these breakins, right? They'll fall back to, okay, I'll try no, I'll try five, I'll try six, I'll try seven, right? The the reasoning becomes really boring and nothing like what you see in the transcripts that we've we've open sourced from this from this YouTube channel. So I just want to put the challenge out there right that this this is a a really difficult benchmark and I think progress on this benchmark will really mean progress in AI generally. >> Could you reflect a bit so after watching this um Cracking the Cryptic YouTube channel? How diverse were the patterns? Because um Chris was saying to me, oh you know these guys they go on Discord servers, they get these creative crazy ideas and I'm I'm obsessed. Maybe it maybe I'm just being idealistic, but I love this idea of there being a deductive closure of knowledge, right? That that there's this big tree of of reasoning and we're all in possession of different parts of the tree to different depths. So the smarter and the more knowledgeable you are, the deeper down the tree you go. But in this idealized form, there is one tree and all knowledge kind of, you know, originates or emanates from these abstract principles. And we could in principle build reasoning engines that could just reason from first principles and it might be um computationally irreducible. So so you have to perform all of the steps. And it feels like because we're not in possession of the full tree. What we need to do is kind of fish around. We fish around to find Lego blocks. Oh, that's a good Lego block. I can apply that to this problem. And maybe that's just what we need to do in AI for the time being is is is we need to just acquire as much of the tree as possible. But could could we just do it all the way down? >> Yeah, fascinating question. That tree is probably massive, right? >> And as a human is solving these puzzles, they're definitely learning in real time and discovering new parts of this tree. And it's it's sort of a meta task, right? Because it's not just reasoning, you're reasoning about the reasoning. And I don't think we can. We have that in AI right now. Because if you watch the videos, they'll say something like, \"Okay, this looks like a parask or this is a set theoretic problem or, you know, maybe I should get my path tool out and trace this this around.\" And of course the professionals they do have this this already massive collection of reasoning Lego blocks as you say in their head. So they'll recognize okay that type of rule usually needs this kind of Lego block. It's actually fascinating to watch how good they are at just intuitively knowing where you know someone like me haven't solved as many needs to spend a lot of time looking around like okay maybe I should try this or maybe I try this one. Um, but even they're not perfect. So, you can watch them take a certain kind of reasoning and start building up. Okay, maybe we should solve it like this and then go and know that doesn't disambiguate it enough and then backtrack and then go down another path. Again, something that we do not see current AI doing when they're trying to solve uh this this benchmark. the the tree is very big and I guess the phoggenetic distance between many of these motifs in in the tree is just so large. So it's so difficult to jump between and and and I and I think that's why as a collective intelligence we work so well together because we actually find ways to jump to different parts of the tree, >> right? And I and I think that's probably why the RL the the current state of the RL algorithms that we're trying to apply to this just isn't working because in order to learn how to get these breakthroughs to to understand what the sort of nuance reasoning is to get these puzzles, you have to sample them. And that it's it's such a rare space, you know, it's it's such an specific kind of reasoning that's required to get to the the specific breakthrough that this kind of [snorts] technique doesn't work, right? And there's definitely a feeling in the community like, okay, this is how you just solve things now. Like we have RL, yes, we can get these language models to do what we want. It doesn't work for this for this data set. >> Guys, it's been an absolute honor having you on the show. Just before we go, are you hiring? Because we've got a we've got a great audience of ML engineers and scientists and um I think working for Zakano would be the dream job. >> That's very kind of you. Yes, we are definitely hiring and as I said earlier in this interview, I honestly want to give people as much research freedom as possible. I'm willing to make that bet, right? I think things that are very interesting will come out of this. And I think we've already seen plenty of interesting things coming out of this. So if you want to work on what you think is interesting and important, come to Japan. >> And Japan just happens to be the most civilized culture in the world. [laughter] >> All right. >> It might be the opportunity of a lifetime, folks. So um yeah, get in touch, guys. Seriously, thank you so much. It's been an honor having you both on the show. >> Thank you very much. >> Thank you so much. It's been great.",
  "fetchedAt": "2026-01-18T18:32:21.288Z"
}