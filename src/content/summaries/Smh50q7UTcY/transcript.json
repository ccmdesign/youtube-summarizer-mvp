{
  "videoId": "Smh50q7UTcY",
  "language": "en",
  "source": "caption-extractor",
  "segments": [
    {
      "start": 0.24,
      "duration": 3.439,
      "text": "Two weeks into the new year and the new"
    },
    {
      "start": 1.839,
      "duration": 3.601,
      "text": "model rumor mill is starting to heat up"
    },
    {
      "start": 3.679,
      "duration": 5.201,
      "text": "as people are sharing rumors of a"
    },
    {
      "start": 5.44,
      "duration": 5.36,
      "text": "forthcoming and new chat GBT model."
    },
    {
      "start": 8.88,
      "duration": 3.679,
      "text": "Welcome back to the AI daily brief."
    },
    {
      "start": 10.8,
      "duration": 4.16,
      "text": "Today we are talking about the latest"
    },
    {
      "start": 12.559,
      "duration": 4.241,
      "text": "leaks/ rumors about the next chat GBT"
    },
    {
      "start": 14.96,
      "duration": 4.479,
      "text": "model. But I think it's important to put"
    },
    {
      "start": 16.8,
      "duration": 4.319,
      "text": "all of this in its proper context. Let's"
    },
    {
      "start": 19.439,
      "duration": 4.241,
      "text": "do a quick hit of the last 5 months of"
    },
    {
      "start": 21.119,
      "duration": 4.4,
      "text": "OpenAI model releases. Things started"
    },
    {
      "start": 23.68,
      "duration": 4,
      "text": "pretty inospiciously in August with the"
    },
    {
      "start": 25.519,
      "duration": 4,
      "text": "release of GPT5. Now, we've gone over"
    },
    {
      "start": 27.68,
      "duration": 4.64,
      "text": "lots of times all of the problems with"
    },
    {
      "start": 29.519,
      "duration": 5.121,
      "text": "the GPT5 release. One very big problem"
    },
    {
      "start": 32.32,
      "duration": 3.68,
      "text": "was the deprecation of 40 alongside it,"
    },
    {
      "start": 34.64,
      "duration": 2.56,
      "text": "which had people angry at them for"
    },
    {
      "start": 36,
      "duration": 2.96,
      "text": "reasons that had nothing to do with the"
    },
    {
      "start": 37.2,
      "duration": 3.12,
      "text": "model's performance and everything to do"
    },
    {
      "start": 38.96,
      "duration": 3.439,
      "text": "with other changes that were being made"
    },
    {
      "start": 40.32,
      "duration": 3.759,
      "text": "at the same time. We've also discussed"
    },
    {
      "start": 42.399,
      "duration": 4.801,
      "text": "how if they had simply called their"
    },
    {
      "start": 44.079,
      "duration": 4.64,
      "text": "biggest reasoning models like 03 GBT,"
    },
    {
      "start": 47.2,
      "duration": 2.879,
      "text": "the perception of the performance jump"
    },
    {
      "start": 48.719,
      "duration": 2.561,
      "text": "might have been very different."
    },
    {
      "start": 50.079,
      "duration": 2.561,
      "text": "Basically, in some ways, they were kind"
    },
    {
      "start": 51.28,
      "duration": 2.88,
      "text": "of a victim of their own making."
    },
    {
      "start": 52.64,
      "duration": 3.28,
      "text": "Whatever the case, the context it came"
    },
    {
      "start": 54.16,
      "duration": 3.919,
      "text": "into was not a great moment for the"
    },
    {
      "start": 55.92,
      "duration": 3.76,
      "text": "narrative around AI, and GBD5 did"
    },
    {
      "start": 58.079,
      "duration": 3.361,
      "text": "nothing to alleviate that. That's when"
    },
    {
      "start": 59.68,
      "duration": 3.519,
      "text": "we were getting these, in retrospect,"
    },
    {
      "start": 61.44,
      "duration": 3.999,
      "text": "very silly opeds in publications like"
    },
    {
      "start": 63.199,
      "duration": 4.24,
      "text": "The New Yorker, what if AI doesn't get"
    },
    {
      "start": 65.439,
      "duration": 3.201,
      "text": "much better than this? Fast forward a"
    },
    {
      "start": 67.439,
      "duration": 2.961,
      "text": "couple months, and the pressure was on"
    },
    {
      "start": 68.64,
      "duration": 3.04,
      "text": "for Google to deliver. There was a while"
    },
    {
      "start": 70.4,
      "duration": 2.96,
      "text": "there where I wasn't even sure that"
    },
    {
      "start": 71.68,
      "duration": 3.439,
      "text": "Google was actually going to drop Gemini"
    },
    {
      "start": 73.36,
      "duration": 2.96,
      "text": "3 in November because of the amount of"
    },
    {
      "start": 75.119,
      "duration": 3.04,
      "text": "pressure they were under to get it"
    },
    {
      "start": 76.32,
      "duration": 3.439,
      "text": "right. But get it right they did. At"
    },
    {
      "start": 78.159,
      "duration": 3.921,
      "text": "least in the court of public opinion."
    },
    {
      "start": 79.759,
      "duration": 4.081,
      "text": "When Gemini 3 came out, people were"
    },
    {
      "start": 82.08,
      "duration": 3.52,
      "text": "extremely excited about it. They were"
    },
    {
      "start": 83.84,
      "duration": 3.279,
      "text": "impressed with Gemini 3 Pro as a model"
    },
    {
      "start": 85.6,
      "duration": 3.6,
      "text": "for their intellectual and work tasks."
    },
    {
      "start": 87.119,
      "duration": 4.161,
      "text": "And of course, Nano Banana Pro's ability"
    },
    {
      "start": 89.2,
      "duration": 4.16,
      "text": "to make infographics opened up all sorts"
    },
    {
      "start": 91.28,
      "duration": 3.68,
      "text": "of totally new possible use cases. It"
    },
    {
      "start": 93.36,
      "duration": 3.84,
      "text": "turns out that OpenAI knew they were in"
    },
    {
      "start": 94.96,
      "duration": 3.92,
      "text": "for a rough patch. Back in October, it"
    },
    {
      "start": 97.2,
      "duration": 3.68,
      "text": "turns out Sam Alman had warned some"
    },
    {
      "start": 98.88,
      "duration": 3.599,
      "text": "staff in a memo that he expected some"
    },
    {
      "start": 100.88,
      "duration": 3.68,
      "text": "rough vibes around the launch of"
    },
    {
      "start": 102.479,
      "duration": 3.761,
      "text": "Google's new models. Rough vibes they"
    },
    {
      "start": 104.56,
      "duration": 4.08,
      "text": "got, ultimately leading to Alman and the"
    },
    {
      "start": 106.24,
      "duration": 4.48,
      "text": "team at OpenAI declaring a code red. Now"
    },
    {
      "start": 108.64,
      "duration": 4,
      "text": "what this code red meant in short was a"
    },
    {
      "start": 110.72,
      "duration": 3.439,
      "text": "sessation or at least a slowdown of work"
    },
    {
      "start": 112.64,
      "duration": 3.36,
      "text": "on a lot of ancillary features and"
    },
    {
      "start": 114.159,
      "duration": 3.841,
      "text": "products to double triple quadruple down"
    },
    {
      "start": 116,
      "duration": 3.68,
      "text": "on core chatbt features including the"
    },
    {
      "start": 118,
      "duration": 4.719,
      "text": "models underneath powering it. That got"
    },
    {
      "start": 119.68,
      "duration": 5.039,
      "text": "us to GBT 5.2 as well as the new chatbt"
    },
    {
      "start": 122.719,
      "duration": 4.641,
      "text": "images model which is it should be noted"
    },
    {
      "start": 124.719,
      "duration": 5.68,
      "text": "a 1.5 model not a full jump to image gen"
    },
    {
      "start": 127.36,
      "duration": 5.519,
      "text": "2. Now 52 and the new chatbt Images are"
    },
    {
      "start": 130.399,
      "duration": 4.321,
      "text": "good models. 52 Pro in particular is"
    },
    {
      "start": 132.879,
      "duration": 3.041,
      "text": "very much in my regular rotation and"
    },
    {
      "start": 134.72,
      "duration": 2.64,
      "text": "when it comes to a lot of heavy"
    },
    {
      "start": 135.92,
      "duration": 3.36,
      "text": "intellectual work, there are many folks"
    },
    {
      "start": 137.36,
      "duration": 3.519,
      "text": "who swear by it. Images frankly was"
    },
    {
      "start": 139.28,
      "duration": 2.959,
      "text": "better than I expected given how much"
    },
    {
      "start": 140.879,
      "duration": 3.121,
      "text": "pressure they had to put that out given"
    },
    {
      "start": 142.239,
      "duration": 3.841,
      "text": "Nano Banana Pro. And so even though"
    },
    {
      "start": 144,
      "duration": 3.84,
      "text": "Gemini and Google had really won a ton"
    },
    {
      "start": 146.08,
      "duration": 4.159,
      "text": "of momentum, I do think that the chat"
    },
    {
      "start": 147.84,
      "duration": 4.16,
      "text": "GPT releases in December maybe didn't"
    },
    {
      "start": 150.239,
      "duration": 3.28,
      "text": "fully stem the bleeding, but for people"
    },
    {
      "start": 152,
      "duration": 3.2,
      "text": "who weren't interested in the horse race"
    },
    {
      "start": 153.519,
      "duration": 3.201,
      "text": "and just wanted high performing models,"
    },
    {
      "start": 155.2,
      "duration": 3.52,
      "text": "you felt very lucky with all the options"
    },
    {
      "start": 156.72,
      "duration": 3.84,
      "text": "you had over the holiday season. But"
    },
    {
      "start": 158.72,
      "duration": 4.32,
      "text": "then of course around all of this was"
    },
    {
      "start": 160.56,
      "duration": 4.56,
      "text": "Claude Opus 4.5. The opinion on this"
    },
    {
      "start": 163.04,
      "duration": 4.32,
      "text": "model has done nothing but go up and up"
    },
    {
      "start": 165.12,
      "duration": 4.08,
      "text": "and up and up. So much so that in a"
    },
    {
      "start": 167.36,
      "duration": 3.04,
      "text": "lastminute upset I actually said that I"
    },
    {
      "start": 169.2,
      "duration": 3.6,
      "text": "thought it might end up being the most"
    },
    {
      "start": 170.4,
      "duration": 3.839,
      "text": "important model release of 2025. And so"
    },
    {
      "start": 172.8,
      "duration": 4.48,
      "text": "far at least I think that argument is"
    },
    {
      "start": 174.239,
      "duration": 4.401,
      "text": "holding up. Cloud code, Opus 4.5 and AGI"
    },
    {
      "start": 177.28,
      "duration": 3.12,
      "text": "are terms that are very frequent"
    },
    {
      "start": 178.64,
      "duration": 3.92,
      "text": "co-inhabitants right now of tweets and"
    },
    {
      "start": 180.4,
      "duration": 3.6,
      "text": "posts on social networks. Since the"
    },
    {
      "start": 182.56,
      "duration": 3.679,
      "text": "beginning of the year, these companies"
    },
    {
      "start": 184,
      "duration": 4.08,
      "text": "have not slowed down. In a major move to"
    },
    {
      "start": 186.239,
      "duration": 3.92,
      "text": "bring cloud code to everybody else,"
    },
    {
      "start": 188.08,
      "duration": 3.28,
      "text": "Anthropic released Co-work, tripling"
    },
    {
      "start": 190.159,
      "duration": 2.641,
      "text": "down in that way on their source of"
    },
    {
      "start": 191.36,
      "duration": 2.64,
      "text": "narrative momentum, while Google and"
    },
    {
      "start": 192.8,
      "duration": 2.799,
      "text": "Apple announced the deal that was"
    },
    {
      "start": 194,
      "duration": 2.879,
      "text": "reported at the end of last year that"
    },
    {
      "start": 195.599,
      "duration": 3.201,
      "text": "forthcoming versions of Apple"
    },
    {
      "start": 196.879,
      "duration": 4.321,
      "text": "intelligence will be powered in fact by"
    },
    {
      "start": 198.8,
      "duration": 3.68,
      "text": "Gemini models. All of this has led to a"
    },
    {
      "start": 201.2,
      "duration": 3.679,
      "text": "sense of a lot of momentum around"
    },
    {
      "start": 202.48,
      "duration": 4.56,
      "text": "Anthropic and Google and kind of less so"
    },
    {
      "start": 204.879,
      "duration": 4.241,
      "text": "around OpenAI. In fact, last night I"
    },
    {
      "start": 207.04,
      "duration": 4.24,
      "text": "tweeted that OpenAI seemed to me to be"
    },
    {
      "start": 209.12,
      "duration": 3.839,
      "text": "almost conspicuously quiet, which"
    },
    {
      "start": 211.28,
      "duration": 4,
      "text": "perhaps isn't totally fair given that"
    },
    {
      "start": 212.959,
      "duration": 4.241,
      "text": "they announced a major product in CHBT"
    },
    {
      "start": 215.28,
      "duration": 3.92,
      "text": "health. But still, it feels to me both"
    },
    {
      "start": 217.2,
      "duration": 4.08,
      "text": "like something is percolating and also"
    },
    {
      "start": 219.2,
      "duration": 4.08,
      "text": "that perhaps the company decided to try"
    },
    {
      "start": 221.28,
      "duration": 5.2,
      "text": "to do a little bit less vague posting in"
    },
    {
      "start": 223.28,
      "duration": 5.36,
      "text": "this new 2026 year. Yesterday, the rumor"
    },
    {
      "start": 226.48,
      "duration": 4.64,
      "text": "mill kicked back up in a big way. Dan"
    },
    {
      "start": 228.64,
      "duration": 4.159,
      "text": "Mack tweeted, \"GBT 53 cenamed garlic"
    },
    {
      "start": 231.12,
      "duration": 3.52,
      "text": "coming soon.\" According to a source, a"
    },
    {
      "start": 232.799,
      "duration": 3.841,
      "text": "very reliable source batting a thousand,"
    },
    {
      "start": 234.64,
      "duration": 4.08,
      "text": "expected to be a doozy, likely with"
    },
    {
      "start": 236.64,
      "duration": 4.08,
      "text": "stronger pre-training and the IMO gold"
    },
    {
      "start": 238.72,
      "duration": 3.519,
      "text": "winning reasoning techniques, the AI"
    },
    {
      "start": 240.72,
      "duration": 2.96,
      "text": "leaker account I rule the world"
    },
    {
      "start": 242.239,
      "duration": 3.36,
      "text": "responded saying that they had also"
    },
    {
      "start": 243.68,
      "duration": 3.04,
      "text": "heard this month and in a separate post"
    },
    {
      "start": 245.599,
      "duration": 3.441,
      "text": "shared something that they had told"
    },
    {
      "start": 246.72,
      "duration": 4,
      "text": "subscribers back in December that the 52"
    },
    {
      "start": 249.04,
      "duration": 3.119,
      "text": "model that we got was a quote rushed"
    },
    {
      "start": 250.72,
      "duration": 3.36,
      "text": "early checkpoint and that the full model"
    },
    {
      "start": 252.159,
      "duration": 3.36,
      "text": "is going to drop in January. Other"
    },
    {
      "start": 254.08,
      "duration": 3.279,
      "text": "speculation is that the model will be"
    },
    {
      "start": 255.519,
      "duration": 3.361,
      "text": "multimodal, generating both images and"
    },
    {
      "start": 257.359,
      "duration": 3.201,
      "text": "audio. Although no one seems quite clear"
    },
    {
      "start": 258.88,
      "duration": 3.84,
      "text": "on the naming conventions, whether it"
    },
    {
      "start": 260.56,
      "duration": 3.68,
      "text": "will be GPT55 or even something like"
    },
    {
      "start": 262.72,
      "duration": 2.96,
      "text": "GPT53."
    },
    {
      "start": 264.24,
      "duration": 3.28,
      "text": "And of course, while these are all just"
    },
    {
      "start": 265.68,
      "duration": 3.36,
      "text": "rumors, although rumors with sourcing,"
    },
    {
      "start": 267.52,
      "duration": 3.2,
      "text": "there is also starting to be some"
    },
    {
      "start": 269.04,
      "duration": 3.76,
      "text": "evidence that some newness might be"
    },
    {
      "start": 270.72,
      "duration": 4,
      "text": "percolating and poking through. Andrew"
    },
    {
      "start": 272.8,
      "duration": 3.6,
      "text": "Curran tweeted, \"My chat is acting quite"
    },
    {
      "start": 274.72,
      "duration": 3.28,
      "text": "differently as of last night. I assumed"
    },
    {
      "start": 276.4,
      "duration": 3.04,
      "text": "it was part of a new personality test"
    },
    {
      "start": 278,
      "duration": 3.52,
      "text": "group. This has happened many times over"
    },
    {
      "start": 279.44,
      "duration": 3.68,
      "text": "the last couple of months. OpenAI did"
    },
    {
      "start": 281.52,
      "duration": 3.52,
      "text": "say the next big update would make five"
    },
    {
      "start": 283.12,
      "duration": 4.4,
      "text": "more personable. It's possible it's"
    },
    {
      "start": 285.04,
      "duration": 4.4,
      "text": "about to arrive. Now, maybe I am wrong"
    },
    {
      "start": 287.52,
      "duration": 3.92,
      "text": "about the vague tweeting given that VB"
    },
    {
      "start": 289.44,
      "duration": 3.759,
      "text": "from OpenAI's developer experience team"
    },
    {
      "start": 291.44,
      "duration": 3.36,
      "text": "posted the eyes emoji getting everyone"
    },
    {
      "start": 293.199,
      "duration": 3.841,
      "text": "talking as part of this conversation as"
    },
    {
      "start": 294.8,
      "duration": 4,
      "text": "well. Obviously, anytime we get a new"
    },
    {
      "start": 297.04,
      "duration": 3.12,
      "text": "model, it's a very exciting moment. And"
    },
    {
      "start": 298.8,
      "duration": 3.119,
      "text": "certainly with the stakes as high as"
    },
    {
      "start": 300.16,
      "duration": 3.36,
      "text": "they are, I would love to see a big"
    },
    {
      "start": 301.919,
      "duration": 4.081,
      "text": "powerful effort drop that shakes the"
    },
    {
      "start": 303.52,
      "duration": 3.92,
      "text": "race up once again. Now, believe it or"
    },
    {
      "start": 306,
      "duration": 3.6,
      "text": "not, that wasn't the only information in"
    },
    {
      "start": 307.44,
      "duration": 3.92,
      "text": "the AI rumor mill. A Chinese consumer"
    },
    {
      "start": 309.6,
      "duration": 3.599,
      "text": "electronics blogger has a new leak from"
    },
    {
      "start": 311.36,
      "duration": 3.76,
      "text": "their contacts and the supply chain."
    },
    {
      "start": 313.199,
      "duration": 4.081,
      "text": "They wrote, \"Hearing fresh detail on"
    },
    {
      "start": 315.12,
      "duration": 4.079,
      "text": "OpenAI to go hardware project from last"
    },
    {
      "start": 317.28,
      "duration": 3.759,
      "text": "report, now confirmed it's a special"
    },
    {
      "start": 319.199,
      "duration": 3.84,
      "text": "audio product to replace AirPod."
    },
    {
      "start": 321.039,
      "duration": 3.681,
      "text": "Internal code name is Sweet Pee. On"
    },
    {
      "start": 323.039,
      "duration": 3.281,
      "text": "manufacturing, Foxcon has been told to"
    },
    {
      "start": 324.72,
      "duration": 4,
      "text": "prepare for a total of five devices by"
    },
    {
      "start": 326.32,
      "duration": 3.84,
      "text": "Q4 2028. All are not known, but a"
    },
    {
      "start": 328.72,
      "duration": 3.12,
      "text": "homestyle device and pen are still"
    },
    {
      "start": 330.16,
      "duration": 3.68,
      "text": "considered. However, many sources"
    },
    {
      "start": 331.84,
      "duration": 3.28,
      "text": "repeated the same thing. Sweet Pea is"
    },
    {
      "start": 333.84,
      "duration": 3.199,
      "text": "now front of the line due to the"
    },
    {
      "start": 335.12,
      "duration": 3.2,
      "text": "priority of the Johnny IV team. The"
    },
    {
      "start": 337.039,
      "duration": 3.681,
      "text": "release has been told to be near"
    },
    {
      "start": 338.32,
      "duration": 4.24,
      "text": "September. Volume projection 40 to 50"
    },
    {
      "start": 340.72,
      "duration": 3.84,
      "text": "million in the first year. Only some"
    },
    {
      "start": 342.56,
      "duration": 4.24,
      "text": "details currently known. Hardware design"
    },
    {
      "start": 344.56,
      "duration": 3.52,
      "text": "is said to be unique, unseen before, and"
    },
    {
      "start": 346.8,
      "duration": 2.959,
      "text": "the main devices to be metal and"
    },
    {
      "start": 348.08,
      "duration": 3.36,
      "text": "resembling the shape of an eggstone."
    },
    {
      "start": 349.759,
      "duration": 3.921,
      "text": "Inside the eggstone, there are two pills"
    },
    {
      "start": 351.44,
      "duration": 3.759,
      "text": "who are removed and rest behind the ear."
    },
    {
      "start": 353.68,
      "duration": 2.959,
      "text": "A custom chip is being developed to"
    },
    {
      "start": 355.199,
      "duration": 3.601,
      "text": "allow the device to replace iPhone"
    },
    {
      "start": 356.639,
      "duration": 3.84,
      "text": "actions by commanding Siri. And overall,"
    },
    {
      "start": 358.8,
      "duration": 3.92,
      "text": "Foxcon leaders are still embarrassed by"
    },
    {
      "start": 360.479,
      "duration": 3.761,
      "text": "losing all AirPods programs to Lux. Now"
    },
    {
      "start": 362.72,
      "duration": 4,
      "text": "they see this as a golden chance to win"
    },
    {
      "start": 364.24,
      "duration": 4.72,
      "text": "back the category. We had a show last"
    },
    {
      "start": 366.72,
      "duration": 4.16,
      "text": "year about how sneakily AirPods could be"
    },
    {
      "start": 368.96,
      "duration": 3.28,
      "text": "the most obvious AI device form factor"
    },
    {
      "start": 370.88,
      "duration": 2.879,
      "text": "that not enough people were thinking"
    },
    {
      "start": 372.24,
      "duration": 3.12,
      "text": "about in that way. And so it's"
    },
    {
      "start": 373.759,
      "duration": 3.681,
      "text": "interesting to see the OpenAI hardware"
    },
    {
      "start": 375.36,
      "duration": 3.36,
      "text": "team seemingly exploring some similar"
    },
    {
      "start": 377.44,
      "duration": 2.72,
      "text": "space. Although of course something"
    },
    {
      "start": 378.72,
      "duration": 3.68,
      "text": "behind the ear is something totally"
    },
    {
      "start": 380.16,
      "duration": 4.24,
      "text": "different once again. Now moving away"
    },
    {
      "start": 382.4,
      "duration": 3.84,
      "text": "from OpenAI but staying in the new model"
    },
    {
      "start": 384.4,
      "duration": 3.919,
      "text": "pool. Another report of a likely model"
    },
    {
      "start": 386.24,
      "duration": 4.16,
      "text": "to drop very soon is the next flagship"
    },
    {
      "start": 388.319,
      "duration": 4,
      "text": "DeepSeek model. The information reports"
    },
    {
      "start": 390.4,
      "duration": 3.919,
      "text": "that DeepSseek V4 will be released in"
    },
    {
      "start": 392.319,
      "duration": 4,
      "text": "midFebruary and will have a heavy focus"
    },
    {
      "start": 394.319,
      "duration": 4.16,
      "text": "on coding performance, writes the"
    },
    {
      "start": 396.319,
      "duration": 3.921,
      "text": "information. The new model V4 is a"
    },
    {
      "start": 398.479,
      "duration": 4.241,
      "text": "successor to the V3 model Deepseek"
    },
    {
      "start": 400.24,
      "duration": 4.239,
      "text": "released in December 2024. Initial tests"
    },
    {
      "start": 402.72,
      "duration": 3.36,
      "text": "done by DeepSec employees based on the"
    },
    {
      "start": 404.479,
      "duration": 3.361,
      "text": "company's internal benchmarks showed"
    },
    {
      "start": 406.08,
      "duration": 3.44,
      "text": "that it outperformed existing models"
    },
    {
      "start": 407.84,
      "duration": 4.32,
      "text": "such as Anthropics Claude and OpenAI's"
    },
    {
      "start": 409.52,
      "duration": 4.32,
      "text": "GPT series in coding. The sources said"
    },
    {
      "start": 412.16,
      "duration": 3.44,
      "text": "the report also states that V4 will"
    },
    {
      "start": 413.84,
      "duration": 3.76,
      "text": "showcase DeepSeek's advances in handling"
    },
    {
      "start": 415.6,
      "duration": 3.28,
      "text": "extremely long context windows, which of"
    },
    {
      "start": 417.6,
      "duration": 3.68,
      "text": "course is critical for large coding"
    },
    {
      "start": 418.88,
      "duration": 4.08,
      "text": "tasks. Now, obviously, it would be quite"
    },
    {
      "start": 421.28,
      "duration": 3.359,
      "text": "the shakeup to have a state-of-the-art"
    },
    {
      "start": 422.96,
      "duration": 3.28,
      "text": "open source coding model, but of course,"
    },
    {
      "start": 424.639,
      "duration": 3.361,
      "text": "we don't actually know how it'll perform"
    },
    {
      "start": 426.24,
      "duration": 3.6,
      "text": "until we see it. Some are convinced,"
    },
    {
      "start": 428,
      "duration": 3.599,
      "text": "though, that a model cenamed Beluga on"
    },
    {
      "start": 429.84,
      "duration": 4.16,
      "text": "LM Arena is our first look at the"
    },
    {
      "start": 431.599,
      "duration": 4.081,
      "text": "whale's next release. Deepseek fan tier"
    },
    {
      "start": 434,
      "duration": 3.68,
      "text": "taxes is skeptical of the sourcing but"
    },
    {
      "start": 435.68,
      "duration": 4.079,
      "text": "still believes the hype, posting, I dunk"
    },
    {
      "start": 437.68,
      "duration": 3.6,
      "text": "on Breathless Insider leaks about V4,"
    },
    {
      "start": 439.759,
      "duration": 3.44,
      "text": "but nobody is more confident than me in"
    },
    {
      "start": 441.28,
      "duration": 3.6,
      "text": "what Deepseek is about to achieve."
    },
    {
      "start": 443.199,
      "duration": 3.201,
      "text": "Personally, in my opinion, it'll be the"
    },
    {
      "start": 444.88,
      "duration": 3.759,
      "text": "end of the road for Daario style"
    },
    {
      "start": 446.4,
      "duration": 3.6,
      "text": "fantasies. Developer Vasio posted,"
    },
    {
      "start": 448.639,
      "duration": 3.041,
      "text": "\"Feels like we're about to get another"
    },
    {
      "start": 450,
      "duration": 3.44,
      "text": "overnight jump that was clearly years in"
    },
    {
      "start": 451.68,
      "duration": 3.6,
      "text": "the making.\" Deepseek was also in the"
    },
    {
      "start": 453.44,
      "duration": 3.44,
      "text": "Western press recently for a different"
    },
    {
      "start": 455.28,
      "duration": 2.96,
      "text": "reason with the founder of Deepseek's"
    },
    {
      "start": 456.88,
      "duration": 3.84,
      "text": "quantitative hedge fund generating"
    },
    {
      "start": 458.24,
      "duration": 4.399,
      "text": "returns of 57% last year, writes"
    },
    {
      "start": 460.72,
      "duration": 3.68,
      "text": "Bloomberg's Joe Weisenthal. Man, this"
    },
    {
      "start": 462.639,
      "duration": 3.201,
      "text": "dude's had a good couple of years. Now,"
    },
    {
      "start": 464.4,
      "duration": 3.68,
      "text": "if those are the fourthcoming model"
    },
    {
      "start": 465.84,
      "duration": 5.04,
      "text": "rumors, we also got a small but real"
    },
    {
      "start": 468.08,
      "duration": 4.64,
      "text": "update in VO31 ingredients to video. The"
    },
    {
      "start": 470.88,
      "duration": 3.28,
      "text": "feature allows users to upload reference"
    },
    {
      "start": 472.72,
      "duration": 2.56,
      "text": "images for characters, props, and"
    },
    {
      "start": 474.16,
      "duration": 2.879,
      "text": "background to guide the video"
    },
    {
      "start": 475.28,
      "duration": 3.12,
      "text": "generation. Google said the upgrade"
    },
    {
      "start": 477.039,
      "duration": 3.201,
      "text": "makes videos more expressive and"
    },
    {
      "start": 478.4,
      "duration": 3.44,
      "text": "creative, even with simple prompts. They"
    },
    {
      "start": 480.24,
      "duration": 3.519,
      "text": "also promised better visual consistency"
    },
    {
      "start": 481.84,
      "duration": 3.28,
      "text": "across multiple scenes to ensure clips"
    },
    {
      "start": 483.759,
      "duration": 3.681,
      "text": "can be easily stitched together to tell"
    },
    {
      "start": 485.12,
      "duration": 4,
      "text": "a coherent story. Vio can also now use"
    },
    {
      "start": 487.44,
      "duration": 3.199,
      "text": "ingredients to video when generating"
    },
    {
      "start": 489.12,
      "duration": 3.519,
      "text": "vertical videos for mobile which wasn't"
    },
    {
      "start": 490.639,
      "duration": 3.521,
      "text": "previously possible. And in a last bit"
    },
    {
      "start": 492.639,
      "duration": 2.96,
      "text": "of lab news, which isn't a model right"
    },
    {
      "start": 494.16,
      "duration": 3.36,
      "text": "now, but could be an interesting product"
    },
    {
      "start": 495.599,
      "duration": 3.681,
      "text": "in the future, Anthropic has announced"
    },
    {
      "start": 497.52,
      "duration": 4,
      "text": "the expansion of their labs team into a"
    },
    {
      "start": 499.28,
      "duration": 4.479,
      "text": "full-blown internal incubator. Anthropic"
    },
    {
      "start": 501.52,
      "duration": 4.079,
      "text": "Labs was started in mid 2024 with just"
    },
    {
      "start": 503.759,
      "duration": 4.401,
      "text": "two members and helped develop Claude"
    },
    {
      "start": 505.599,
      "duration": 4.16,
      "text": "Code, MCP, and more recently Co-work."
    },
    {
      "start": 508.16,
      "duration": 3.2,
      "text": "Labs will now become a more substantial"
    },
    {
      "start": 509.759,
      "duration": 2.96,
      "text": "part of the company with Anthropic"
    },
    {
      "start": 511.36,
      "duration": 3.2,
      "text": "aiming to double the lab's headcount"
    },
    {
      "start": 512.719,
      "duration": 3.44,
      "text": "within the next 6 months. The expanded"
    },
    {
      "start": 514.56,
      "duration": 3.12,
      "text": "team will be co-led by chief product"
    },
    {
      "start": 516.159,
      "duration": 3.44,
      "text": "officer Mike Kreger and product"
    },
    {
      "start": 517.68,
      "duration": 3.52,
      "text": "engineering lead Ben man. The team will"
    },
    {
      "start": 519.599,
      "duration": 3.44,
      "text": "report to anthropic president Daniela"
    },
    {
      "start": 521.2,
      "duration": 4,
      "text": "Amade. Now, if you want to hear more"
    },
    {
      "start": 523.039,
      "duration": 3.761,
      "text": "about how Mike thinks about building AI"
    },
    {
      "start": 525.2,
      "duration": 2.96,
      "text": "products, I did an interview with him as"
    },
    {
      "start": 526.8,
      "duration": 2.64,
      "text": "part of our end of year episodes which"
    },
    {
      "start": 528.16,
      "duration": 3.359,
      "text": "you can find on YouTube or on this"
    },
    {
      "start": 529.44,
      "duration": 3.519,
      "text": "podcast feed. Ultimately, it sounds like"
    },
    {
      "start": 531.519,
      "duration": 2.721,
      "text": "a big part of the move is about"
    },
    {
      "start": 532.959,
      "duration": 3.041,
      "text": "restructuring the team so that"
    },
    {
      "start": 534.24,
      "duration": 3.76,
      "text": "Anthropic's product philosophy can match"
    },
    {
      "start": 536,
      "duration": 4.16,
      "text": "the rapid pace of the industry. Wrote"
    },
    {
      "start": 538,
      "duration": 3.6,
      "text": "Daniela. The speed of advancement in AI"
    },
    {
      "start": 540.16,
      "duration": 3.04,
      "text": "demands a different approach in how we"
    },
    {
      "start": 541.6,
      "duration": 3.44,
      "text": "build, how we organize, and where we"
    },
    {
      "start": 543.2,
      "duration": 4.24,
      "text": "focus. Labs gives us room to break the"
    },
    {
      "start": 545.04,
      "duration": 4.16,
      "text": "mold and explore. Look, if it leads to"
    },
    {
      "start": 547.44,
      "duration": 3.28,
      "text": "more products like Cloud Code, I think"
    },
    {
      "start": 549.2,
      "duration": 4,
      "text": "most folks in the industry will say"
    },
    {
      "start": 550.72,
      "duration": 3.92,
      "text": "count us in. For now, that's the latest"
    },
    {
      "start": 553.2,
      "duration": 2.96,
      "text": "on what's cooking around the AI rumor"
    },
    {
      "start": 554.64,
      "duration": 3.12,
      "text": "mill. Hopefully, we get some real models"
    },
    {
      "start": 556.16,
      "duration": 2.64,
      "text": "in the next couple of weeks to explore."
    },
    {
      "start": 557.76,
      "duration": 2.96,
      "text": "For now, though, appreciate you"
    },
    {
      "start": 558.8,
      "duration": 4.96,
      "text": "listening or watching. as always and"
    },
    {
      "start": 560.72,
      "duration": 3.04,
      "text": "until next time."
    }
  ],
  "fullText": "Two weeks into the new year and the new model rumor mill is starting to heat up as people are sharing rumors of a forthcoming and new chat GBT model. Welcome back to the AI daily brief. Today we are talking about the latest leaks/ rumors about the next chat GBT model. But I think it's important to put all of this in its proper context. Let's do a quick hit of the last 5 months of OpenAI model releases. Things started pretty inospiciously in August with the release of GPT5. Now, we've gone over lots of times all of the problems with the GPT5 release. One very big problem was the deprecation of 40 alongside it, which had people angry at them for reasons that had nothing to do with the model's performance and everything to do with other changes that were being made at the same time. We've also discussed how if they had simply called their biggest reasoning models like 03 GBT, the perception of the performance jump might have been very different. Basically, in some ways, they were kind of a victim of their own making. Whatever the case, the context it came into was not a great moment for the narrative around AI, and GBD5 did nothing to alleviate that. That's when we were getting these, in retrospect, very silly opeds in publications like The New Yorker, what if AI doesn't get much better than this? Fast forward a couple months, and the pressure was on for Google to deliver. There was a while there where I wasn't even sure that Google was actually going to drop Gemini 3 in November because of the amount of pressure they were under to get it right. But get it right they did. At least in the court of public opinion. When Gemini 3 came out, people were extremely excited about it. They were impressed with Gemini 3 Pro as a model for their intellectual and work tasks. And of course, Nano Banana Pro's ability to make infographics opened up all sorts of totally new possible use cases. It turns out that OpenAI knew they were in for a rough patch. Back in October, it turns out Sam Alman had warned some staff in a memo that he expected some rough vibes around the launch of Google's new models. Rough vibes they got, ultimately leading to Alman and the team at OpenAI declaring a code red. Now what this code red meant in short was a sessation or at least a slowdown of work on a lot of ancillary features and products to double triple quadruple down on core chatbt features including the models underneath powering it. That got us to GBT 5.2 as well as the new chatbt images model which is it should be noted a 1.5 model not a full jump to image gen 2. Now 52 and the new chatbt Images are good models. 52 Pro in particular is very much in my regular rotation and when it comes to a lot of heavy intellectual work, there are many folks who swear by it. Images frankly was better than I expected given how much pressure they had to put that out given Nano Banana Pro. And so even though Gemini and Google had really won a ton of momentum, I do think that the chat GPT releases in December maybe didn't fully stem the bleeding, but for people who weren't interested in the horse race and just wanted high performing models, you felt very lucky with all the options you had over the holiday season. But then of course around all of this was Claude Opus 4.5. The opinion on this model has done nothing but go up and up and up and up. So much so that in a lastminute upset I actually said that I thought it might end up being the most important model release of 2025. And so far at least I think that argument is holding up. Cloud code, Opus 4.5 and AGI are terms that are very frequent co-inhabitants right now of tweets and posts on social networks. Since the beginning of the year, these companies have not slowed down. In a major move to bring cloud code to everybody else, Anthropic released Co-work, tripling down in that way on their source of narrative momentum, while Google and Apple announced the deal that was reported at the end of last year that forthcoming versions of Apple intelligence will be powered in fact by Gemini models. All of this has led to a sense of a lot of momentum around Anthropic and Google and kind of less so around OpenAI. In fact, last night I tweeted that OpenAI seemed to me to be almost conspicuously quiet, which perhaps isn't totally fair given that they announced a major product in CHBT health. But still, it feels to me both like something is percolating and also that perhaps the company decided to try to do a little bit less vague posting in this new 2026 year. Yesterday, the rumor mill kicked back up in a big way. Dan Mack tweeted, \"GBT 53 cenamed garlic coming soon.\" According to a source, a very reliable source batting a thousand, expected to be a doozy, likely with stronger pre-training and the IMO gold winning reasoning techniques, the AI leaker account I rule the world responded saying that they had also heard this month and in a separate post shared something that they had told subscribers back in December that the 52 model that we got was a quote rushed early checkpoint and that the full model is going to drop in January. Other speculation is that the model will be multimodal, generating both images and audio. Although no one seems quite clear on the naming conventions, whether it will be GPT55 or even something like GPT53. And of course, while these are all just rumors, although rumors with sourcing, there is also starting to be some evidence that some newness might be percolating and poking through. Andrew Curran tweeted, \"My chat is acting quite differently as of last night. I assumed it was part of a new personality test group. This has happened many times over the last couple of months. OpenAI did say the next big update would make five more personable. It's possible it's about to arrive. Now, maybe I am wrong about the vague tweeting given that VB from OpenAI's developer experience team posted the eyes emoji getting everyone talking as part of this conversation as well. Obviously, anytime we get a new model, it's a very exciting moment. And certainly with the stakes as high as they are, I would love to see a big powerful effort drop that shakes the race up once again. Now, believe it or not, that wasn't the only information in the AI rumor mill. A Chinese consumer electronics blogger has a new leak from their contacts and the supply chain. They wrote, \"Hearing fresh detail on OpenAI to go hardware project from last report, now confirmed it's a special audio product to replace AirPod. Internal code name is Sweet Pee. On manufacturing, Foxcon has been told to prepare for a total of five devices by Q4 2028. All are not known, but a homestyle device and pen are still considered. However, many sources repeated the same thing. Sweet Pea is now front of the line due to the priority of the Johnny IV team. The release has been told to be near September. Volume projection 40 to 50 million in the first year. Only some details currently known. Hardware design is said to be unique, unseen before, and the main devices to be metal and resembling the shape of an eggstone. Inside the eggstone, there are two pills who are removed and rest behind the ear. A custom chip is being developed to allow the device to replace iPhone actions by commanding Siri. And overall, Foxcon leaders are still embarrassed by losing all AirPods programs to Lux. Now they see this as a golden chance to win back the category. We had a show last year about how sneakily AirPods could be the most obvious AI device form factor that not enough people were thinking about in that way. And so it's interesting to see the OpenAI hardware team seemingly exploring some similar space. Although of course something behind the ear is something totally different once again. Now moving away from OpenAI but staying in the new model pool. Another report of a likely model to drop very soon is the next flagship DeepSeek model. The information reports that DeepSseek V4 will be released in midFebruary and will have a heavy focus on coding performance, writes the information. The new model V4 is a successor to the V3 model Deepseek released in December 2024. Initial tests done by DeepSec employees based on the company's internal benchmarks showed that it outperformed existing models such as Anthropics Claude and OpenAI's GPT series in coding. The sources said the report also states that V4 will showcase DeepSeek's advances in handling extremely long context windows, which of course is critical for large coding tasks. Now, obviously, it would be quite the shakeup to have a state-of-the-art open source coding model, but of course, we don't actually know how it'll perform until we see it. Some are convinced, though, that a model cenamed Beluga on LM Arena is our first look at the whale's next release. Deepseek fan tier taxes is skeptical of the sourcing but still believes the hype, posting, I dunk on Breathless Insider leaks about V4, but nobody is more confident than me in what Deepseek is about to achieve. Personally, in my opinion, it'll be the end of the road for Daario style fantasies. Developer Vasio posted, \"Feels like we're about to get another overnight jump that was clearly years in the making.\" Deepseek was also in the Western press recently for a different reason with the founder of Deepseek's quantitative hedge fund generating returns of 57% last year, writes Bloomberg's Joe Weisenthal. Man, this dude's had a good couple of years. Now, if those are the fourthcoming model rumors, we also got a small but real update in VO31 ingredients to video. The feature allows users to upload reference images for characters, props, and background to guide the video generation. Google said the upgrade makes videos more expressive and creative, even with simple prompts. They also promised better visual consistency across multiple scenes to ensure clips can be easily stitched together to tell a coherent story. Vio can also now use ingredients to video when generating vertical videos for mobile which wasn't previously possible. And in a last bit of lab news, which isn't a model right now, but could be an interesting product in the future, Anthropic has announced the expansion of their labs team into a full-blown internal incubator. Anthropic Labs was started in mid 2024 with just two members and helped develop Claude Code, MCP, and more recently Co-work. Labs will now become a more substantial part of the company with Anthropic aiming to double the lab's headcount within the next 6 months. The expanded team will be co-led by chief product officer Mike Kreger and product engineering lead Ben man. The team will report to anthropic president Daniela Amade. Now, if you want to hear more about how Mike thinks about building AI products, I did an interview with him as part of our end of year episodes which you can find on YouTube or on this podcast feed. Ultimately, it sounds like a big part of the move is about restructuring the team so that Anthropic's product philosophy can match the rapid pace of the industry. Wrote Daniela. The speed of advancement in AI demands a different approach in how we build, how we organize, and where we focus. Labs gives us room to break the mold and explore. Look, if it leads to more products like Cloud Code, I think most folks in the industry will say count us in. For now, that's the latest on what's cooking around the AI rumor mill. Hopefully, we get some real models in the next couple of weeks to explore. For now, though, appreciate you listening or watching. as always and until next time.",
  "fetchedAt": "2026-01-18T18:32:59.342Z"
}