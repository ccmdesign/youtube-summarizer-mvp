---
metadata:
  videoId: "XP6TJRbOdGo"
  title: "I Wasn't Ready For What This Does"
  description: "Gemini 3 has changed the game. In this gemini 3 review, I combine gemini veo 3, google ai studio tools, and whisk ai into one powerful workflow to build professional landing pages with smooth scroll animations.




    Google Whisk: https://labs.google/fx/tools/whisk\ 


    Google Flow: https://labs.google/flow/about\ 


    Hero UI: https://www.heroui.com/\ 


    Motion: https://motion.dev/\ 


    21st.dev: https://21st.dev/



    Google Gemini 3 powers some incredible experimental tools that most people don't know how to use together. Whether you've seen the debates around gpt 5.2 vs gemini 3 or chatgpt 5.2 vs gemini 3, the real question isn't which model wins on benchmarks. It's about what you can actually build.

    In this video, I walk through a complete workflow using Whisk (powered by Nano Banana Pro for image generation and Gemini 3 for prompt enhancement), Google Flow with gemini veo 3 for video creation, and Claude Code for implementation. You'll see how to generate consistent keyframes, create smooth transitions between them, convert assets for web performance, and build a polished landing page with Hero UI and Motion.dev.

    This isn't vibe coding where you hope for the best. It's a structured approach that combines AI tools strategically. While discussions about gemini 3 pro vs gpt 5.1 or gemini 3 vs gpt 5.2 dominate AI news, I'm focused on showing you practical applications with tools like gemini 3 flash, gemini 3 pro, and gemini 3 deep think capabilities through Google AI Studio.

    I also show you how to use 21st.dev for component inspiration and how Claude Code automatically adapts components to fit your project without explicit instructions.


    Hashtags:

    #ai #gemini #claudecode #chatgpt #googleaistudio #ainews #vibecoding #nanabananapro #antigravity #googleantigravity"
  channel: "AI LABS"
  channelId: "UCelfWQr9sXVMTvBzviPGlFw"
  duration: "PT9M37S"
  publishedAt: "2026-01-12T14:01:14Z"
  thumbnailUrl: "https://i.ytimg.com/vi/XP6TJRbOdGo/hqdefault.jpg"
  youtubeUrl: "https://www.youtube.com/watch?v=XP6TJRbOdGo"
processedAt: "2026-01-14T16:23:10.424Z"
source: "youtube"
playlistId: "PL-SEjLl-bojVmsXOvG-TBp7DVv0McXJzn"
playlistName: "AI Summaries"
category: "ai"
tldr: "Building professional, high-performance landing pages requires a **multi-tool AI workflow** rather than single-shot prompts.\ 

  - **Google Whisk & Flow**: Use these for consistent asset generation and keyframe-based animations via the **VO 3.1** model.

  - **Optimized Implementation**: Convert video to **WEBP** for scroll-mapping and use **Claude** with XML-structured prompts to integrate libraries li\n"
ai:
  provider: "gemini"
  model: "gemini-3-flash-preview"
  apiCalls: 1
  fallbackAttempts: 0
  inputTokens: 2655
  outputTokens: 863
  totalTokens: 4322
  processingTimeMs: 12117
---

## Key Takeaways

Creating premium web experiences now relies on orchestrating specialized AI models for design, motion, and code.

- **Asset Continuity**: Use the **Subject, Scene, and Style framework** in Google Whisk to ensure visual consistency across different frames.

- **Performance Optimization**: Convert MP4 animations to **WEBP** to allow seamless scroll-based interactions without the overhead of media players.

- **Structured Prompting**: Use **XML tags** when working with Claude to help the model parse complex technical requirements and UI constraints independently.

- **Component Libraries**: Leverage **Hero UI** for high-end aesthetics and **21st.dev** to source pre-configured AI prompts for complex UI sections.

## Summary

The video breaks down the misconception that high-end landing pages are created with a single AI prompt. Instead, the creator demonstrates a sophisticated workflow using Google's experimental Gemini 3-powered tools and specialized UI libraries to achieve a professional "Apple-style" result.

### Asset Generation and Animation
To solve the issue of inconsistent AI images, the process starts with **Google Whisk**. This tool uses a **Subject, Scene, and Style framework**, allowing for precise control over visual assets. By using **Gemini 3** as a middle layer to expand simple prompts, Whisk generates consistent keyframes. 

For motion, the creator uses **Google Flow** powered by the **VO 3.1 model**. Unlike standard image-to-video tools, Flow can connect two distinct keyframes (a start and an end frame) to create a logical transition. To ensure these animations work well on the web, they are converted from MP4 to **WEBP** format. This allows the browser to treat the animation as an image, making it significantly easier to map to **scroll-based interactions**.

### Development and UI Implementation
The project is built on **Next.js**, with **Claude** acting as the primary coding agent. The creator emphasizes using **XML-structured prompts** (e.g., `<requirements>`, `<animation_behavior>`) to help Claude reason through complex implementation details. 

To move away from the generic look of AI-generated CSS, the workflow incorporates:

- **Hero UI**: A library built on Tailwind CSS and Framer Motion that mimics premium design languages.

- **Motion.dev**: An open-source library used to handle the heavy lifting of scroll-linked animations and parallax effects.

- **21st.dev**: A platform used to source complex UI components like Footers and Call-to-Action sections. 

### Refining the AI Agent Output
A major highlight is the use of **AI-ready prompts** from 21st.dev. These prompts are pre-structured with dependency maps and installation instructions, allowing Claude to integrate complex components (like a specialized camera-product footer) while automatically stripping out irrelevant parts. This modular approach ensures the final product feels bespoke rather than generated.

## Context

As generative AI matures, the focus is shifting from simple text-to-image generation to complex workflow orchestration. This video targets developers and designers who find that standard AI tools produce 'generic' results. By combining Google's latest experimental models (Whisk, Flow, VO) with advanced LLM prompting techniques (Claude's XML structure), the video illustrates how the gap between 'AI-generated' and 'professionally designed' is rapidly closing. This matters because it demonstrates a future where high-performance, motion-rich web design is accessible to those who can manage multiple specialized AI agents effectively.
