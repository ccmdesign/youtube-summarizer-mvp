{
  "videoId": "fbpZXu_gbQg",
  "language": "en",
  "source": "caption-extractor",
  "segments": [
    {
      "start": 0.08,
      "duration": 6.239,
      "text": "We are figuring out which AI is able to"
    },
    {
      "start": 3.52,
      "duration": 5.119,
      "text": "help us find the true best deal on"
    },
    {
      "start": 6.319,
      "duration": 4.081,
      "text": "commonly discounted items. I chose a"
    },
    {
      "start": 8.639,
      "duration": 3.761,
      "text": "sectional couch for this, but you can"
    },
    {
      "start": 10.4,
      "duration": 3.52,
      "text": "absolutely use this for TVs or anything"
    },
    {
      "start": 12.4,
      "duration": 4.32,
      "text": "else that you're looking for. What are"
    },
    {
      "start": 13.92,
      "duration": 6.32,
      "text": "the contestants? Chad GPT 5.1, Claude"
    },
    {
      "start": 16.72,
      "duration": 5.36,
      "text": "Opus 4.5, Gemini 3, and two smart"
    },
    {
      "start": 20.24,
      "duration": 4.64,
      "text": "browsers. I went with Atlas and I went"
    },
    {
      "start": 22.08,
      "duration": 6.24,
      "text": "with Comet. So, number one, the intent"
    },
    {
      "start": 24.88,
      "duration": 4.88,
      "text": "has to be very clear for the model to"
    },
    {
      "start": 28.32,
      "duration": 3.44,
      "text": "come back and give you what you want. I"
    },
    {
      "start": 29.76,
      "duration": 4.799,
      "text": "know that's not new, but it came"
    },
    {
      "start": 31.76,
      "duration": 5.44,
      "text": "through. Comet did not figure out even"
    },
    {
      "start": 34.559,
      "duration": 5.041,
      "text": "though I was on a gray sectional couch"
    },
    {
      "start": 37.2,
      "duration": 4.48,
      "text": "page that I wanted a gray sectional"
    },
    {
      "start": 39.6,
      "duration": 4.56,
      "text": "couch. So, the color didn't come through"
    },
    {
      "start": 41.68,
      "duration": 4.8,
      "text": "because I didn't specify it. Anywhere"
    },
    {
      "start": 44.16,
      "duration": 3.68,
      "text": "you don't have clear intent, the model"
    },
    {
      "start": 46.48,
      "duration": 3.84,
      "text": "is just going to give you its best"
    },
    {
      "start": 47.84,
      "duration": 6,
      "text": "guess. That's why I built a prompt that"
    },
    {
      "start": 50.32,
      "duration": 5.36,
      "text": "is actually designed to let you specify"
    },
    {
      "start": 53.84,
      "duration": 3.84,
      "text": "as much as you want, in as much detail"
    },
    {
      "start": 55.68,
      "duration": 4.32,
      "text": "as you want, so the model can go and get"
    },
    {
      "start": 57.68,
      "duration": 3.92,
      "text": "it. And you'll see what happens when you"
    },
    {
      "start": 60,
      "duration": 4,
      "text": "start to get clear and how much more"
    },
    {
      "start": 61.6,
      "duration": 4,
      "text": "powerful the search gets. Overall, the"
    },
    {
      "start": 64,
      "duration": 3.6,
      "text": "browsers have a very different approach"
    },
    {
      "start": 65.6,
      "duration": 4.32,
      "text": "architecturally than the models do. The"
    },
    {
      "start": 67.6,
      "duration": 3.76,
      "text": "models can use web search tools and then"
    },
    {
      "start": 69.92,
      "duration": 3.92,
      "text": "their own inference or reasoning"
    },
    {
      "start": 71.36,
      "duration": 4.24,
      "text": "abilities to figure out what is the"
    },
    {
      "start": 73.84,
      "duration": 3.2,
      "text": "right answer to the prompt. The web"
    },
    {
      "start": 75.6,
      "duration": 3.839,
      "text": "search tools are actually equipped with"
    },
    {
      "start": 77.04,
      "duration": 5.439,
      "text": "more information. They are able to look"
    },
    {
      "start": 79.439,
      "duration": 5.04,
      "text": "at the web page itself along with"
    },
    {
      "start": 82.479,
      "duration": 5.041,
      "text": "whatever prompt you give. What you see"
    },
    {
      "start": 84.479,
      "duration": 3.041,
      "text": "is what you get here,"
    }
  ],
  "fullText": "We are figuring out which AI is able to help us find the true best deal on commonly discounted items. I chose a sectional couch for this, but you can absolutely use this for TVs or anything else that you're looking for. What are the contestants? Chad GPT 5.1, Claude Opus 4.5, Gemini 3, and two smart browsers. I went with Atlas and I went with Comet. So, number one, the intent has to be very clear for the model to come back and give you what you want. I know that's not new, but it came through. Comet did not figure out even though I was on a gray sectional couch page that I wanted a gray sectional couch. So, the color didn't come through because I didn't specify it. Anywhere you don't have clear intent, the model is just going to give you its best guess. That's why I built a prompt that is actually designed to let you specify as much as you want, in as much detail as you want, so the model can go and get it. And you'll see what happens when you start to get clear and how much more powerful the search gets. Overall, the browsers have a very different approach architecturally than the models do. The models can use web search tools and then their own inference or reasoning abilities to figure out what is the right answer to the prompt. The web search tools are actually equipped with more information. They are able to look at the web page itself along with whatever prompt you give. What you see is what you get here,",
  "fetchedAt": "2026-01-18T18:33:43.027Z"
}