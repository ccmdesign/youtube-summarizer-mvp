videoId: k1t2xyWMUdY
title: How METR measures Long Tasks and Experienced Open Source Dev Productivity
  - Joel Becker, METR
description: >-
  AI models are crushing benchmarks. SWE-bench scores are climbing, and METR's
  measured time horizons are rising rapidly. Yet when we deployed these same
  models in a field study with experienced developers, they didn't speed up
  work. What's going on? Are benchmarks misleading us about AI capabilities? Are
  we missing something about how AI performs in the real world? In this talk,
  we'll reconcile lab and field evidence on AI capabilities. Drawing from METR's
  time horizon measurements and developer productivity RCT, we'll explore why
  impressive benchmark performance doesn't always translate to real-world
  impact. We'll examine potential explanations—from reliability requirements to
  task distribution to capability elicitation—and discuss what this means for
  automated AI R&D.


  https://x.com/joel_bkr
channel: AI Engineer
channelId: UCLKPca3kwwd-B59HNr-_lvA
duration: PT1H15M52S
publishedAt: 2026-01-19T14:00:06Z
thumbnailUrl: https://i.ytimg.com/vi/k1t2xyWMUdY/hqdefault.jpg
youtubeUrl: https://www.youtube.com/watch?v=k1t2xyWMUdY
playlistId: PL-SEjLl-bojVmsXOvG-TBp7DVv0McXJzn
processedAt: 2026-01-20T17:01:07.464Z
lengthCategory: longform
modelUsed: openrouter/deepseek/deepseek-v3.2
aiProvider: openrouter
apiCalls: 1
fallbackAttempts: 0
inputTokens: 17162
outputTokens: 1359
totalTokens: 18521
processingTimeMs: 44458
