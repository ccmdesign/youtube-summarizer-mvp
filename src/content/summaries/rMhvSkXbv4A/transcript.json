{
  "videoId": "rMhvSkXbv4A",
  "language": "en",
  "source": "caption-extractor",
  "segments": [
    {
      "start": 0.08,
      "duration": 5.52,
      "text": "We've got Kiara to my left, Alex to my"
    },
    {
      "start": 2.639,
      "duration": 4.961,
      "text": "right, CEO of Arcade. Kiara's working on"
    },
    {
      "start": 5.6,
      "duration": 3.12,
      "text": "IUD. She's a process lead data"
    },
    {
      "start": 7.6,
      "duration": 2.24,
      "text": "scientist."
    },
    {
      "start": 8.72,
      "duration": 4.839,
      "text": ">> Data scientist."
    },
    {
      "start": 9.84,
      "duration": 3.719,
      "text": ">> You're leading our book."
    },
    {
      "start": 15.2,
      "duration": 3.919,
      "text": ">> You've been working on a project at I"
    },
    {
      "start": 17.199,
      "duration": 3.601,
      "text": "Food. You gave a talk last night. I"
    },
    {
      "start": 19.119,
      "duration": 3.361,
      "text": "loved it. I wanted to bring you on here"
    },
    {
      "start": 20.8,
      "duration": 3.44,
      "text": "to talk about some of your learnings."
    },
    {
      "start": 22.48,
      "duration": 3.44,
      "text": ">> For those who don't know, I food is the"
    },
    {
      "start": 24.24,
      "duration": 4.64,
      "text": "biggest uh food delivery company in"
    },
    {
      "start": 25.92,
      "duration": 6.08,
      "text": "Brazil. Um it has a huge order volume"
    },
    {
      "start": 28.88,
      "duration": 5.92,
      "text": "160 million per month. Um Brazilians use"
    },
    {
      "start": 32,
      "duration": 4.48,
      "text": "it a lot. What we realize is that users"
    },
    {
      "start": 34.8,
      "duration": 4.64,
      "text": "often go to the app and they don't know"
    },
    {
      "start": 36.48,
      "duration": 4.399,
      "text": "what to order. Uh they are bit undecided"
    },
    {
      "start": 39.44,
      "duration": 3.2,
      "text": "and sometimes they get frustrated"
    },
    {
      "start": 40.879,
      "duration": 4.241,
      "text": "because they have too many options. It's"
    },
    {
      "start": 42.64,
      "duration": 4.64,
      "text": "a paradox of choice, right? So the"
    },
    {
      "start": 45.12,
      "duration": 4.16,
      "text": "problem we solve with this agent is to"
    },
    {
      "start": 47.28,
      "duration": 5.2,
      "text": "help them decide. We built something"
    },
    {
      "start": 49.28,
      "duration": 6.48,
      "text": "that um knows who the users are, knows"
    },
    {
      "start": 52.48,
      "duration": 5.12,
      "text": "uh their preferences, their habits, and"
    },
    {
      "start": 55.76,
      "duration": 5.76,
      "text": "um the price range they're willing to"
    },
    {
      "start": 57.6,
      "duration": 6.24,
      "text": "pay. And we use that plus uh the users"
    },
    {
      "start": 61.52,
      "duration": 6.88,
      "text": "questions to suggest the best options"
    },
    {
      "start": 63.84,
      "duration": 6.48,
      "text": "for them even proactively. And we yeah,"
    },
    {
      "start": 68.4,
      "duration": 4.64,
      "text": "we have a flow where the user can can"
    },
    {
      "start": 70.32,
      "duration": 5.44,
      "text": "search and refine uh and then order at"
    },
    {
      "start": 73.04,
      "duration": 5.52,
      "text": "the end. We prepared two interfaces for"
    },
    {
      "start": 75.76,
      "duration": 6.24,
      "text": "the agent. One is in the app and one is"
    },
    {
      "start": 78.56,
      "duration": 6.559,
      "text": "on WhatsApp. Uh WhatsApp is very uh"
    },
    {
      "start": 82,
      "duration": 6.88,
      "text": "popular in Brazil. I think there are 160"
    },
    {
      "start": 85.119,
      "duration": 5.441,
      "text": "million uh active users. So they they"
    },
    {
      "start": 88.88,
      "duration": 4.239,
      "text": "use it a lot. If you don't know uh"
    },
    {
      "start": 90.56,
      "duration": 4.879,
      "text": "people use it uh to order food with just"
    },
    {
      "start": 93.119,
      "duration": 4,
      "text": "voice messages. It's it's really smooth."
    },
    {
      "start": 95.439,
      "duration": 3.201,
      "text": "They just send a voice note to the to"
    },
    {
      "start": 97.119,
      "duration": 4.32,
      "text": "the restaurant and they can order like"
    },
    {
      "start": 98.64,
      "duration": 6.479,
      "text": "that. So we we leverage this familiarity"
    },
    {
      "start": 101.439,
      "duration": 6.401,
      "text": "with um the conversational interface."
    },
    {
      "start": 105.119,
      "duration": 6.801,
      "text": "uh both had different challenges uh in"
    },
    {
      "start": 107.84,
      "duration": 6.72,
      "text": "terms of um UX how we uh show results to"
    },
    {
      "start": 111.92,
      "duration": 4.239,
      "text": "the user. It often happens with agents,"
    },
    {
      "start": 114.56,
      "duration": 4.8,
      "text": "right? So the the biggest challenges are"
    },
    {
      "start": 116.159,
      "duration": 6.32,
      "text": "not AI related but uh UX and adoption"
    },
    {
      "start": 119.36,
      "duration": 7.119,
      "text": "related. So the agent that uh we built"
    },
    {
      "start": 122.479,
      "duration": 6.081,
      "text": "is um kind of a react agent. We didn't"
    },
    {
      "start": 126.479,
      "duration": 3.601,
      "text": "use like too fancy multi- aent setup"
    },
    {
      "start": 128.56,
      "duration": 2.399,
      "text": "because we needed things to go very"
    },
    {
      "start": 130.08,
      "duration": 2.72,
      "text": "fast."
    },
    {
      "start": 130.959,
      "duration": 4.721,
      "text": ">> Users are hungry. They don't want to"
    },
    {
      "start": 132.8,
      "duration": 5.36,
      "text": "wait. So we need to have the simplest"
    },
    {
      "start": 135.68,
      "duration": 4.72,
      "text": "flow. We need to make sure that the"
    },
    {
      "start": 138.16,
      "duration": 4.719,
      "text": "recommendations that we give to them uh"
    },
    {
      "start": 140.4,
      "duration": 4.72,
      "text": "are are good. They work for them. And we"
    },
    {
      "start": 142.879,
      "duration": 4.641,
      "text": "also need to remind to remember if they"
    },
    {
      "start": 145.12,
      "duration": 5.759,
      "text": "don't like certain foods like the agent"
    },
    {
      "start": 147.52,
      "duration": 5.28,
      "text": "really needs to be a smart companion uh"
    },
    {
      "start": 150.879,
      "duration": 3.841,
      "text": "almost reading their mind. One of the"
    },
    {
      "start": 152.8,
      "duration": 3.84,
      "text": "things we wanted to make sure is that"
    },
    {
      "start": 154.72,
      "duration": 4.48,
      "text": "the conversational interface was not"
    },
    {
      "start": 156.64,
      "duration": 4.4,
      "text": "just textual and there were multiple"
    },
    {
      "start": 159.2,
      "duration": 3.84,
      "text": "modalities for the user to talk to the"
    },
    {
      "start": 161.04,
      "duration": 4.08,
      "text": "agent because when they're hungry they"
    },
    {
      "start": 163.04,
      "duration": 5.36,
      "text": "don't want to spend time typing, right?"
    },
    {
      "start": 165.12,
      "duration": 5.759,
      "text": "Um so we we made sure that tools that we"
    },
    {
      "start": 168.4,
      "duration": 5.04,
      "text": "built were connected to UX and UI"
    },
    {
      "start": 170.879,
      "duration": 6.241,
      "text": "elements so that the user could directly"
    },
    {
      "start": 173.44,
      "duration": 5.519,
      "text": "interact with them. um to have some uh"
    },
    {
      "start": 177.12,
      "duration": 3.52,
      "text": "short circuit uh let's say"
    },
    {
      "start": 178.959,
      "duration": 3.841,
      "text": ">> it's like swiping and"
    },
    {
      "start": 180.64,
      "duration": 2.959,
      "text": ">> also yeah we also implemented a swiping"
    },
    {
      "start": 182.8,
      "duration": 1.6,
      "text": "interface"
    },
    {
      "start": 183.599,
      "duration": 3.28,
      "text": ">> voice also"
    },
    {
      "start": 184.4,
      "duration": 5.919,
      "text": ">> also voice yeah yeah so voice is a"
    },
    {
      "start": 186.879,
      "duration": 6.401,
      "text": "modality but it's still textual in a way"
    },
    {
      "start": 190.319,
      "duration": 5.84,
      "text": "um what we we did was also making sure"
    },
    {
      "start": 193.28,
      "duration": 5.44,
      "text": "that there were buttons to click to do"
    },
    {
      "start": 196.159,
      "duration": 4.321,
      "text": "actions quickly without having to type"
    },
    {
      "start": 198.72,
      "duration": 4.239,
      "text": "like I want the third item that you're"
    },
    {
      "start": 200.48,
      "duration": 4.479,
      "text": "showing me and that's not needed one"
    },
    {
      "start": 202.959,
      "duration": 4,
      "text": "interesting thing we noticed is that uh"
    },
    {
      "start": 204.959,
      "duration": 3.92,
      "text": "people on WhatsApp were way more lenient"
    },
    {
      "start": 206.959,
      "duration": 4.241,
      "text": "towards this conversational behavior"
    },
    {
      "start": 208.879,
      "duration": 3.92,
      "text": "than in app. Uh in app really people"
    },
    {
      "start": 211.2,
      "duration": 3.92,
      "text": "really want to use buttons. They expect"
    },
    {
      "start": 212.799,
      "duration": 5.761,
      "text": "a different type of interface."
    },
    {
      "start": 215.12,
      "duration": 6.399,
      "text": ">> So our tools needed to work very well."
    },
    {
      "start": 218.56,
      "duration": 6.08,
      "text": "Uh one of the challenges we encountered"
    },
    {
      "start": 221.519,
      "duration": 6.64,
      "text": "was that the tool definitions that we"
    },
    {
      "start": 224.64,
      "duration": 6.4,
      "text": "had made a lot of sense for us but it"
    },
    {
      "start": 228.159,
      "duration": 5.601,
      "text": "didn't make sense uh to someone external"
    },
    {
      "start": 231.04,
      "duration": 4.4,
      "text": "that would see them for the first time."
    },
    {
      "start": 233.76,
      "duration": 4.08,
      "text": "We realized this afterwards of course"
    },
    {
      "start": 235.44,
      "duration": 5.439,
      "text": "with trial and and error. What we"
    },
    {
      "start": 237.84,
      "duration": 6,
      "text": "noticed was that um we we created the"
    },
    {
      "start": 240.879,
      "duration": 5.041,
      "text": "tools right uh things made sense but as"
    },
    {
      "start": 243.84,
      "duration": 3.92,
      "text": "soon as we were getting edge cases in"
    },
    {
      "start": 245.92,
      "duration": 6,
      "text": "production we were adding this to the"
    },
    {
      "start": 247.76,
      "duration": 6.8,
      "text": "tool. So whenever the user uh wants to"
    },
    {
      "start": 251.92,
      "duration": 4.48,
      "text": "order something and you don't have uh"
    },
    {
      "start": 254.56,
      "duration": 4.56,
      "text": "enough information about it, make sure"
    },
    {
      "start": 256.4,
      "duration": 5.44,
      "text": "to call the get information tool like a"
    },
    {
      "start": 259.12,
      "duration": 6.799,
      "text": "lot of edge cases for these flows and it"
    },
    {
      "start": 261.84,
      "duration": 7.28,
      "text": "quickly becomes uh code like a statement"
    },
    {
      "start": 265.919,
      "duration": 6.481,
      "text": "and that you don't want right uh so the"
    },
    {
      "start": 269.12,
      "duration": 5.44,
      "text": "exercises we made was to try to to"
    },
    {
      "start": 272.4,
      "duration": 4.88,
      "text": "standardize this tool like think if I"
    },
    {
      "start": 274.56,
      "duration": 4.8,
      "text": "would share this tool with another team"
    },
    {
      "start": 277.28,
      "duration": 3.84,
      "text": "and if they would want know use it in"
    },
    {
      "start": 279.36,
      "duration": 3.839,
      "text": "their own agent. How would I write"
    },
    {
      "start": 281.12,
      "duration": 4.56,
      "text": "things there? Like the idea is to make"
    },
    {
      "start": 283.199,
      "duration": 5.601,
      "text": "them as clear as possible. Uh would the"
    },
    {
      "start": 285.68,
      "duration": 5.2,
      "text": "name of the tool even make sense? Right?"
    },
    {
      "start": 288.8,
      "duration": 4,
      "text": ">> And after that we had a massive"
    },
    {
      "start": 290.88,
      "duration": 4.319,
      "text": "improvement in latency because we could"
    },
    {
      "start": 292.8,
      "duration": 4.959,
      "text": "cut a lot of tokens and our system"
    },
    {
      "start": 295.199,
      "duration": 6.241,
      "text": "become became much more stable."
    },
    {
      "start": 297.759,
      "duration": 6.241,
      "text": ">> Making sure that a tool encapsulates"
    },
    {
      "start": 301.44,
      "duration": 5.599,
      "text": "the right things is the hardest part of"
    },
    {
      "start": 304,
      "duration": 4.4,
      "text": "the problem. Um, and I think people"
    },
    {
      "start": 307.039,
      "duration": 3.6,
      "text": "really struggle with that. They they"
    },
    {
      "start": 308.4,
      "duration": 3.6,
      "text": "think of it as an API. Oh, we just have"
    },
    {
      "start": 310.639,
      "duration": 3.12,
      "text": "an API. We'll call it. Well, that's not"
    },
    {
      "start": 312,
      "duration": 3.44,
      "text": "really going to work, right? You know,"
    },
    {
      "start": 313.759,
      "duration": 3.521,
      "text": "there's a lot of usability. It's like,"
    },
    {
      "start": 315.44,
      "duration": 4.24,
      "text": "well, what's the user experience going"
    },
    {
      "start": 317.28,
      "duration": 3.84,
      "text": "to be? What's the intention that the"
    },
    {
      "start": 319.68,
      "duration": 3.04,
      "text": "user has? What's the intention that the"
    },
    {
      "start": 321.12,
      "duration": 3.76,
      "text": "agent needs to have? And then figuring"
    },
    {
      "start": 322.72,
      "duration": 5.12,
      "text": "out, okay, well, what's what's the right"
    },
    {
      "start": 324.88,
      "duration": 4.48,
      "text": "encapsulation of that in a tool"
    },
    {
      "start": 327.84,
      "duration": 2.799,
      "text": ">> is what everybody's struggling with."
    },
    {
      "start": 329.36,
      "duration": 4.96,
      "text": "It's a new paradigm. It's a mental"
    },
    {
      "start": 330.639,
      "duration": 6.321,
      "text": "model. What we what we see as a best"
    },
    {
      "start": 334.32,
      "duration": 6.319,
      "text": "practice as people try and build that is"
    },
    {
      "start": 336.96,
      "duration": 7.84,
      "text": "that it's you know there's like a lading"
    },
    {
      "start": 340.639,
      "duration": 5.681,
      "text": "of tools and so you might have a shared"
    },
    {
      "start": 344.8,
      "duration": 5.28,
      "text": "tool"
    },
    {
      "start": 346.32,
      "duration": 5.2,
      "text": ">> that is a workflow or maybe even an MCP"
    },
    {
      "start": 350.08,
      "duration": 3.2,
      "text": "server that's integrating to another"
    },
    {
      "start": 351.52,
      "duration": 3.92,
      "text": "service."
    },
    {
      "start": 353.28,
      "duration": 4.96,
      "text": "But even if you have those things, the"
    },
    {
      "start": 355.44,
      "duration": 5.52,
      "text": "agents tend to do better if you then"
    },
    {
      "start": 358.24,
      "duration": 5.76,
      "text": "build a very domain specific or agent"
    },
    {
      "start": 360.96,
      "duration": 5.359,
      "text": "specific tool to capture that particular"
    },
    {
      "start": 364,
      "duration": 4.16,
      "text": "agent's nuances."
    },
    {
      "start": 366.319,
      "duration": 4.801,
      "text": ">> And so when you get that, you get both"
    },
    {
      "start": 368.16,
      "duration": 4.96,
      "text": "the accuracy and the lower latency that"
    },
    {
      "start": 371.12,
      "duration": 3.84,
      "text": "you're looking for because you're"
    },
    {
      "start": 373.12,
      "duration": 3.68,
      "text": "pushing more off to deterministic"
    },
    {
      "start": 374.96,
      "duration": 3.92,
      "text": "software."
    },
    {
      "start": 376.8,
      "duration": 3.839,
      "text": "And then you're able to abstract out the"
    },
    {
      "start": 378.88,
      "duration": 4.48,
      "text": "common elements so that other teams can"
    },
    {
      "start": 380.639,
      "duration": 5.521,
      "text": "reuse them really easily. I love how you"
    },
    {
      "start": 383.36,
      "duration": 6.24,
      "text": "talk about the difference between just a"
    },
    {
      "start": 386.16,
      "duration": 7.44,
      "text": "basic API and then an agent needing to"
    },
    {
      "start": 389.6,
      "duration": 6.719,
      "text": "consume some kind of a service and that"
    },
    {
      "start": 393.6,
      "duration": 3.599,
      "text": "one key word which is the intention."
    },
    {
      "start": 396.319,
      "duration": 3.041,
      "text": ">> Yeah."
    },
    {
      "start": 397.199,
      "duration": 5.12,
      "text": ">> And how that intention plays such a big"
    },
    {
      "start": 399.36,
      "duration": 4.24,
      "text": "part in what is trying to consume."
    },
    {
      "start": 402.319,
      "duration": 4.481,
      "text": ">> Yeah. I think there's a lot of confusion"
    },
    {
      "start": 403.6,
      "duration": 5.12,
      "text": "right now because"
    },
    {
      "start": 406.8,
      "duration": 2.72,
      "text": "every every engineer is familiar with"
    },
    {
      "start": 408.72,
      "duration": 2.88,
      "text": "APIs."
    },
    {
      "start": 409.52,
      "duration": 4.08,
      "text": ">> Yeah. And then you throw in MCP and"
    },
    {
      "start": 411.6,
      "duration": 5.039,
      "text": "people go, \"Oh, it's the same thing."
    },
    {
      "start": 413.6,
      "duration": 5.439,
      "text": ">> Let me just wrap an API and MCP and"
    },
    {
      "start": 416.639,
      "duration": 4.641,
      "text": "success. We we have an agent and we have"
    },
    {
      "start": 419.039,
      "duration": 5.44,
      "text": "tools and it doesn't work.\""
    },
    {
      "start": 421.28,
      "duration": 4.72,
      "text": ">> Um, for a bunch of reasons."
    },
    {
      "start": 424.479,
      "duration": 4.081,
      "text": "MCP is just a wire protocol. But more"
    },
    {
      "start": 426,
      "duration": 5.52,
      "text": "importantly, tools are not APIs. And so"
    },
    {
      "start": 428.56,
      "duration": 5.52,
      "text": "in engineering speak, an API is a"
    },
    {
      "start": 431.52,
      "duration": 4.799,
      "text": "service contract for the downstream"
    },
    {
      "start": 434.08,
      "duration": 4.48,
      "text": "service. So we'll use Google Drive as an"
    },
    {
      "start": 436.319,
      "duration": 4.16,
      "text": "example. It has an API. that API is a"
    },
    {
      "start": 438.56,
      "duration": 5.199,
      "text": "service contract on how Google Drive"
    },
    {
      "start": 440.479,
      "duration": 6.081,
      "text": "works. And yes, there's a lot of work"
    },
    {
      "start": 443.759,
      "duration": 6,
      "text": "that goes into building a really nice"
    },
    {
      "start": 446.56,
      "duration": 5.52,
      "text": "Google Drive MCP server like we have um"
    },
    {
      "start": 449.759,
      "duration": 5.28,
      "text": "to make it a bit more workflowish, be"
    },
    {
      "start": 452.08,
      "duration": 5.839,
      "text": "make it more intention based to kind of"
    },
    {
      "start": 455.039,
      "duration": 5.361,
      "text": "remove or at least abstract away the"
    },
    {
      "start": 457.919,
      "duration": 4.161,
      "text": "structured inputs that are required. So"
    },
    {
      "start": 460.4,
      "duration": 5.28,
      "text": ">> an LLM has no idea what a Unix time"
    },
    {
      "start": 462.08,
      "duration": 5.839,
      "text": "stamp is. Um, so your MCP tool has to"
    },
    {
      "start": 465.68,
      "duration": 3.68,
      "text": "like know what yesterday is as a concept"
    },
    {
      "start": 467.919,
      "duration": 2.4,
      "text": "and then translate that to unique time"
    },
    {
      "start": 469.36,
      "duration": 3.52,
      "text": "stamp."
    },
    {
      "start": 470.319,
      "duration": 6.56,
      "text": ">> But even with all of that, if you're"
    },
    {
      "start": 472.88,
      "duration": 7.2,
      "text": "building a sales agent, for example, and"
    },
    {
      "start": 476.879,
      "duration": 5.6,
      "text": "and a and a rep is going to ask, \"Hey, I"
    },
    {
      "start": 480.08,
      "duration": 3.839,
      "text": "need the brochure for this product"
    },
    {
      "start": 482.479,
      "duration": 2.801,
      "text": "because I'm going into this customer"
    },
    {
      "start": 483.919,
      "duration": 3.361,
      "text": "account.\""
    },
    {
      "start": 485.28,
      "duration": 4.56,
      "text": ">> The agent doesn't care at all about"
    },
    {
      "start": 487.28,
      "duration": 4.56,
      "text": "Google Drive. That's not its intention."
    },
    {
      "start": 489.84,
      "duration": 4.56,
      "text": "its intention is to find the brochure"
    },
    {
      "start": 491.84,
      "duration": 6.32,
      "text": "that it needs. And so if you give it"
    },
    {
      "start": 494.4,
      "duration": 6.4,
      "text": "even a pristine, beautiful"
    },
    {
      "start": 498.16,
      "duration": 4.719,
      "text": "Google Drive MCP server, you're asking"
    },
    {
      "start": 500.8,
      "duration": 4.32,
      "text": "for higher latency and you're asking for"
    },
    {
      "start": 502.879,
      "duration": 4.401,
      "text": "hallucinations because now you have to"
    },
    {
      "start": 505.12,
      "duration": 5.28,
      "text": "stuff the context window with"
    },
    {
      "start": 507.28,
      "duration": 4.8,
      "text": "explanations of how to find the brochure"
    },
    {
      "start": 510.4,
      "duration": 2.8,
      "text": "using the MCP server,"
    },
    {
      "start": 512.08,
      "duration": 2.72,
      "text": ">> which means it's going to have to take"
    },
    {
      "start": 513.2,
      "duration": 3.12,
      "text": "multiple turns figuring out what the"
    },
    {
      "start": 514.8,
      "duration": 3.44,
      "text": "right folder is and where the right"
    },
    {
      "start": 516.32,
      "duration": 3.12,
      "text": "files are and how to determine which"
    },
    {
      "start": 518.24,
      "duration": 2.159,
      "text": "ones are brochures and which ones aren't"
    },
    {
      "start": 519.44,
      "duration": 3.599,
      "text": "brochures and which is the right"
    },
    {
      "start": 520.399,
      "duration": 5.201,
      "text": "brochure. But if you instead give it a"
    },
    {
      "start": 523.039,
      "duration": 5.441,
      "text": "get brochure tool and that get brochure"
    },
    {
      "start": 525.6,
      "duration": 4.4,
      "text": "tool can call the Google Drive MCP"
    },
    {
      "start": 528.48,
      "duration": 4.24,
      "text": "server,"
    },
    {
      "start": 530,
      "duration": 4.24,
      "text": "then all of a sudden all the agent has"
    },
    {
      "start": 532.72,
      "duration": 3.04,
      "text": "to do is say, \"Oh, I need a brochure."
    },
    {
      "start": 534.24,
      "duration": 2.96,
      "text": "There's a get brochure tool. I have the"
    },
    {
      "start": 535.76,
      "duration": 3.519,
      "text": "context that I need. Let me submit that"
    },
    {
      "start": 537.2,
      "duration": 4.079,
      "text": "as arguments.\" And then it's done. It's"
    },
    {
      "start": 539.279,
      "duration": 3.68,
      "text": "one call. It's low latency. You don't"
    },
    {
      "start": 541.279,
      "duration": 3.921,
      "text": "have to stuff the context window. You"
    },
    {
      "start": 542.959,
      "duration": 6.401,
      "text": "minimize the amount of tool definitions"
    },
    {
      "start": 545.2,
      "duration": 7.28,
      "text": "that you passed over. And then likely"
    },
    {
      "start": 549.36,
      "duration": 5.68,
      "text": "much of the code inside of the get"
    },
    {
      "start": 552.48,
      "duration": 4.72,
      "text": "brochure tool is deterministic."
    },
    {
      "start": 555.04,
      "duration": 3.68,
      "text": ">> You know, chances are it's not calling a"
    },
    {
      "start": 557.2,
      "duration": 4.16,
      "text": "model or if it is, it's calling one"
    },
    {
      "start": 558.72,
      "duration": 5.119,
      "text": "maybe once I think very specific. So the"
    },
    {
      "start": 561.36,
      "duration": 6.159,
      "text": "whole system just gets more accurate and"
    },
    {
      "start": 563.839,
      "duration": 6.321,
      "text": "faster. And so what that means is"
    },
    {
      "start": 567.519,
      "duration": 4.641,
      "text": "a tool is actually kind of the inverse"
    },
    {
      "start": 570.16,
      "duration": 3.679,
      "text": "of an API. Well, an API is a service"
    },
    {
      "start": 572.16,
      "duration": 3.92,
      "text": "contract of what a of what a downstream"
    },
    {
      "start": 573.839,
      "duration": 4.401,
      "text": "service looks like like Google Drive. In"
    },
    {
      "start": 576.08,
      "duration": 4.08,
      "text": "my opinion, a tool is kind of like the"
    },
    {
      "start": 578.24,
      "duration": 3.52,
      "text": "service contract for the agents"
    },
    {
      "start": 580.16,
      "duration": 5.84,
      "text": "intentions."
    },
    {
      "start": 581.76,
      "duration": 7.519,
      "text": ">> It's it's what it expects to do."
    },
    {
      "start": 586,
      "duration": 6.08,
      "text": ">> Okay. And being able to write the proper"
    },
    {
      "start": 589.279,
      "duration": 3.041,
      "text": "tool definition is really the key"
    },
    {
      "start": 592.08,
      "duration": 1.439,
      "text": "though."
    },
    {
      "start": 592.32,
      "duration": 1.68,
      "text": ">> It's like it's like half the battle."
    },
    {
      "start": 593.519,
      "duration": 1.44,
      "text": ">> Yeah."
    },
    {
      "start": 594,
      "duration": 2.8,
      "text": ">> It's like half the battle."
    },
    {
      "start": 594.959,
      "duration": 4.56,
      "text": ">> That's why evaluations are so important"
    },
    {
      "start": 596.8,
      "duration": 5.2,
      "text": "as well. Well, I think also I just want"
    },
    {
      "start": 599.519,
      "duration": 5.041,
      "text": "to highlight such an important thing"
    },
    {
      "start": 602,
      "duration": 4.959,
      "text": "that you said yesterday and just now"
    },
    {
      "start": 604.56,
      "duration": 5.6,
      "text": "again, which is let somebody else look"
    },
    {
      "start": 606.959,
      "duration": 5.281,
      "text": "at your tool definitions. Let them see"
    },
    {
      "start": 610.16,
      "duration": 6.16,
      "text": "if they can understand it. And if they"
    },
    {
      "start": 612.24,
      "duration": 5.92,
      "text": "can, then you can try it with the agent."
    },
    {
      "start": 616.32,
      "duration": 4.079,
      "text": "But if they can't, you already know, all"
    },
    {
      "start": 618.16,
      "duration": 2.96,
      "text": "right, this is probably where the"
    },
    {
      "start": 620.399,
      "duration": 4.081,
      "text": "problem is."
    },
    {
      "start": 621.12,
      "duration": 6.24,
      "text": ">> Yeah. Exactly. Um, and this exercise"
    },
    {
      "start": 624.48,
      "duration": 5.84,
      "text": "really forces you to to have clear tool"
    },
    {
      "start": 627.36,
      "duration": 6,
      "text": "definitions. And I think it's also"
    },
    {
      "start": 630.32,
      "duration": 5.199,
      "text": "important to try to limit the agent"
    },
    {
      "start": 633.36,
      "duration": 3.76,
      "text": "choices as much as possible. I think if"
    },
    {
      "start": 635.519,
      "duration": 4,
      "text": "there is a lesson I've learned in this"
    },
    {
      "start": 637.12,
      "duration": 4.88,
      "text": "year's building agents, that's that's"
    },
    {
      "start": 639.519,
      "duration": 6.161,
      "text": "this one. Um, it decreases"
    },
    {
      "start": 642,
      "duration": 7.12,
      "text": "hallucinations. It decreases um context"
    },
    {
      "start": 645.68,
      "duration": 5.599,
      "text": "bloating as well. Um, if you have tool"
    },
    {
      "start": 649.12,
      "duration": 4.399,
      "text": "that's like tools that are always called"
    },
    {
      "start": 651.279,
      "duration": 4.56,
      "text": "together like in the get brochure case,"
    },
    {
      "start": 653.519,
      "duration": 4.401,
      "text": "it makes so much more sense to create a"
    },
    {
      "start": 655.839,
      "duration": 5.841,
      "text": "workflow and encapsulate that into a"
    },
    {
      "start": 657.92,
      "duration": 5.84,
      "text": "tool. A tool is um something that LLM"
    },
    {
      "start": 661.68,
      "duration": 4.159,
      "text": "can use to take action. It doesn't need"
    },
    {
      "start": 663.76,
      "duration": 4.4,
      "text": "to know what's inside. It can be a it"
    },
    {
      "start": 665.839,
      "duration": 5.041,
      "text": "can even be another agent, right?"
    },
    {
      "start": 668.16,
      "duration": 5.919,
      "text": ">> Um so yeah, one way is also to use"
    },
    {
      "start": 670.88,
      "duration": 4.72,
      "text": "multi- aent setup, of course. Uh but for"
    },
    {
      "start": 674.079,
      "duration": 3.041,
      "text": "from the point of view of the main"
    },
    {
      "start": 675.6,
      "duration": 3.919,
      "text": "agent, it doesn't really matter."
    },
    {
      "start": 677.12,
      "duration": 6.159,
      "text": ">> Yeah, we we think a lot about this. Um"
    },
    {
      "start": 679.519,
      "duration": 5.681,
      "text": "so yeah, in a perfect world, you give it"
    },
    {
      "start": 683.279,
      "duration": 4,
      "text": "you give it one tool, right? In a"
    },
    {
      "start": 685.2,
      "duration": 3.52,
      "text": "perfect world, uh the agent doesn't have"
    },
    {
      "start": 687.279,
      "duration": 2.961,
      "text": "to think at all and you don't even need"
    },
    {
      "start": 688.72,
      "duration": 1.92,
      "text": "an LLM."
    },
    {
      "start": 690.24,
      "duration": 3.92,
      "text": ">> Yeah."
    },
    {
      "start": 690.64,
      "duration": 6.16,
      "text": ">> Right. Um because it's faster, it's"
    },
    {
      "start": 694.16,
      "duration": 4.96,
      "text": "cheaper, it's deterministic."
    },
    {
      "start": 696.8,
      "duration": 5.12,
      "text": "But that's not the real world. The power"
    },
    {
      "start": 699.12,
      "duration": 4.719,
      "text": "of of an agent is that it can handle"
    },
    {
      "start": 701.92,
      "duration": 5.44,
      "text": "generality."
    },
    {
      "start": 703.839,
      "duration": 5.201,
      "text": "And so there's this careful balance. You"
    },
    {
      "start": 707.36,
      "duration": 4.4,
      "text": "know, Sam, my co-founder, talks about"
    },
    {
      "start": 709.04,
      "duration": 5.28,
      "text": "turning the knob on determinism."
    },
    {
      "start": 711.76,
      "duration": 4.8,
      "text": "And so"
    },
    {
      "start": 714.32,
      "duration": 6.88,
      "text": "you can give it fewer tools and you and"
    },
    {
      "start": 716.56,
      "duration": 6.719,
      "text": "arguably today you should because you"
    },
    {
      "start": 721.2,
      "duration": 6.319,
      "text": "want to minimize error rates."
    },
    {
      "start": 723.279,
      "duration": 6.8,
      "text": "Um but the point of all of this where"
    },
    {
      "start": 727.519,
      "duration": 5.201,
      "text": "all this is going uh where all the"
    },
    {
      "start": 730.079,
      "duration": 4.081,
      "text": "investments are going where the model"
    },
    {
      "start": 732.72,
      "duration": 3.76,
      "text": "companies are investing heavily where"
    },
    {
      "start": 734.16,
      "duration": 3.52,
      "text": "the orchestration systems like Langraph"
    },
    {
      "start": 736.48,
      "duration": 2.96,
      "text": "are investing heavily where we're"
    },
    {
      "start": 737.68,
      "duration": 5.04,
      "text": "investing heavily as a world which is"
    },
    {
      "start": 739.44,
      "duration": 5.36,
      "text": "the opposite where you can turn up the"
    },
    {
      "start": 742.72,
      "duration": 4.799,
      "text": "the you know the non-determinism you can"
    },
    {
      "start": 744.8,
      "duration": 5.92,
      "text": "turn up the ability to give it as many"
    },
    {
      "start": 747.519,
      "duration": 5.44,
      "text": "tools as you want and then let the agent"
    },
    {
      "start": 750.72,
      "duration": 3.76,
      "text": "intelligently decide what to"
    },
    {
      "start": 752.959,
      "duration": 3.761,
      "text": "That's very hard. That's where we're"
    },
    {
      "start": 754.48,
      "duration": 5.76,
      "text": "going to get to at the limit."
    },
    {
      "start": 756.72,
      "duration": 5.28,
      "text": ">> You know, we ourselves have achieved,"
    },
    {
      "start": 760.24,
      "duration": 3.68,
      "text": "you know, incredible things in the lab"
    },
    {
      "start": 762,
      "duration": 4.72,
      "text": "that we haven't yet announced."
    },
    {
      "start": 763.92,
      "duration": 5.68,
      "text": ">> Uh where we're making it possible to"
    },
    {
      "start": 766.72,
      "duration": 4.32,
      "text": "kind of turn that that dial up on the"
    },
    {
      "start": 769.6,
      "duration": 4.4,
      "text": "tool level."
    },
    {
      "start": 771.04,
      "duration": 4.72,
      "text": ">> But for most people today, you're right."
    },
    {
      "start": 774,
      "duration": 5.12,
      "text": "You're better off really thinking"
    },
    {
      "start": 775.76,
      "duration": 4.96,
      "text": "through in a multi- aent system. you"
    },
    {
      "start": 779.12,
      "duration": 3.36,
      "text": "know, which are the right tools based on"
    },
    {
      "start": 780.72,
      "duration": 6.08,
      "text": "the node that I'm in or the state that"
    },
    {
      "start": 782.48,
      "duration": 6.32,
      "text": "I'm in and trying to be very specific."
    },
    {
      "start": 786.8,
      "duration": 4.64,
      "text": "But the benefits of giving it more tools"
    },
    {
      "start": 788.8,
      "duration": 4.64,
      "text": "are huge because then you have fewer"
    },
    {
      "start": 791.44,
      "duration": 3.199,
      "text": "nodes, the agents more intelligent, but"
    },
    {
      "start": 793.44,
      "duration": 2.079,
      "text": "it really depends on what you're trying"
    },
    {
      "start": 794.639,
      "duration": 4.481,
      "text": "to do."
    },
    {
      "start": 795.519,
      "duration": 8,
      "text": ">> Yeah. Also I think the we haven't"
    },
    {
      "start": 799.12,
      "duration": 6.8,
      "text": "touched on this topic but the way output"
    },
    {
      "start": 803.519,
      "duration": 4,
      "text": "um the way you construct a tool output"
    },
    {
      "start": 805.92,
      "duration": 4,
      "text": "is also important because you can put a"
    },
    {
      "start": 807.519,
      "duration": 4.401,
      "text": "lot of instructions there as well. So by"
    },
    {
      "start": 809.92,
      "duration": 4.88,
      "text": "limiting the amount of choices I don't"
    },
    {
      "start": 811.92,
      "duration": 3.84,
      "text": "mean the agent shouldn't have tools like"
    },
    {
      "start": 814.8,
      "duration": 3.12,
      "text": "we should try to make it as"
    },
    {
      "start": 815.76,
      "duration": 5.04,
      "text": "deterministic as possible. Uh we can"
    },
    {
      "start": 817.92,
      "duration": 4.56,
      "text": "still leave freedom but I think we need"
    },
    {
      "start": 820.8,
      "duration": 2.88,
      "text": "to be smart in where we put the"
    },
    {
      "start": 822.48,
      "duration": 4.96,
      "text": "information where we put the"
    },
    {
      "start": 823.68,
      "duration": 6.56,
      "text": "instructions. So if um for instance I"
    },
    {
      "start": 827.44,
      "duration": 5.68,
      "text": "always have a certain options for tools"
    },
    {
      "start": 830.24,
      "duration": 5.44,
      "text": "after a given tool is called I can put"
    },
    {
      "start": 833.12,
      "duration": 4.88,
      "text": "the instructions in the tool response. I"
    },
    {
      "start": 835.68,
      "duration": 3.44,
      "text": "don't need to to bloat the system prompt"
    },
    {
      "start": 838,
      "duration": 3.12,
      "text": "with those instructions."
    },
    {
      "start": 839.12,
      "duration": 4.64,
      "text": ">> I've heard that a ton that dynamically"
    },
    {
      "start": 841.12,
      "duration": 4.64,
      "text": "inserting context in there. That's one"
    },
    {
      "start": 843.76,
      "duration": 5.36,
      "text": "way of doing it. There's all kinds of"
    },
    {
      "start": 845.76,
      "duration": 5.199,
      "text": "fancy ways that you can make sure to"
    },
    {
      "start": 849.12,
      "duration": 4.32,
      "text": "leave things out that need to be left"
    },
    {
      "start": 850.959,
      "duration": 3.921,
      "text": "out and then when it needs it if it"
    },
    {
      "start": 853.44,
      "duration": 2.399,
      "text": "needs it. It's like this is a need to"
    },
    {
      "start": 854.88,
      "duration": 1.519,
      "text": "know basis here."
    },
    {
      "start": 855.839,
      "duration": 3.68,
      "text": ">> Yeah."
    },
    {
      "start": 856.399,
      "duration": 9.041,
      "text": ">> Well, I think I'll I'll go back to this"
    },
    {
      "start": 859.519,
      "duration": 8.161,
      "text": "concept of uh layering up tools."
    },
    {
      "start": 865.44,
      "duration": 3.6,
      "text": ">> If you look at APIs, this pattern"
    },
    {
      "start": 867.68,
      "duration": 3.839,
      "text": "already exists."
    },
    {
      "start": 869.04,
      "duration": 6.32,
      "text": ">> You've got your your low-level system"
    },
    {
      "start": 871.519,
      "duration": 6.401,
      "text": "APIs, you've got your workflow APIs in"
    },
    {
      "start": 875.36,
      "duration": 4.4,
      "text": "the back end, and then you have the APIs"
    },
    {
      "start": 877.92,
      "duration": 3.039,
      "text": "that that the that the mobile"
    },
    {
      "start": 879.76,
      "duration": 2.96,
      "text": "application or the JavaScript"
    },
    {
      "start": 880.959,
      "duration": 3.201,
      "text": "application talks to. And there are like"
    },
    {
      "start": 882.72,
      "duration": 2,
      "text": "three different sets of APIs."
    },
    {
      "start": 884.16,
      "duration": 2.16,
      "text": ">> Mh."
    },
    {
      "start": 884.72,
      "duration": 3.119,
      "text": ">> And when you get all the way to the top"
    },
    {
      "start": 886.32,
      "duration": 4.24,
      "text": "where it's a JavaScript app talking to"
    },
    {
      "start": 887.839,
      "duration": 5.521,
      "text": "the back ends, those APIs are very very"
    },
    {
      "start": 890.56,
      "duration": 4.56,
      "text": "specific to that application most of the"
    },
    {
      "start": 893.36,
      "duration": 2.96,
      "text": "time. And similarly in what you're"
    },
    {
      "start": 895.12,
      "duration": 2.56,
      "text": "describing, and we talked a little more"
    },
    {
      "start": 896.32,
      "duration": 4.639,
      "text": "about this last night, so I'm going to"
    },
    {
      "start": 897.68,
      "duration": 6.64,
      "text": "I'm going to steal from last night. You"
    },
    {
      "start": 900.959,
      "duration": 6.401,
      "text": "can insert UI code in the response,"
    },
    {
      "start": 904.32,
      "duration": 4.8,
      "text": ">> right? You can present a table. It"
    },
    {
      "start": 907.36,
      "duration": 6.56,
      "text": "doesn't have to be just text. You can"
    },
    {
      "start": 909.12,
      "duration": 7.279,
      "text": "present a React component in a tool that"
    },
    {
      "start": 913.92,
      "duration": 4.8,
      "text": "gets very agent specific, but that's"
    },
    {
      "start": 916.399,
      "duration": 3.761,
      "text": "kind of the point. You minimize the"
    },
    {
      "start": 918.72,
      "duration": 4.559,
      "text": "amount of work being done by the rest of"
    },
    {
      "start": 920.16,
      "duration": 5.76,
      "text": "the system by the tool carrying and"
    },
    {
      "start": 923.279,
      "duration": 5.041,
      "text": "doing a lot of the heavy lifting."
    },
    {
      "start": 925.92,
      "duration": 4.56,
      "text": "And you know, I'll go back to the Google"
    },
    {
      "start": 928.32,
      "duration": 4.24,
      "text": "Drive example, right? Sure, it can pull"
    },
    {
      "start": 930.48,
      "duration": 3.599,
      "text": "the brochure, but it can also go pull a"
    },
    {
      "start": 932.56,
      "duration": 5.839,
      "text": "bunch of context that you know the"
    },
    {
      "start": 934.079,
      "duration": 6.241,
      "text": "model's going to need on the next turn."
    },
    {
      "start": 938.399,
      "duration": 4.961,
      "text": "Yeah, it reminds me of a conversation I"
    },
    {
      "start": 940.32,
      "duration": 5.6,
      "text": "had with Zach uh from Sierra and he was"
    },
    {
      "start": 943.36,
      "duration": 4.08,
      "text": "saying that a lot of times since they're"
    },
    {
      "start": 945.92,
      "duration": 5.279,
      "text": "doing voice agents and it's real-time"
    },
    {
      "start": 947.44,
      "duration": 6.88,
      "text": "voice agents, what happens is they'll"
    },
    {
      "start": 951.199,
      "duration": 8.08,
      "text": "have almost like a supervisor agent that"
    },
    {
      "start": 954.32,
      "duration": 8.4,
      "text": "will recognize and preemptively assume"
    },
    {
      "start": 959.279,
      "duration": 6.161,
      "text": "if this conversation is going in a"
    },
    {
      "start": 962.72,
      "duration": 5.76,
      "text": "direction that I think I may need this"
    },
    {
      "start": 965.44,
      "duration": 5.36,
      "text": "context for. they just go and grab it"
    },
    {
      "start": 968.48,
      "duration": 3.84,
      "text": "just in case it comes up and all right"
    },
    {
      "start": 970.8,
      "duration": 3.44,
      "text": "we have it now I can give it to you and"
    },
    {
      "start": 972.32,
      "duration": 4.319,
      "text": "then you don't have that user experience"
    },
    {
      "start": 974.24,
      "duration": 6.399,
      "text": "where the person is waiting on the other"
    },
    {
      "start": 976.639,
      "duration": 5.76,
      "text": "line because the context needs to go and"
    },
    {
      "start": 980.639,
      "duration": 3.281,
      "text": "you need to grab it and bring it back"
    },
    {
      "start": 982.399,
      "duration": 3.521,
      "text": "and that takes a little bit longer. It's"
    },
    {
      "start": 983.92,
      "duration": 4,
      "text": "just like let's have everything kind of"
    },
    {
      "start": 985.92,
      "duration": 4.159,
      "text": "loaded up and then if we need it we can"
    },
    {
      "start": 987.92,
      "duration": 3.039,
      "text": "serve it to the agent that's interacting"
    },
    {
      "start": 990.079,
      "duration": 2.721,
      "text": "with the human."
    },
    {
      "start": 990.959,
      "duration": 4.081,
      "text": ">> Well, I mean I I think that speaks to"
    },
    {
      "start": 992.8,
      "duration": 5.92,
      "text": "you know how quickly the industry's"
    },
    {
      "start": 995.04,
      "duration": 8,
      "text": "changed. It's November of 2025 right now"
    },
    {
      "start": 998.72,
      "duration": 6.16,
      "text": "and the conversation is no longer about"
    },
    {
      "start": 1003.04,
      "duration": 2.96,
      "text": "accuracy and consistency being the"
    },
    {
      "start": 1004.88,
      "duration": 2.48,
      "text": "blocker to production."
    },
    {
      "start": 1006,
      "duration": 3.839,
      "text": ">> Mhm."
    },
    {
      "start": 1007.36,
      "duration": 4.88,
      "text": ">> 5 months ago, maybe even less, that was"
    },
    {
      "start": 1009.839,
      "duration": 4.161,
      "text": "the only conversation we were having."
    },
    {
      "start": 1012.24,
      "duration": 2.399,
      "text": "Now we're talking about latency."
    },
    {
      "start": 1014,
      "duration": 2.56,
      "text": ">> Yeah."
    },
    {
      "start": 1014.639,
      "duration": 3.681,
      "text": ">> Every like that is the biggest problem."
    },
    {
      "start": 1016.56,
      "duration": 3.12,
      "text": "We're going to prod now, but now we're"
    },
    {
      "start": 1018.32,
      "duration": 3.36,
      "text": "just having, you know, mediocre"
    },
    {
      "start": 1019.68,
      "duration": 2.719,
      "text": "experience because we're all waiting 30"
    },
    {
      "start": 1021.68,
      "duration": 2.96,
      "text": "seconds."
    },
    {
      "start": 1022.399,
      "duration": 4.721,
      "text": ">> Yeah. and and now and it's it's amusing"
    },
    {
      "start": 1024.64,
      "duration": 4.24,
      "text": "to me because if we were waiting 30"
    },
    {
      "start": 1027.12,
      "duration": 3.52,
      "text": "seconds five months ago, we would have"
    },
    {
      "start": 1028.88,
      "duration": 4.24,
      "text": "been totally cool with it."
    },
    {
      "start": 1030.64,
      "duration": 4.319,
      "text": ">> But now we're like 30 seconds, right?"
    },
    {
      "start": 1033.12,
      "duration": 3.839,
      "text": ">> This also connects to what I said"
    },
    {
      "start": 1034.959,
      "duration": 4.08,
      "text": "earlier about WhatsApp versus app"
    },
    {
      "start": 1036.959,
      "duration": 4.88,
      "text": "experience. So on WhatsApp, people are"
    },
    {
      "start": 1039.039,
      "duration": 4.16,
      "text": "totally fine with waiting because they"
    },
    {
      "start": 1041.839,
      "duration": 3.441,
      "text": "expect it. It's it's a familiar"
    },
    {
      "start": 1043.199,
      "duration": 4.161,
      "text": "interface. Uh they don't expect it to go"
    },
    {
      "start": 1045.28,
      "duration": 3.44,
      "text": "so fast probably because normally you"
    },
    {
      "start": 1047.36,
      "duration": 4.16,
      "text": "have another person speaking on the"
    },
    {
      "start": 1048.72,
      "duration": 6.64,
      "text": "other side. But on app you're punished"
    },
    {
      "start": 1051.52,
      "duration": 5.36,
      "text": "if you if you don't deliver in time. The"
    },
    {
      "start": 1055.36,
      "duration": 3.12,
      "text": "the expectations are completely"
    },
    {
      "start": 1056.88,
      "duration": 3.679,
      "text": "different even for the same user."
    },
    {
      "start": 1058.48,
      "duration": 4.64,
      "text": ">> In a perfect world where you had user"
    },
    {
      "start": 1060.559,
      "duration": 4,
      "text": "feedback from everybody who's using"
    },
    {
      "start": 1063.12,
      "duration": 3.52,
      "text": "interacting with your agent in real"
    },
    {
      "start": 1064.559,
      "duration": 3.921,
      "text": "time. I'd be very curious to see a"
    },
    {
      "start": 1066.64,
      "duration": 4.64,
      "text": "generational distribution"
    },
    {
      "start": 1068.48,
      "duration": 4.16,
      "text": ">> on on patients for waiting for the agent"
    },
    {
      "start": 1071.28,
      "duration": 2.56,
      "text": ">> because one of the things that one of"
    },
    {
      "start": 1072.64,
      "duration": 4.8,
      "text": "the things that I see"
    },
    {
      "start": 1073.84,
      "duration": 5.44,
      "text": ">> but I'm very curious uh is"
    },
    {
      "start": 1077.44,
      "duration": 4.88,
      "text": "the"
    },
    {
      "start": 1079.28,
      "duration": 6.48,
      "text": "the generation of people who are let's"
    },
    {
      "start": 1082.32,
      "duration": 8.32,
      "text": "say under 30 expect everything to be"
    },
    {
      "start": 1085.76,
      "duration": 6.799,
      "text": "agentic. if they see a menu,"
    },
    {
      "start": 1090.64,
      "duration": 5.52,
      "text": "you know, they've got to click around,"
    },
    {
      "start": 1092.559,
      "duration": 5.761,
      "text": "they just they bail, right? The later"
    },
    {
      "start": 1096.16,
      "duration": 5.6,
      "text": "generations are the opposite. They"
    },
    {
      "start": 1098.32,
      "duration": 6.64,
      "text": "expect a snappy UI, very snappy and"
    },
    {
      "start": 1101.76,
      "duration": 5.44,
      "text": "responsive buttons and clicks, but I'm"
    },
    {
      "start": 1104.96,
      "duration": 4.56,
      "text": "very curious how"
    },
    {
      "start": 1107.2,
      "duration": 4.56,
      "text": "the the generational"
    },
    {
      "start": 1109.52,
      "duration": 4.8,
      "text": "distribution might be on on patients for"
    },
    {
      "start": 1111.76,
      "duration": 4.48,
      "text": "latency. M and I also feel like when"
    },
    {
      "start": 1114.32,
      "duration": 3.2,
      "text": "you're in WhatsApp, you can go and you"
    },
    {
      "start": 1116.24,
      "duration": 4.64,
      "text": "can talk to your friend, you can look at"
    },
    {
      "start": 1117.52,
      "duration": 6.56,
      "text": "something else and then come back and so"
    },
    {
      "start": 1120.88,
      "duration": 5.919,
      "text": "you get that cuz I imagine that you get"
    },
    {
      "start": 1124.08,
      "duration": 4.56,
      "text": "a notification when the agent is done"
    },
    {
      "start": 1126.799,
      "duration": 3.681,
      "text": "and it's sending you the information."
    },
    {
      "start": 1128.64,
      "duration": 4,
      "text": "You don't have to sit there and wait the"
    },
    {
      "start": 1130.48,
      "duration": 3.92,
      "text": "30 seconds looking at the WhatsApp chat."
    },
    {
      "start": 1132.64,
      "duration": 3.6,
      "text": "When I'm in WhatsApp, I'm talking with"
    },
    {
      "start": 1134.4,
      "duration": 3.519,
      "text": "three or four people at the same time"
    },
    {
      "start": 1136.24,
      "duration": 2.559,
      "text": "and I'm going back and forth between"
    },
    {
      "start": 1137.919,
      "duration": 3.041,
      "text": "those conversations."
    },
    {
      "start": 1138.799,
      "duration": 4.481,
      "text": ">> Exactly. The data that we got was really"
    },
    {
      "start": 1140.96,
      "duration": 4.959,
      "text": "clear about this. That's why we spent so"
    },
    {
      "start": 1143.28,
      "duration": 5.04,
      "text": "much time refining UX thinking how to"
    },
    {
      "start": 1145.919,
      "duration": 4.081,
      "text": "present you know the data to the user."
    },
    {
      "start": 1148.32,
      "duration": 3.92,
      "text": "There's a lot of work done around the"
    },
    {
      "start": 1150,
      "duration": 3.76,
      "text": "agent that is not agent itself. And I"
    },
    {
      "start": 1152.24,
      "duration": 5.679,
      "text": "think this was one of the biggest"
    },
    {
      "start": 1153.76,
      "duration": 7.279,
      "text": "challenges. Um also users you know they"
    },
    {
      "start": 1157.919,
      "duration": 6.561,
      "text": "are familiar with AI by now but uh it's"
    },
    {
      "start": 1161.039,
      "duration": 5.281,
      "text": "still hard to to trust an AI interface"
    },
    {
      "start": 1164.48,
      "duration": 3.439,
      "text": "to suggest you food. People are pretty"
    },
    {
      "start": 1166.32,
      "duration": 5.359,
      "text": "sensitive around that. they have their"
    },
    {
      "start": 1167.919,
      "duration": 7.681,
      "text": "preferences. Um, so we really needed to"
    },
    {
      "start": 1171.679,
      "duration": 6.161,
      "text": "build customer adoption, make it uh like"
    },
    {
      "start": 1175.6,
      "duration": 3.92,
      "text": "also in terms of the persona that we"
    },
    {
      "start": 1177.84,
      "duration": 4.4,
      "text": "developed, it needed to be friendly but"
    },
    {
      "start": 1179.52,
      "duration": 4.8,
      "text": "also engaging. Uh, we wanted people to"
    },
    {
      "start": 1182.24,
      "duration": 5.439,
      "text": "come back, right? It all connects to"
    },
    {
      "start": 1184.32,
      "duration": 6.32,
      "text": "tools at the end that wasn't uh how do"
    },
    {
      "start": 1187.679,
      "duration": 4.641,
      "text": "you define it, how you use it, um how"
    },
    {
      "start": 1190.64,
      "duration": 3.2,
      "text": "smart you want it to be."
    },
    {
      "start": 1192.32,
      "duration": 7.239,
      "text": ">> Can I call something you said that I"
    },
    {
      "start": 1193.84,
      "duration": 5.719,
      "text": "think is perfectly on point? Um, today"
    },
    {
      "start": 1199.6,
      "duration": 5.04,
      "text": "the the intersection between an"
    },
    {
      "start": 1202.32,
      "duration": 3.359,
      "text": "application and an agent is now"
    },
    {
      "start": 1204.64,
      "duration": 2.399,
      "text": "complete."
    },
    {
      "start": 1205.679,
      "duration": 3.441,
      "text": ">> And you mentioned earlier, right? Like"
    },
    {
      "start": 1207.039,
      "duration": 4.481,
      "text": "so many of the things that you ran into"
    },
    {
      "start": 1209.12,
      "duration": 6.32,
      "text": "as you were building this weren't"
    },
    {
      "start": 1211.52,
      "duration": 5.36,
      "text": "necessarily like the model or the AI. It"
    },
    {
      "start": 1215.44,
      "duration": 2.16,
      "text": "was the the application."
    },
    {
      "start": 1216.88,
      "duration": 3.2,
      "text": ">> Yeah."
    },
    {
      "start": 1217.6,
      "duration": 5.04,
      "text": ">> And and I feel again, you know, speaking"
    },
    {
      "start": 1220.08,
      "duration": 4.32,
      "text": "at least today and you know, we'll see"
    },
    {
      "start": 1222.64,
      "duration": 5.279,
      "text": "what the world looks like in 3 months."
    },
    {
      "start": 1224.4,
      "duration": 5.759,
      "text": "Um that's itself a huge transition you"
    },
    {
      "start": 1227.919,
      "duration": 4.24,
      "text": "know now we're having the debate is now"
    },
    {
      "start": 1230.159,
      "duration": 4.161,
      "text": "well how do I make this UI work properly"
    },
    {
      "start": 1232.159,
      "duration": 5.041,
      "text": "and you know how do I deliver this to"
    },
    {
      "start": 1234.32,
      "duration": 5.28,
      "text": "the to the to the to the user properly"
    },
    {
      "start": 1237.2,
      "duration": 6.08,
      "text": "as opposed to getting all caught up in"
    },
    {
      "start": 1239.6,
      "duration": 4.72,
      "text": "this super deep ML data science of the"
    },
    {
      "start": 1243.28,
      "duration": 3.92,
      "text": "AI"
    },
    {
      "start": 1244.32,
      "duration": 5.359,
      "text": ">> and this also connects to evaluations"
    },
    {
      "start": 1247.2,
      "duration": 4.08,
      "text": "how do you evaluate such a system"
    },
    {
      "start": 1249.679,
      "duration": 3.441,
      "text": "because when we talk about evaluations"
    },
    {
      "start": 1251.28,
      "duration": 4.48,
      "text": "we have the standard metrics in mind"
    },
    {
      "start": 1253.12,
      "duration": 4.32,
      "text": "like faithfulness helpfulness, you name"
    },
    {
      "start": 1255.76,
      "duration": 3.6,
      "text": "it, but they're not necessarily"
    },
    {
      "start": 1257.44,
      "duration": 3.44,
      "text": "connected to the business value that"
    },
    {
      "start": 1259.36,
      "duration": 2,
      "text": "your app brings."
    },
    {
      "start": 1260.88,
      "duration": 4.88,
      "text": ">> Mh."
    },
    {
      "start": 1261.36,
      "duration": 6.559,
      "text": ">> Um, like how can you leave UX out of the"
    },
    {
      "start": 1265.76,
      "duration": 4,
      "text": "evaluation? Like you you need to take"
    },
    {
      "start": 1267.919,
      "duration": 3.441,
      "text": "this UX elements into account. That's"
    },
    {
      "start": 1269.76,
      "duration": 3.68,
      "text": "part of the of the user journey and"
    },
    {
      "start": 1271.36,
      "duration": 4,
      "text": "that's also part of the agent. It's"
    },
    {
      "start": 1273.44,
      "duration": 4.4,
      "text": "really really hard to to separate these"
    },
    {
      "start": 1275.36,
      "duration": 5.92,
      "text": "two. We were joking last night that"
    },
    {
      "start": 1277.84,
      "duration": 5.12,
      "text": "every developer uh believes so strongly"
    },
    {
      "start": 1281.28,
      "duration": 3.36,
      "text": "in test-driven development that they"
    },
    {
      "start": 1282.96,
      "duration": 3.04,
      "text": "recommend every other developer do test"
    },
    {
      "start": 1284.64,
      "duration": 2.72,
      "text": "driven development. They just too lazy"
    },
    {
      "start": 1286,
      "duration": 4.72,
      "text": "to do it themselves,"
    },
    {
      "start": 1287.36,
      "duration": 6.08,
      "text": ">> right? But I feel with agents,"
    },
    {
      "start": 1290.72,
      "duration": 3.92,
      "text": "especially around evals, you have to"
    },
    {
      "start": 1293.44,
      "duration": 3.68,
      "text": "start there."
    },
    {
      "start": 1294.64,
      "duration": 4.32,
      "text": ">> Um and so I'm curious on this point,"
    },
    {
      "start": 1297.12,
      "duration": 4.64,
      "text": "which I think is a really incredible"
    },
    {
      "start": 1298.96,
      "duration": 4.56,
      "text": "point around assessing the connection"
    },
    {
      "start": 1301.76,
      "duration": 4.24,
      "text": "between business value and and and the"
    },
    {
      "start": 1303.52,
      "duration": 4.32,
      "text": "user UI. How did you how did you"
    },
    {
      "start": 1306,
      "duration": 4.88,
      "text": "structure your evals? What what were the"
    },
    {
      "start": 1307.84,
      "duration": 5.199,
      "text": "evals you you ultimately landed on?"
    },
    {
      "start": 1310.88,
      "duration": 5.039,
      "text": ">> We have different levels of evals,"
    },
    {
      "start": 1313.039,
      "duration": 5.52,
      "text": "right? Uh you have those more connected"
    },
    {
      "start": 1315.919,
      "duration": 5.441,
      "text": "to development. Uh like making sure"
    },
    {
      "start": 1318.559,
      "duration": 4.801,
      "text": "everything works like regression test um"
    },
    {
      "start": 1321.36,
      "duration": 4.48,
      "text": "things you can evaluate with code that"
    },
    {
      "start": 1323.36,
      "duration": 6.72,
      "text": "that's like the foundation. Uh we also"
    },
    {
      "start": 1325.84,
      "duration": 8.24,
      "text": "have a golden data set that we run. What"
    },
    {
      "start": 1330.08,
      "duration": 6.64,
      "text": "we realized after I think the the evol"
    },
    {
      "start": 1334.08,
      "duration": 6.32,
      "text": "community is shifting towards uh towards"
    },
    {
      "start": 1336.72,
      "duration": 6.4,
      "text": "this as well is to that error analysis"
    },
    {
      "start": 1340.4,
      "duration": 5.04,
      "text": "is really really important like we we"
    },
    {
      "start": 1343.12,
      "duration": 5.12,
      "text": "started like many teams to think of"
    },
    {
      "start": 1345.44,
      "duration": 5.28,
      "text": "metrics like is the agent helpful? Uh"
    },
    {
      "start": 1348.24,
      "duration": 5.52,
      "text": "did the agent satisfy the user request?"
    },
    {
      "start": 1350.72,
      "duration": 5.04,
      "text": "Uh which are like they're okay but"
    },
    {
      "start": 1353.76,
      "duration": 4.08,
      "text": "they're very generic. you need to write"
    },
    {
      "start": 1355.76,
      "duration": 3.44,
      "text": "them in a way that is very specific for"
    },
    {
      "start": 1357.84,
      "duration": 3.199,
      "text": "your product."
    },
    {
      "start": 1359.2,
      "duration": 5.04,
      "text": ">> And when you don't have a product yet,"
    },
    {
      "start": 1361.039,
      "duration": 6.161,
      "text": "this is really really hard to define."
    },
    {
      "start": 1364.24,
      "duration": 5.28,
      "text": ">> So we were lucky enough to have a"
    },
    {
      "start": 1367.2,
      "duration": 4.24,
      "text": "community of uh I food employees. There"
    },
    {
      "start": 1369.52,
      "duration": 3.68,
      "text": "are more than 7,000 people employed at"
    },
    {
      "start": 1371.44,
      "duration": 4.479,
      "text": "food. So they used our app and they gave"
    },
    {
      "start": 1373.2,
      "duration": 4.8,
      "text": "us feedback. Um"
    },
    {
      "start": 1375.919,
      "duration": 4.401,
      "text": "uh there's nothing that can substitute"
    },
    {
      "start": 1378,
      "duration": 5.36,
      "text": "looking at the data. So we had to go and"
    },
    {
      "start": 1380.32,
      "duration": 5.599,
      "text": "look at the the traces identify the the"
    },
    {
      "start": 1383.36,
      "duration": 5.6,
      "text": "errors that we were seeing and once you"
    },
    {
      "start": 1385.919,
      "duration": 6,
      "text": "have the you have a good overview of"
    },
    {
      "start": 1388.96,
      "duration": 5.28,
      "text": "what can go wrong in in your application"
    },
    {
      "start": 1391.919,
      "duration": 4.88,
      "text": "uh that's when you can build a taxonomy"
    },
    {
      "start": 1394.24,
      "duration": 5.6,
      "text": "of errors. So with this error taxonomy"
    },
    {
      "start": 1396.799,
      "duration": 6.161,
      "text": "uh you you can uh build a test set uh"
    },
    {
      "start": 1399.84,
      "duration": 5.12,
      "text": "and it can it can inform you of you know"
    },
    {
      "start": 1402.96,
      "duration": 4.88,
      "text": "things like like how how good you're"
    },
    {
      "start": 1404.96,
      "duration": 6,
      "text": "doing uh with your evaluation and if the"
    },
    {
      "start": 1407.84,
      "duration": 5.76,
      "text": "agent is performing better or not. And"
    },
    {
      "start": 1410.96,
      "duration": 5.76,
      "text": "this is connected to LLM as judge. When"
    },
    {
      "start": 1413.6,
      "duration": 6.16,
      "text": "you write an LLM as judge having this uh"
    },
    {
      "start": 1416.72,
      "duration": 6.4,
      "text": "very specific u domain knowledge helps a"
    },
    {
      "start": 1419.76,
      "duration": 4.96,
      "text": "lot. So we couldn't separate it from"
    },
    {
      "start": 1423.12,
      "duration": 3.2,
      "text": "error analysis. It's something we"
    },
    {
      "start": 1424.72,
      "duration": 2.8,
      "text": "learned later. If I would start a new"
    },
    {
      "start": 1426.32,
      "duration": 2.239,
      "text": "project, I would start from that"
    },
    {
      "start": 1427.52,
      "duration": 3.2,
      "text": "straight away."
    },
    {
      "start": 1428.559,
      "duration": 4,
      "text": ">> And but you're also checking for evals"
    },
    {
      "start": 1430.72,
      "duration": 2.319,
      "text": "on the tools and"
    },
    {
      "start": 1432.559,
      "duration": 2.161,
      "text": ">> yeah,"
    },
    {
      "start": 1433.039,
      "duration": 3.281,
      "text": ">> which tools were called? Was it the"
    },
    {
      "start": 1434.72,
      "duration": 3.36,
      "text": "right tool?"
    },
    {
      "start": 1436.32,
      "duration": 3.599,
      "text": ">> So there's like higher level objectives."
    },
    {
      "start": 1438.08,
      "duration": 3.92,
      "text": "Did it satisfy the user? But then"
    },
    {
      "start": 1439.919,
      "duration": 2.401,
      "text": "there's those very nuanced pieces,"
    },
    {
      "start": 1442,
      "duration": 2,
      "text": "right?"
    },
    {
      "start": 1442.32,
      "duration": 3.68,
      "text": ">> Yeah. We we have of course for the"
    },
    {
      "start": 1444,
      "duration": 4.559,
      "text": "tools. Some of our tools are smart"
    },
    {
      "start": 1446,
      "duration": 5.279,
      "text": "tools. Um you could call them agents"
    },
    {
      "start": 1448.559,
      "duration": 4.24,
      "text": "themselves like searching in our food"
    },
    {
      "start": 1451.279,
      "duration": 4.64,
      "text": "catalog. you need to take into account"
    },
    {
      "start": 1452.799,
      "duration": 5.12,
      "text": "user preferences, sort the items, pick"
    },
    {
      "start": 1455.919,
      "duration": 4.88,
      "text": "the ones that have most variety and like"
    },
    {
      "start": 1457.919,
      "duration": 5.841,
      "text": "match with the user intent and profile."
    },
    {
      "start": 1460.799,
      "duration": 4.48,
      "text": "So that's uh that's just a tool but it"
    },
    {
      "start": 1463.76,
      "duration": 2.159,
      "text": "deserves a whole set of evaluation"
    },
    {
      "start": 1465.279,
      "duration": 3.201,
      "text": "itself."
    },
    {
      "start": 1465.919,
      "duration": 4.88,
      "text": ">> Is that and just is that how you were"
    },
    {
      "start": 1468.48,
      "duration": 4.079,
      "text": "able to see which tools were used"
    },
    {
      "start": 1470.799,
      "duration": 2.48,
      "text": "together and then create workflows from"
    },
    {
      "start": 1472.559,
      "duration": 3.6,
      "text": "the tools?"
    },
    {
      "start": 1473.279,
      "duration": 6.321,
      "text": ">> We analyze the data like we did a lot of"
    },
    {
      "start": 1476.159,
      "duration": 5.841,
      "text": "uh ADOC analysis. uh a team member of us"
    },
    {
      "start": 1479.6,
      "duration": 5.12,
      "text": "is completely completely dedicated to"
    },
    {
      "start": 1482,
      "duration": 5.36,
      "text": "this um like assessing the quality of"
    },
    {
      "start": 1484.72,
      "duration": 5.52,
      "text": "the agent and like understanding what"
    },
    {
      "start": 1487.36,
      "duration": 4.64,
      "text": "goes on uh behind the scenes and also"
    },
    {
      "start": 1490.24,
      "duration": 4.96,
      "text": "what goes on in front of the of the"
    },
    {
      "start": 1492,
      "duration": 5.12,
      "text": "user. Another thing that we did I didn't"
    },
    {
      "start": 1495.2,
      "duration": 5.839,
      "text": "mention yet but I presented it yesterday"
    },
    {
      "start": 1497.12,
      "duration": 6.48,
      "text": "was to create an evil set that was um"
    },
    {
      "start": 1501.039,
      "duration": 5.601,
      "text": "going to pick be picked up by an agent"
    },
    {
      "start": 1503.6,
      "duration": 6,
      "text": "that would impersonate a user. So that"
    },
    {
      "start": 1506.64,
      "duration": 6.399,
      "text": "was something uh that was defined by"
    },
    {
      "start": 1509.6,
      "duration": 6.24,
      "text": "product team. So uh what what we noticed"
    },
    {
      "start": 1513.039,
      "duration": 4.24,
      "text": "was that was very easy to define"
    },
    {
      "start": 1515.84,
      "duration": 2.88,
      "text": "scenarios and what the agent should do"
    },
    {
      "start": 1517.279,
      "duration": 4.081,
      "text": "in those scenarios."
    },
    {
      "start": 1518.72,
      "duration": 5.12,
      "text": ">> What was hard was to create a LLM judge"
    },
    {
      "start": 1521.36,
      "duration": 4.48,
      "text": "that could judge any scenario but given"
    },
    {
      "start": 1523.84,
      "duration": 4.319,
      "text": "a scenario you could say like the agent"
    },
    {
      "start": 1525.84,
      "duration": 5.199,
      "text": "should do this and that. So we started"
    },
    {
      "start": 1528.159,
      "duration": 6.64,
      "text": "with a set of uh of queries defined this"
    },
    {
      "start": 1531.039,
      "duration": 6.401,
      "text": "way and um sometimes you needed some uh"
    },
    {
      "start": 1534.799,
      "duration": 4.161,
      "text": "pre-processing steps to get there like"
    },
    {
      "start": 1537.44,
      "duration": 3.2,
      "text": "for instance when you have an item in"
    },
    {
      "start": 1538.96,
      "duration": 3.199,
      "text": "the cart like when you start you need to"
    },
    {
      "start": 1540.64,
      "duration": 5.279,
      "text": "make sure there is already an item"
    },
    {
      "start": 1542.159,
      "duration": 6.961,
      "text": "things like that um and then we we built"
    },
    {
      "start": 1545.919,
      "duration": 5.441,
      "text": "an interface um between the agent that"
    },
    {
      "start": 1549.12,
      "duration": 4.559,
      "text": "would would test our endpoint and the"
    },
    {
      "start": 1551.36,
      "duration": 4.16,
      "text": "endpoint and this interface made sure"
    },
    {
      "start": 1553.679,
      "duration": 4.24,
      "text": "that when we were returning UI elements"
    },
    {
      "start": 1555.52,
      "duration": 5.6,
      "text": "these were also shown to the user"
    },
    {
      "start": 1557.919,
      "duration": 5.36,
      "text": "impersonating agent. So we like the"
    },
    {
      "start": 1561.12,
      "duration": 4.24,
      "text": "agent could choose to click on certain"
    },
    {
      "start": 1563.279,
      "duration": 4.961,
      "text": "UI elements and at the end we would"
    },
    {
      "start": 1565.36,
      "duration": 6.24,
      "text": "judge the outcome of all of this. So I"
    },
    {
      "start": 1568.24,
      "duration": 7.52,
      "text": "think this allowed us to also test the"
    },
    {
      "start": 1571.6,
      "duration": 6.4,
      "text": "UX in a way. It doesn't substitute uh AB"
    },
    {
      "start": 1575.76,
      "duration": 5.039,
      "text": "testing of course that's uh like online"
    },
    {
      "start": 1578,
      "duration": 6.4,
      "text": "testing is another story but uh it"
    },
    {
      "start": 1580.799,
      "duration": 6.161,
      "text": "helped us to identify regressions"
    },
    {
      "start": 1584.4,
      "duration": 4.8,
      "text": ">> on the tool side. How much work went"
    },
    {
      "start": 1586.96,
      "duration": 4.8,
      "text": "into evaluating the tools themselves to"
    },
    {
      "start": 1589.2,
      "duration": 4.56,
      "text": "make sure that you designed them or at"
    },
    {
      "start": 1591.76,
      "duration": 4.08,
      "text": "least their definitions properly and the"
    },
    {
      "start": 1593.76,
      "duration": 3.919,
      "text": "parameters the parameter definitions"
    },
    {
      "start": 1595.84,
      "duration": 4,
      "text": "properly to see if the model was"
    },
    {
      "start": 1597.679,
      "duration": 3.281,
      "text": "selecting them correctly at the right"
    },
    {
      "start": 1599.84,
      "duration": 4.8,
      "text": "time."
    },
    {
      "start": 1600.96,
      "duration": 6.24,
      "text": ">> Yeah. So we we did evaluate if the agent"
    },
    {
      "start": 1604.64,
      "duration": 6.48,
      "text": "was calling the right tools. Of course"
    },
    {
      "start": 1607.2,
      "duration": 6.959,
      "text": "um depends on the tools. I think uh like"
    },
    {
      "start": 1611.12,
      "duration": 5.679,
      "text": "some tools are so clear to use like uh"
    },
    {
      "start": 1614.159,
      "duration": 4.88,
      "text": "create cart you know some definitions"
    },
    {
      "start": 1616.799,
      "duration": 4.321,
      "text": "are so clear that you don't need to"
    },
    {
      "start": 1619.039,
      "duration": 3.841,
      "text": "spend too much time on that. You just"
    },
    {
      "start": 1621.12,
      "duration": 4.4,
      "text": "want to know that the agent can pick it"
    },
    {
      "start": 1622.88,
      "duration": 5.44,
      "text": "up correctly. But some others are whole"
    },
    {
      "start": 1625.52,
      "duration": 5.039,
      "text": "workflows like searching uh what I was"
    },
    {
      "start": 1628.32,
      "duration": 3.92,
      "text": "talking about before that had a lot of"
    },
    {
      "start": 1630.559,
      "duration": 3.681,
      "text": "evaluation being done and there is still"
    },
    {
      "start": 1632.24,
      "duration": 4.24,
      "text": "a lot going on there"
    },
    {
      "start": 1634.24,
      "duration": 4.08,
      "text": ">> because it's building a recommendation"
    },
    {
      "start": 1636.48,
      "duration": 3.6,
      "text": "system basically right uh"
    },
    {
      "start": 1638.32,
      "duration": 4.08,
      "text": ">> the truth"
    },
    {
      "start": 1640.08,
      "duration": 4.88,
      "text": ">> uh yeah so"
    },
    {
      "start": 1642.4,
      "duration": 4.08,
      "text": ">> like what we have is a user who's"
    },
    {
      "start": 1644.96,
      "duration": 3.04,
      "text": "searching for something or maybe just"
    },
    {
      "start": 1646.48,
      "duration": 4,
      "text": "exploring options they just say I'm"
    },
    {
      "start": 1648,
      "duration": 4.4,
      "text": "hungry surprise me give me promotions"
    },
    {
      "start": 1650.48,
      "duration": 4.64,
      "text": "without any intent"
    },
    {
      "start": 1652.4,
      "duration": 5.92,
      "text": ">> what you're building is is a homepage"
    },
    {
      "start": 1655.12,
      "duration": 5.679,
      "text": "right in the agent. So you want to show"
    },
    {
      "start": 1658.32,
      "duration": 5.04,
      "text": "options that uh are really really good"
    },
    {
      "start": 1660.799,
      "duration": 6.561,
      "text": "for them even when they don't specify"
    },
    {
      "start": 1663.36,
      "duration": 5.76,
      "text": "anything. So that's uh yeah that's a"
    },
    {
      "start": 1667.36,
      "duration": 4.799,
      "text": "recommendation problem."
    },
    {
      "start": 1669.12,
      "duration": 5.12,
      "text": ">> Mhm. Is there ways that you're plugging"
    },
    {
      "start": 1672.159,
      "duration": 3.441,
      "text": "in because I imagine when it comes to"
    },
    {
      "start": 1674.24,
      "duration": 3.52,
      "text": "the workflow, you're plugging in"
    },
    {
      "start": 1675.6,
      "duration": 4.64,
      "text": "structured data and unstructured data in"
    },
    {
      "start": 1677.76,
      "duration": 6.72,
      "text": "this like you're giving the context to"
    },
    {
      "start": 1680.24,
      "duration": 6.64,
      "text": "the agent of the last three, five meals"
    },
    {
      "start": 1684.48,
      "duration": 4.72,
      "text": "that this person ordered, when they"
    },
    {
      "start": 1686.88,
      "duration": 5.039,
      "text": "ordered it, the timing, what they like"
    },
    {
      "start": 1689.2,
      "duration": 5.04,
      "text": "in general, all of these features, quote"
    },
    {
      "start": 1691.919,
      "duration": 6,
      "text": "unquote, that you would normally put in"
    },
    {
      "start": 1694.24,
      "duration": 5.84,
      "text": "a recommendation model, but now you're"
    },
    {
      "start": 1697.919,
      "duration": 4.321,
      "text": "serving it up to the agent in different"
    },
    {
      "start": 1700.08,
      "duration": 6.16,
      "text": "moments of that workflow."
    },
    {
      "start": 1702.24,
      "duration": 5.919,
      "text": ">> Yeah. Yeah. Exactly. Um we have a team"
    },
    {
      "start": 1706.24,
      "duration": 4.4,
      "text": "uh at process AI that is completely"
    },
    {
      "start": 1708.159,
      "duration": 5.681,
      "text": "dedicated to building a model we call"
    },
    {
      "start": 1710.64,
      "duration": 7.2,
      "text": "LCM large commerce model. So it's a"
    },
    {
      "start": 1713.84,
      "duration": 6.24,
      "text": "model that um was fine-tuned based on"
    },
    {
      "start": 1717.84,
      "duration": 5.28,
      "text": "user behavior in our apps in the"
    },
    {
      "start": 1720.08,
      "duration": 5.839,
      "text": "ecosystem. So whether user uh searches"
    },
    {
      "start": 1723.12,
      "duration": 5.6,
      "text": "for something, likes something, orders"
    },
    {
      "start": 1725.919,
      "duration": 4.801,
      "text": "uh so using this model we built"
    },
    {
      "start": 1728.72,
      "duration": 5.12,
      "text": "representations of who the users are. So"
    },
    {
      "start": 1730.72,
      "duration": 6,
      "text": "it goes way beyond the last orders. We"
    },
    {
      "start": 1733.84,
      "duration": 4.8,
      "text": "know what type of customer they are. We"
    },
    {
      "start": 1736.72,
      "duration": 5.439,
      "text": "have some segmentation as well in there"
    },
    {
      "start": 1738.64,
      "duration": 6.72,
      "text": "that uh occurred naturally while um"
    },
    {
      "start": 1742.159,
      "duration": 6.321,
      "text": "while using this model. Um we know their"
    },
    {
      "start": 1745.36,
      "duration": 5.76,
      "text": "their patterns. Uh so that that's like"
    },
    {
      "start": 1748.48,
      "duration": 5.84,
      "text": "the core of who the user is and we have"
    },
    {
      "start": 1751.12,
      "duration": 5.919,
      "text": "similar things for restaurants items. So"
    },
    {
      "start": 1754.32,
      "duration": 6.479,
      "text": "it's um it's much more nuanced than just"
    },
    {
      "start": 1757.039,
      "duration": 6.321,
      "text": "a list of uh like order history."
    },
    {
      "start": 1760.799,
      "duration": 4.961,
      "text": "So we use that in the main agent to to"
    },
    {
      "start": 1763.36,
      "duration": 4.88,
      "text": "select the best uh way to communicate to"
    },
    {
      "start": 1765.76,
      "duration": 5.12,
      "text": "them like select to select the tools in"
    },
    {
      "start": 1768.24,
      "duration": 4.559,
      "text": "the best way. But within the tools also"
    },
    {
      "start": 1770.88,
      "duration": 4.799,
      "text": "we are connecting to white food"
    },
    {
      "start": 1772.799,
      "duration": 5.36,
      "text": "recommendation system. So when we plug"
    },
    {
      "start": 1775.679,
      "duration": 4.321,
      "text": "um dishes, we also have models that were"
    },
    {
      "start": 1778.159,
      "duration": 4.321,
      "text": "trained to"
    },
    {
      "start": 1780,
      "duration": 4.64,
      "text": "um to show the best recommendation. So"
    },
    {
      "start": 1782.48,
      "duration": 3.12,
      "text": "it it's in several places that we're"
    },
    {
      "start": 1784.64,
      "duration": 2.639,
      "text": "doing this."
    },
    {
      "start": 1785.6,
      "duration": 4.799,
      "text": ">> It's almost like there's very complex."
    },
    {
      "start": 1787.279,
      "duration": 5.201,
      "text": ">> Yeah. There's like a Rexus tool in a way"
    },
    {
      "start": 1790.399,
      "duration": 4.16,
      "text": "or like I'm going to use the"
    },
    {
      "start": 1792.48,
      "duration": 3.6,
      "text": "recommendation tool and it's calls a"
    },
    {
      "start": 1794.559,
      "duration": 3.681,
      "text": "machine learning model."
    },
    {
      "start": 1796.08,
      "duration": 4.88,
      "text": ">> Yeah. Yeah. When there are several"
    },
    {
      "start": 1798.24,
      "duration": 4.64,
      "text": "models for different use cases for that."
    },
    {
      "start": 1800.96,
      "duration": 4.079,
      "text": ">> Yeah. Plus, the agent has the brain and"
    },
    {
      "start": 1802.88,
      "duration": 3.679,
      "text": "we have LLM friendly representation of"
    },
    {
      "start": 1805.039,
      "duration": 4.561,
      "text": "the user."
    },
    {
      "start": 1806.559,
      "duration": 4.72,
      "text": ">> Like for instance, if you order pizza in"
    },
    {
      "start": 1809.6,
      "duration": 4.48,
      "text": "Brazil, you can put a lot of toppings"
    },
    {
      "start": 1811.279,
      "duration": 4.961,
      "text": "and customization. If you always put"
    },
    {
      "start": 1814.08,
      "duration": 4.719,
      "text": "pepperoni on your pizza, I know you're a"
    },
    {
      "start": 1816.24,
      "duration": 4.799,
      "text": "meat lover. This you don't see it from"
    },
    {
      "start": 1818.799,
      "duration": 4.801,
      "text": "the order history, but I can extract"
    },
    {
      "start": 1821.039,
      "duration": 4.561,
      "text": "this nuanced information. So, the next"
    },
    {
      "start": 1823.6,
      "duration": 3.439,
      "text": "time you say, \"I want something healthy,"
    },
    {
      "start": 1825.6,
      "duration": 2.48,
      "text": "I'm going to propose you something with"
    },
    {
      "start": 1827.039,
      "duration": 3.76,
      "text": "meat"
    },
    {
      "start": 1828.08,
      "duration": 5.28,
      "text": ">> because I know you like it, right?\""
    },
    {
      "start": 1830.799,
      "duration": 4.48,
      "text": "So the yeah there is a lot of emergent"
    },
    {
      "start": 1833.36,
      "duration": 3.679,
      "text": "patterns that uh"
    },
    {
      "start": 1835.279,
      "duration": 3.28,
      "text": ">> you just can't get with traditional"
    },
    {
      "start": 1837.039,
      "duration": 4.801,
      "text": "machine learning models because they're"
    },
    {
      "start": 1838.559,
      "duration": 5.761,
      "text": "so specific and so here you can infer it"
    },
    {
      "start": 1841.84,
      "duration": 3.52,
      "text": "because of the LLM being that"
    },
    {
      "start": 1844.32,
      "duration": 2.56,
      "text": "intelligence."
    },
    {
      "start": 1845.36,
      "duration": 3.679,
      "text": ">> Yeah, exactly."
    },
    {
      "start": 1846.88,
      "duration": 3.919,
      "text": ">> That's the the beauty of exploring this"
    },
    {
      "start": 1849.039,
      "duration": 4.161,
      "text": "field. Uh"
    },
    {
      "start": 1850.799,
      "duration": 5.281,
      "text": ">> and we learn this as we go. There is so"
    },
    {
      "start": 1853.2,
      "duration": 5.04,
      "text": "much uh yeah so many learnings on this"
    },
    {
      "start": 1856.08,
      "duration": 4.64,
      "text": "and we also get feedback from the user"
    },
    {
      "start": 1858.24,
      "duration": 4.48,
      "text": "which is uh amazing to see."
    },
    {
      "start": 1860.72,
      "duration": 3.6,
      "text": ">> I feel like I feel like I I'm now like"
    },
    {
      "start": 1862.72,
      "duration": 2.72,
      "text": "excited for this app. When are you guys"
    },
    {
      "start": 1864.32,
      "duration": 2.079,
      "text": "when you when are you guys going to be"
    },
    {
      "start": 1865.44,
      "duration": 1.44,
      "text": "in San Francisco?"
    },
    {
      "start": 1866.399,
      "duration": 2.561,
      "text": ">> Yeah."
    },
    {
      "start": 1866.88,
      "duration": 4.72,
      "text": ">> Where are we going? We can go to Brazil."
    },
    {
      "start": 1868.96,
      "duration": 5.12,
      "text": ">> Yeah, that's it. We got to go to Brazil."
    },
    {
      "start": 1871.6,
      "duration": 4.4,
      "text": "That's the easier option than them"
    },
    {
      "start": 1874.08,
      "duration": 4.88,
      "text": "coming to San Fran. Do you have some"
    },
    {
      "start": 1876,
      "duration": 5.52,
      "text": "kind of a checker agent that makes sure"
    },
    {
      "start": 1878.96,
      "duration": 5.68,
      "text": "what's happening is actually what should"
    },
    {
      "start": 1881.52,
      "duration": 5.92,
      "text": "be happening like overseer? I don't know"
    },
    {
      "start": 1884.64,
      "duration": 5.039,
      "text": "what that would how you architect it but"
    },
    {
      "start": 1887.44,
      "duration": 4.8,
      "text": ">> we have a system in place for guard"
    },
    {
      "start": 1889.679,
      "duration": 4.88,
      "text": "rails and making sure"
    },
    {
      "start": 1892.24,
      "duration": 4.48,
      "text": "you know the response that we were given"
    },
    {
      "start": 1894.559,
      "duration": 5.921,
      "text": "as uh"
    },
    {
      "start": 1896.72,
      "duration": 7.12,
      "text": "makes sense let's say um but we didn't"
    },
    {
      "start": 1900.48,
      "duration": 5.36,
      "text": "uh choose a full-blown multi- aent setup"
    },
    {
      "start": 1903.84,
      "duration": 3.92,
      "text": "uh because we wanted to keep it simple"
    },
    {
      "start": 1905.84,
      "duration": 4.559,
      "text": "our use case is relatively simple I"
    },
    {
      "start": 1907.76,
      "duration": 5.12,
      "text": "think what's uh what's difficult is"
    },
    {
      "start": 1910.399,
      "duration": 6.241,
      "text": "given the right recommendations"
    },
    {
      "start": 1912.88,
      "duration": 6.96,
      "text": "um having the context, but you know that"
    },
    {
      "start": 1916.64,
      "duration": 5.6,
      "text": "the the context of the agent is pretty"
    },
    {
      "start": 1919.84,
      "duration": 4.4,
      "text": "self-contained. We don't have an agent"
    },
    {
      "start": 1922.24,
      "duration": 3.919,
      "text": "to schedule a trip for instance. That"
    },
    {
      "start": 1924.24,
      "duration": 5.76,
      "text": "would be another agent. But the set of"
    },
    {
      "start": 1926.159,
      "duration": 5.76,
      "text": "tools that our agent has um are, you"
    },
    {
      "start": 1930,
      "duration": 4.159,
      "text": "know, compatible with each other. We we"
    },
    {
      "start": 1931.919,
      "duration": 4.721,
      "text": "don't need another agent for that. What"
    },
    {
      "start": 1934.159,
      "duration": 4.161,
      "text": "we did, however, was to have a dynamic"
    },
    {
      "start": 1936.64,
      "duration": 4.399,
      "text": "system prompt that would change based on"
    },
    {
      "start": 1938.32,
      "duration": 5.44,
      "text": "the state so that we would not need to"
    },
    {
      "start": 1941.039,
      "duration": 4.321,
      "text": "to have so much information every time."
    },
    {
      "start": 1943.76,
      "duration": 5.68,
      "text": "And yeah, that of course helped with"
    },
    {
      "start": 1945.36,
      "duration": 6.319,
      "text": "latency and having less choices to make"
    },
    {
      "start": 1949.44,
      "duration": 4.88,
      "text": ">> to go back to the stratification we were"
    },
    {
      "start": 1951.679,
      "duration": 4.961,
      "text": "talking about earlier. The way that"
    },
    {
      "start": 1954.32,
      "duration": 5.599,
      "text": "someone interacts with i food on"
    },
    {
      "start": 1956.64,
      "duration": 6.24,
      "text": "WhatsApp is still almost like through"
    },
    {
      "start": 1959.919,
      "duration": 4.48,
      "text": "the i food app but that's just to verify"
    },
    {
      "start": 1962.88,
      "duration": 2.32,
      "text": "their profile and then they go back to"
    },
    {
      "start": 1964.399,
      "duration": 2.16,
      "text": "WhatsApp."
    },
    {
      "start": 1965.2,
      "duration": 3.839,
      "text": ">> Did I understand it correctly?"
    },
    {
      "start": 1966.559,
      "duration": 4.561,
      "text": ">> This is just uh to kick off the first"
    },
    {
      "start": 1969.039,
      "duration": 4.561,
      "text": "authorization flow. So we need to make"
    },
    {
      "start": 1971.12,
      "duration": 6.48,
      "text": "sure that you or you you know connect to"
    },
    {
      "start": 1973.6,
      "duration": 5.439,
      "text": "your profile. Um, so yeah, they they if"
    },
    {
      "start": 1977.6,
      "duration": 3.439,
      "text": "they don't have an account, if they"
    },
    {
      "start": 1979.039,
      "duration": 3.441,
      "text": "write to us from a phone number, they"
    },
    {
      "start": 1981.039,
      "duration": 4.401,
      "text": "don't have an iPhone account, we need to"
    },
    {
      "start": 1982.48,
      "duration": 4.64,
      "text": "make sure that they create one like uh"
    },
    {
      "start": 1985.44,
      "duration": 3.52,
      "text": ">> and then you have all of the information"
    },
    {
      "start": 1987.12,
      "duration": 3.279,
      "text": "about that user in i food."
    },
    {
      "start": 1988.96,
      "duration": 3.199,
      "text": ">> Yeah. And we connect. Yeah."
    },
    {
      "start": 1990.399,
      "duration": 4.16,
      "text": ">> Including the payment options and all of"
    },
    {
      "start": 1992.159,
      "duration": 4.961,
      "text": "that stuff. And so the"
    },
    {
      "start": 1994.559,
      "duration": 4.24,
      "text": "agent, I'm assuming, just says, do you"
    },
    {
      "start": 1997.12,
      "duration": 4.799,
      "text": "want to use your regular credit card or"
    },
    {
      "start": 1998.799,
      "duration": 5.521,
      "text": "do you want to use one of these options?"
    },
    {
      "start": 2001.919,
      "duration": 5.201,
      "text": "There are some systems in Brazil uh for"
    },
    {
      "start": 2004.32,
      "duration": 3.92,
      "text": "payments that uh we are connecting with."
    },
    {
      "start": 2007.12,
      "duration": 3.279,
      "text": "Yeah. But"
    },
    {
      "start": 2008.24,
      "duration": 6.48,
      "text": ">> I remember Nishi talking to me about how"
    },
    {
      "start": 2010.399,
      "duration": 6.241,
      "text": "hard it was to context engineer the"
    },
    {
      "start": 2014.72,
      "duration": 3.12,
      "text": "types of payment systems that people"
    },
    {
      "start": 2016.64,
      "duration": 4.159,
      "text": "would ask for."
    },
    {
      "start": 2017.84,
      "duration": 5.6,
      "text": ">> Mhm. And it goes back to what you were"
    },
    {
      "start": 2020.799,
      "duration": 4.88,
      "text": "talking about at the beginning of you"
    },
    {
      "start": 2023.44,
      "duration": 4.959,
      "text": "end up just adding all these edge cases"
    },
    {
      "start": 2025.679,
      "duration": 5.921,
      "text": "to the prompt and before you know it"
    },
    {
      "start": 2028.399,
      "duration": 6.241,
      "text": "your prompt is so bloated and if last"
    },
    {
      "start": 2031.6,
      "duration": 6.4,
      "text": "night 6 hours stream taught me anything"
    },
    {
      "start": 2034.64,
      "duration": 5.84,
      "text": "it is like the least amount of context"
    },
    {
      "start": 2038,
      "duration": 5.279,
      "text": "as necessary. If you think about uh what"
    },
    {
      "start": 2040.48,
      "duration": 5.199,
      "text": "a user can ask in an app to order food,"
    },
    {
      "start": 2043.279,
      "duration": 6.32,
      "text": "uh they could ask for specific payment"
    },
    {
      "start": 2045.679,
      "duration": 6.881,
      "text": "method, price range, delivery time, uh"
    },
    {
      "start": 2049.599,
      "duration": 4.56,
      "text": "like distance from the restaurant or"
    },
    {
      "start": 2052.56,
      "duration": 4.16,
      "text": "they're vegetarian, they want"
    },
    {
      "start": 2054.159,
      "duration": 5.52,
      "text": "gluten-free discounts, they have a"
    },
    {
      "start": 2056.72,
      "duration": 4.399,
      "text": "specific membership uh that they want to"
    },
    {
      "start": 2059.679,
      "duration": 3.601,
      "text": "like that allows them specific"
    },
    {
      "start": 2061.119,
      "duration": 4.48,
      "text": "discounts, they want to use that. Like"
    },
    {
      "start": 2063.28,
      "duration": 4.399,
      "text": "there is so much it's really impossible"
    },
    {
      "start": 2065.599,
      "duration": 4.721,
      "text": "to give all this information to the"
    },
    {
      "start": 2067.679,
      "duration": 4.16,
      "text": "agent because then you need to like the"
    },
    {
      "start": 2070.32,
      "duration": 3.759,
      "text": "agent needs to convert that in the qu"
    },
    {
      "start": 2071.839,
      "duration": 3.921,
      "text": "into a query, right? If you give all"
    },
    {
      "start": 2074.079,
      "duration": 4.401,
      "text": "this information to the main agent, it's"
    },
    {
      "start": 2075.76,
      "duration": 7.04,
      "text": "going to blow up the the prompt. So what"
    },
    {
      "start": 2078.48,
      "duration": 6.24,
      "text": "we did was um like having a converting"
    },
    {
      "start": 2082.8,
      "duration": 4.319,
      "text": "the query into something more LLM"
    },
    {
      "start": 2084.72,
      "duration": 4.399,
      "text": "friendly um with some basic knowledge"
    },
    {
      "start": 2087.119,
      "duration": 4.641,
      "text": "from the main agent and then giving"
    },
    {
      "start": 2089.119,
      "duration": 5.841,
      "text": "context of like who the user what the"
    },
    {
      "start": 2091.76,
      "duration": 6.079,
      "text": "user wants and in a way this is like"
    },
    {
      "start": 2094.96,
      "duration": 4.56,
      "text": "preparing a task for another agent. So"
    },
    {
      "start": 2097.839,
      "duration": 3.921,
      "text": "we we delegate and the main agent"
    },
    {
      "start": 2099.52,
      "duration": 5.2,
      "text": "doesn't need to worry about anything."
    },
    {
      "start": 2101.76,
      "duration": 5.68,
      "text": ">> And that first touch is just through"
    },
    {
      "start": 2104.72,
      "duration": 5.76,
      "text": "like a small language model or sentiment"
    },
    {
      "start": 2107.44,
      "duration": 5.2,
      "text": "analysis or it still is an LLM call."
    },
    {
      "start": 2110.48,
      "duration": 6.4,
      "text": ">> No, we we use an LLM straight away for"
    },
    {
      "start": 2112.64,
      "duration": 6.64,
      "text": "that. Yeah, it's it's simpler. Um but we"
    },
    {
      "start": 2116.88,
      "duration": 4.959,
      "text": "implemented some classification later in"
    },
    {
      "start": 2119.28,
      "duration": 4.96,
      "text": "the way. So yeah, we we have some"
    },
    {
      "start": 2121.839,
      "duration": 3.76,
      "text": "classifier steps to simplify."
    },
    {
      "start": 2124.24,
      "duration": 3.599,
      "text": ">> Nice."
    },
    {
      "start": 2125.599,
      "duration": 4.48,
      "text": "How much are you using"
    },
    {
      "start": 2127.839,
      "duration": 6.881,
      "text": "the foundation foundational models like"
    },
    {
      "start": 2130.079,
      "duration": 7.76,
      "text": "OpenAI or Claude versus your own?"
    },
    {
      "start": 2134.72,
      "duration": 6.32,
      "text": ">> I would say we use foundational"
    },
    {
      "start": 2137.839,
      "duration": 5.201,
      "text": "uh almost everywhere. Um we use smaller"
    },
    {
      "start": 2141.04,
      "duration": 5.6,
      "text": "models, fine-tuned models for specific"
    },
    {
      "start": 2143.04,
      "duration": 5.2,
      "text": "steps in the workflow like creating uh"
    },
    {
      "start": 2146.64,
      "duration": 3.52,
      "text": "representations for the users for"
    },
    {
      "start": 2148.24,
      "duration": 5.2,
      "text": "instance uh it's a task where there is a"
    },
    {
      "start": 2150.16,
      "duration": 5.76,
      "text": "fine-tuned model. Um but for the"
    },
    {
      "start": 2153.44,
      "duration": 4.24,
      "text": "conversational part we haven't explored"
    },
    {
      "start": 2155.92,
      "duration": 4.64,
      "text": "yet."
    },
    {
      "start": 2157.68,
      "duration": 5.12,
      "text": ">> I think foundational model models are so"
    },
    {
      "start": 2160.56,
      "duration": 5.68,
      "text": "good right now that uh if you don't need"
    },
    {
      "start": 2162.8,
      "duration": 5.36,
      "text": "to fine-tune that's probably you"
    },
    {
      "start": 2166.24,
      "duration": 4.48,
      "text": "shouldn't do it. It's"
    },
    {
      "start": 2168.16,
      "duration": 4.4,
      "text": ">> I think I hear a lot about fine-tuning"
    },
    {
      "start": 2170.72,
      "duration": 3.52,
      "text": "like maybe we should fine-tune that to"
    },
    {
      "start": 2172.56,
      "duration": 3.2,
      "text": "fix the output. No, it's it's a"
    },
    {
      "start": 2174.24,
      "duration": 4.96,
      "text": "specification problem. you're not"
    },
    {
      "start": 2175.76,
      "duration": 5.839,
      "text": "specifying enough uh or you maybe you're"
    },
    {
      "start": 2179.2,
      "duration": 4.24,
      "text": "specifying too much in the prompt if"
    },
    {
      "start": 2181.599,
      "duration": 3.361,
      "text": "something can be fixed there"
    },
    {
      "start": 2183.44,
      "duration": 2.72,
      "text": ">> as the first step."
    },
    {
      "start": 2184.96,
      "duration": 2.48,
      "text": ">> Well, I I think it's a great I think"
    },
    {
      "start": 2186.16,
      "duration": 3.04,
      "text": "it's a that's a great point I'd love to"
    },
    {
      "start": 2187.44,
      "duration": 4.8,
      "text": "dig into because you know you know so"
    },
    {
      "start": 2189.2,
      "duration": 6.32,
      "text": "much more about this than most people."
    },
    {
      "start": 2192.24,
      "duration": 5.68,
      "text": "Where do you draw the line on"
    },
    {
      "start": 2195.52,
      "duration": 5.52,
      "text": "when and where to finetune me? You guys"
    },
    {
      "start": 2197.92,
      "duration": 7.52,
      "text": "have an incredible amount of data"
    },
    {
      "start": 2201.04,
      "duration": 7.28,
      "text": "and I know that much of it is leveraged"
    },
    {
      "start": 2205.44,
      "duration": 6.159,
      "text": "where do you decide to do that work?"
    },
    {
      "start": 2208.32,
      "duration": 5.12,
      "text": ">> So, I think one of the the biggest"
    },
    {
      "start": 2211.599,
      "duration": 5.921,
      "text": "reasons why you might want to fine-tune"
    },
    {
      "start": 2213.44,
      "duration": 5.6,
      "text": "is cost and and latency as well. So, if"
    },
    {
      "start": 2217.52,
      "duration": 3.599,
      "text": "you're building a model for a very"
    },
    {
      "start": 2219.04,
      "duration": 5.76,
      "text": "specific task and the model doesn't need"
    },
    {
      "start": 2221.119,
      "duration": 7.201,
      "text": "to be able to converse with the user, uh"
    },
    {
      "start": 2224.8,
      "duration": 5.2,
      "text": "they just need to take user data and"
    },
    {
      "start": 2228.32,
      "duration": 3.44,
      "text": "build a representation of the user for"
    },
    {
      "start": 2230,
      "duration": 3.599,
      "text": "instance. That's a very specific task."
    },
    {
      "start": 2231.76,
      "duration": 3.359,
      "text": "and then you you want to scale it to 60"
    },
    {
      "start": 2233.599,
      "duration": 2.961,
      "text": "million users and you want to do it"
    },
    {
      "start": 2235.119,
      "duration": 4.72,
      "text": "every day."
    },
    {
      "start": 2236.56,
      "duration": 5.279,
      "text": ">> Foundational model is not going to going"
    },
    {
      "start": 2239.839,
      "duration": 4.081,
      "text": "to work very well."
    },
    {
      "start": 2241.839,
      "duration": 5.52,
      "text": ">> It's going to be extremely expensive."
    },
    {
      "start": 2243.92,
      "duration": 6.88,
      "text": "Yeah. So, and also performance-wise,"
    },
    {
      "start": 2247.359,
      "duration": 6.561,
      "text": "right? Uh because at the end we're"
    },
    {
      "start": 2250.8,
      "duration": 5.279,
      "text": "talking about embeddings and you want if"
    },
    {
      "start": 2253.92,
      "duration": 5.6,
      "text": "you if you're working on a very specific"
    },
    {
      "start": 2256.079,
      "duration": 5.201,
      "text": "uh space like uh food delivery, you want"
    },
    {
      "start": 2259.52,
      "duration": 4.24,
      "text": "to you want the model to clearly"
    },
    {
      "start": 2261.28,
      "duration": 4.24,
      "text": "differentiate terms that might look the"
    },
    {
      "start": 2263.76,
      "duration": 2.48,
      "text": "same but are actually sematically"
    },
    {
      "start": 2265.52,
      "duration": 1.36,
      "text": "different."
    },
    {
      "start": 2266.24,
      "duration": 2.56,
      "text": ">> Mhm."
    },
    {
      "start": 2266.88,
      "duration": 6.32,
      "text": ">> And that nuance you don't get in"
    },
    {
      "start": 2268.8,
      "duration": 6.88,
      "text": "foundation model. Um, so you at the end"
    },
    {
      "start": 2273.2,
      "duration": 5.12,
      "text": "when you're fine-tuning, you're changing"
    },
    {
      "start": 2275.68,
      "duration": 6.159,
      "text": "the space where your model moves and"
    },
    {
      "start": 2278.32,
      "duration": 5.36,
      "text": "you're making this um the meaning of"
    },
    {
      "start": 2281.839,
      "duration": 3.76,
      "text": "words that might look similar, more far"
    },
    {
      "start": 2283.68,
      "duration": 4.72,
      "text": "apart from each other."
    },
    {
      "start": 2285.599,
      "duration": 5.76,
      "text": ">> So that that that thing you want to do"
    },
    {
      "start": 2288.4,
      "duration": 5.439,
      "text": "um and we proved that for our"
    },
    {
      "start": 2291.359,
      "duration": 5.601,
      "text": "application it's better actually. Uh we"
    },
    {
      "start": 2293.839,
      "duration": 5.28,
      "text": "AB tested this and um yeah, it gave"
    },
    {
      "start": 2296.96,
      "duration": 4.96,
      "text": "better results."
    },
    {
      "start": 2299.119,
      "duration": 5.361,
      "text": "If you want to just kickstart a project"
    },
    {
      "start": 2301.92,
      "duration": 4.32,
      "text": "then yeah first you know make it work"
    },
    {
      "start": 2304.48,
      "duration": 2.56,
      "text": "then make it cheap then make it fast"
    },
    {
      "start": 2306.24,
      "duration": 2.24,
      "text": "etc."
    },
    {
      "start": 2307.04,
      "duration": 6.799,
      "text": ">> Yeah it's interesting we see this as"
    },
    {
      "start": 2308.48,
      "duration": 9.119,
      "text": "well with a lot of customers um is again"
    },
    {
      "start": 2313.839,
      "duration": 5.52,
      "text": "today versus last year"
    },
    {
      "start": 2317.599,
      "duration": 3.601,
      "text": ">> people used to start with all of their"
    },
    {
      "start": 2319.359,
      "duration": 3.681,
      "text": "own data and with fine-tuning and that's"
    },
    {
      "start": 2321.2,
      "duration": 3.6,
      "text": "that was the beginning of the journey"
    },
    {
      "start": 2323.04,
      "duration": 3.2,
      "text": "and now today it's the end of the"
    },
    {
      "start": 2324.8,
      "duration": 3.76,
      "text": "journey you instead you throw a"
    },
    {
      "start": 2326.24,
      "duration": 4.24,
      "text": "financial model at it. Most of the time"
    },
    {
      "start": 2328.56,
      "duration": 3.36,
      "text": "it's good enough. You do some prompt"
    },
    {
      "start": 2330.48,
      "duration": 3.04,
      "text": "engineering, you attach some tools, and"
    },
    {
      "start": 2331.92,
      "duration": 4.08,
      "text": "you're good to go. But when you want"
    },
    {
      "start": 2333.52,
      "duration": 4.96,
      "text": "that extra last inch, now that's where"
    },
    {
      "start": 2336,
      "duration": 5.839,
      "text": "everybody's using fine-tuning. I'm"
    },
    {
      "start": 2338.48,
      "duration": 4.96,
      "text": "curious within the work that you've been"
    },
    {
      "start": 2341.839,
      "duration": 4.961,
      "text": "doing,"
    },
    {
      "start": 2343.44,
      "duration": 6.08,
      "text": "where's the dividing line of fine-tuning"
    },
    {
      "start": 2346.8,
      "duration": 4.4,
      "text": "an existing large language model,"
    },
    {
      "start": 2349.52,
      "duration": 3.04,
      "text": "whether it's a foundational model, open"
    },
    {
      "start": 2351.2,
      "duration": 4.159,
      "text": "source one,"
    },
    {
      "start": 2352.56,
      "duration": 5.44,
      "text": ">> versus building your own model that"
    },
    {
      "start": 2355.359,
      "duration": 6.801,
      "text": "might not be LLM based. Yeah, it's very"
    },
    {
      "start": 2358,
      "duration": 5.92,
      "text": "fine line sometimes. Um I think regular"
    },
    {
      "start": 2362.16,
      "duration": 4.08,
      "text": "like more traditional machine learning"
    },
    {
      "start": 2363.92,
      "duration": 3.84,
      "text": "approaches uh are good to get patterns"
    },
    {
      "start": 2366.24,
      "duration": 5.76,
      "text": "from the data like when the data is"
    },
    {
      "start": 2367.76,
      "duration": 6.72,
      "text": "numeric or uh when you have graph type"
    },
    {
      "start": 2372,
      "duration": 5.359,
      "text": "of data like collaborative filtering for"
    },
    {
      "start": 2374.48,
      "duration": 6.08,
      "text": "instance. So we're also working on that."
    },
    {
      "start": 2377.359,
      "duration": 6.161,
      "text": "Um I think traditional ML can find"
    },
    {
      "start": 2380.56,
      "duration": 5.84,
      "text": "patterns that um"
    },
    {
      "start": 2383.52,
      "duration": 5.52,
      "text": "an um an LLM like conversational type of"
    },
    {
      "start": 2386.4,
      "duration": 4.719,
      "text": "LLM would not necessarily find because"
    },
    {
      "start": 2389.04,
      "duration": 5.6,
      "text": "it can leverage also connections between"
    },
    {
      "start": 2391.119,
      "duration": 5.921,
      "text": "user data points um you're embedding"
    },
    {
      "start": 2394.64,
      "duration": 3.84,
      "text": "different type of information. So for"
    },
    {
      "start": 2397.04,
      "duration": 6,
      "text": "instance to give you an example with"
    },
    {
      "start": 2398.48,
      "duration": 6.72,
      "text": "collaborative filtering um the the model"
    },
    {
      "start": 2403.04,
      "duration": 4.96,
      "text": "um might know that we are similar users"
    },
    {
      "start": 2405.2,
      "duration": 4.48,
      "text": "and I order some food that you haven't"
    },
    {
      "start": 2408,
      "duration": 2.32,
      "text": "ordered yet and it will suggest you this"
    },
    {
      "start": 2409.68,
      "duration": 2.32,
      "text": "food."
    },
    {
      "start": 2410.32,
      "duration": 4.64,
      "text": ">> I don't necessarily have this connection"
    },
    {
      "start": 2412,
      "duration": 3.52,
      "text": "in an LLM um that is conversational."
    },
    {
      "start": 2414.96,
      "duration": 2.08,
      "text": "Mhm."
    },
    {
      "start": 2415.52,
      "duration": 4.64,
      "text": ">> Um"
    },
    {
      "start": 2417.04,
      "duration": 4.96,
      "text": "so yeah that's um there is a very fine"
    },
    {
      "start": 2420.16,
      "duration": 7.28,
      "text": "line. What what we're trying to do is"
    },
    {
      "start": 2422,
      "duration": 7.92,
      "text": "use LLM um for finding patterns based on"
    },
    {
      "start": 2427.44,
      "duration": 5.919,
      "text": "uh the user behavior things that are not"
    },
    {
      "start": 2429.92,
      "duration": 5.12,
      "text": "just hard data like the the example I"
    },
    {
      "start": 2433.359,
      "duration": 4,
      "text": "mentioned before where you order pizza"
    },
    {
      "start": 2435.04,
      "duration": 3.84,
      "text": "with pepperoni might be a meat lover. I"
    },
    {
      "start": 2437.359,
      "duration": 4.081,
      "text": "know you're not but"
    },
    {
      "start": 2438.88,
      "duration": 3.199,
      "text": ">> I'm the opposite but I understand for"
    },
    {
      "start": 2441.44,
      "duration": 2.8,
      "text": "sake of argument"
    },
    {
      "start": 2442.079,
      "duration": 4.641,
      "text": ">> you know just to to give you an idea."
    },
    {
      "start": 2444.24,
      "duration": 5.52,
      "text": "and then I can extract a filter that I"
    },
    {
      "start": 2446.72,
      "duration": 7.04,
      "text": "will use in every query uh uh to to"
    },
    {
      "start": 2449.76,
      "duration": 5.44,
      "text": "filter the data that I show you. Um"
    },
    {
      "start": 2453.76,
      "duration": 4.559,
      "text": "yeah, with traditional machine learning"
    },
    {
      "start": 2455.2,
      "duration": 5.84,
      "text": "I wouldn't get this patterns out. Yeah,"
    },
    {
      "start": 2458.319,
      "duration": 4.641,
      "text": "it's it's a hard question. Uh I think"
    },
    {
      "start": 2461.04,
      "duration": 3.84,
      "text": "because"
    },
    {
      "start": 2462.96,
      "duration": 3.76,
      "text": "it yeah at the end it boils down what"
    },
    {
      "start": 2464.88,
      "duration": 3.68,
      "text": "what type of data you want to show to"
    },
    {
      "start": 2466.72,
      "duration": 4.72,
      "text": "the user."
    },
    {
      "start": 2468.56,
      "duration": 5.759,
      "text": "I think for data to fit to LLMs"
    },
    {
      "start": 2471.44,
      "duration": 5.76,
      "text": "sometimes it makes more sense to get"
    },
    {
      "start": 2474.319,
      "duration": 5.52,
      "text": "like text based representation"
    },
    {
      "start": 2477.2,
      "duration": 5.44,
      "text": "but when you you need to do operations"
    },
    {
      "start": 2479.839,
      "duration": 7.52,
      "text": "like search in a database yeah there you"
    },
    {
      "start": 2482.64,
      "duration": 8.16,
      "text": "need vectors you need to to optimize um"
    },
    {
      "start": 2487.359,
      "duration": 6.321,
      "text": "yeah based on vector representations"
    },
    {
      "start": 2490.8,
      "duration": 4.24,
      "text": "yeah it's a it's a very good question"
    },
    {
      "start": 2493.68,
      "duration": 3.6,
      "text": ">> yeah it's cool to hear that you're still"
    },
    {
      "start": 2495.04,
      "duration": 4,
      "text": "grappling with it and there are these"
    },
    {
      "start": 2497.28,
      "duration": 4.4,
      "text": "pros pros and cons of each and obviously"
    },
    {
      "start": 2499.04,
      "duration": 7.36,
      "text": "it's always a trade-off. I like the idea"
    },
    {
      "start": 2501.68,
      "duration": 7.12,
      "text": "of how you can leverage one and at the"
    },
    {
      "start": 2506.4,
      "duration": 5.12,
      "text": "same time kind of plug in the machine"
    },
    {
      "start": 2508.8,
      "duration": 4.64,
      "text": "learning models. So it's like the"
    },
    {
      "start": 2511.52,
      "duration": 3.92,
      "text": "majority of the stuff is happening with"
    },
    {
      "start": 2513.44,
      "duration": 3.36,
      "text": "the large language models and the agents"
    },
    {
      "start": 2515.44,
      "duration": 3.679,
      "text": "that are going and they're doing stuff"
    },
    {
      "start": 2516.8,
      "duration": 4.16,
      "text": "and maybe one node or one tool that it"
    },
    {
      "start": 2519.119,
      "duration": 3.841,
      "text": "can call is a machine learning model. I"
    },
    {
      "start": 2520.96,
      "duration": 4.96,
      "text": "think one of the things that I find most"
    },
    {
      "start": 2522.96,
      "duration": 5.2,
      "text": "most interesting about process is how"
    },
    {
      "start": 2525.92,
      "duration": 5.76,
      "text": "far how far out ahead and how advanced"
    },
    {
      "start": 2528.16,
      "duration": 5.6,
      "text": "you folks are in agent building. You got"
    },
    {
      "start": 2531.68,
      "duration": 3.12,
      "text": "a target for what 30,000 agents in the"
    },
    {
      "start": 2533.76,
      "duration": 1.44,
      "text": "organization."
    },
    {
      "start": 2534.8,
      "duration": 0.72,
      "text": ">> Yeah."
    },
    {
      "start": 2535.2,
      "duration": 1.84,
      "text": ">> Which"
    },
    {
      "start": 2535.52,
      "duration": 2.96,
      "text": ">> that was in the keynote which is funny"
    },
    {
      "start": 2537.04,
      "duration": 3.039,
      "text": "cuz you know we can laugh about how"
    },
    {
      "start": 2538.48,
      "duration": 3.44,
      "text": "crazy that number is but then how many"
    },
    {
      "start": 2540.079,
      "duration": 4.641,
      "text": "do you actually have right now?"
    },
    {
      "start": 2541.92,
      "duration": 4.32,
      "text": ">> It's it's more than anyone else and so"
    },
    {
      "start": 2544.72,
      "duration": 4,
      "text": ">> it's not that far off. It's"
    },
    {
      "start": 2546.24,
      "duration": 3.599,
      "text": ">> Yeah. Like you you have at least over a"
    },
    {
      "start": 2548.72,
      "duration": 2.48,
      "text": "thousand at this point and"
    },
    {
      "start": 2549.839,
      "duration": 2.961,
      "text": ">> Yeah. over 10,000."
    },
    {
      "start": 2551.2,
      "duration": 3.52,
      "text": ">> Yeah. And so, you know, we can joke"
    },
    {
      "start": 2552.8,
      "duration": 4.72,
      "text": "about 30,000, but most people are"
    },
    {
      "start": 2554.72,
      "duration": 4.639,
      "text": "struggling to get one out, right? and"
    },
    {
      "start": 2557.52,
      "duration": 3.52,
      "text": "and we've talked and we've talked a fair"
    },
    {
      "start": 2559.359,
      "duration": 3.441,
      "text": "bit and I'm sure we'll talk more in"
    },
    {
      "start": 2561.04,
      "duration": 3.279,
      "text": "different sessions about how what it"
    },
    {
      "start": 2562.8,
      "duration": 3.68,
      "text": "took to get there both from a technical"
    },
    {
      "start": 2564.319,
      "duration": 4.081,
      "text": "perspective and from an organizational"
    },
    {
      "start": 2566.48,
      "duration": 5.28,
      "text": "perspective but you had made a really"
    },
    {
      "start": 2568.4,
      "duration": 7.36,
      "text": "interesting point about tools"
    },
    {
      "start": 2571.76,
      "duration": 7.28,
      "text": ">> and and how you know different teams"
    },
    {
      "start": 2575.76,
      "duration": 4.96,
      "text": "start in one way but then eventually you"
    },
    {
      "start": 2579.04,
      "duration": 3.039,
      "text": "got to start think you start layering in"
    },
    {
      "start": 2580.72,
      "duration": 3.84,
      "text": "governance. I'm wondering if you could"
    },
    {
      "start": 2582.079,
      "duration": 5.681,
      "text": "share more about that. Yeah, this is uh"
    },
    {
      "start": 2584.56,
      "duration": 5.68,
      "text": "I think um trans transition that happens"
    },
    {
      "start": 2587.76,
      "duration": 6.16,
      "text": "in other organization as well where we"
    },
    {
      "start": 2590.24,
      "duration": 5.92,
      "text": "are approaching genai and we have very"
    },
    {
      "start": 2593.92,
      "duration": 4.72,
      "text": "uh vertical type of vision. We're trying"
    },
    {
      "start": 2596.16,
      "duration": 6.88,
      "text": "to build a product for specific uh use"
    },
    {
      "start": 2598.64,
      "duration": 6.08,
      "text": "case, right? So what uh what you do if"
    },
    {
      "start": 2603.04,
      "duration": 4.16,
      "text": "you're a team building this is you go"
    },
    {
      "start": 2604.72,
      "duration": 5.68,
      "text": "very all in and very deep in this"
    },
    {
      "start": 2607.2,
      "duration": 5.6,
      "text": "vertical direction. But if you do this"
    },
    {
      "start": 2610.4,
      "duration": 5.28,
      "text": "and you multiply it for 10 20 teams in"
    },
    {
      "start": 2612.8,
      "duration": 5.68,
      "text": "an organization, you realize that uh"
    },
    {
      "start": 2615.68,
      "duration": 5.84,
      "text": "often similar tools are being built."
    },
    {
      "start": 2618.48,
      "duration": 5.839,
      "text": ">> For instance, uh answer the user"
    },
    {
      "start": 2621.52,
      "duration": 6.319,
      "text": "questions using knowledge base, right?"
    },
    {
      "start": 2624.319,
      "duration": 6.961,
      "text": "Um so what uh what I think tools are"
    },
    {
      "start": 2627.839,
      "duration": 6.561,
      "text": "really good for is also creating layers"
    },
    {
      "start": 2631.28,
      "duration": 4.64,
      "text": "of governance where for instance in the"
    },
    {
      "start": 2634.4,
      "duration": 3.6,
      "text": "case of the knowledge base there is a"
    },
    {
      "start": 2635.92,
      "duration": 4.72,
      "text": "team that uh makes sure that that works"
    },
    {
      "start": 2638,
      "duration": 6.16,
      "text": "very well and then can be shared across"
    },
    {
      "start": 2640.64,
      "duration": 7.04,
      "text": "different teams. The the trick here is"
    },
    {
      "start": 2644.16,
      "duration": 6.32,
      "text": "that the teams def defining these rules"
    },
    {
      "start": 2647.68,
      "duration": 4.8,
      "text": "needs to be very LLM savy as well"
    },
    {
      "start": 2650.48,
      "duration": 4.24,
      "text": "because the interface that this tool"
    },
    {
      "start": 2652.48,
      "duration": 4.96,
      "text": "would use needs to be used by an agent."
    },
    {
      "start": 2654.72,
      "duration": 5.52,
      "text": "What we see sometimes is that um these"
    },
    {
      "start": 2657.44,
      "duration": 5.04,
      "text": "definitions get too verbose. Uh there is"
    },
    {
      "start": 2660.24,
      "duration": 5.119,
      "text": "a lot of requirements for how the tool"
    },
    {
      "start": 2662.48,
      "duration": 4.4,
      "text": "should be used and um like the language"
    },
    {
      "start": 2665.359,
      "duration": 4.321,
      "text": "that should be used. Sometimes you don't"
    },
    {
      "start": 2666.88,
      "duration": 5.439,
      "text": "need all of that and you really need"
    },
    {
      "start": 2669.68,
      "duration": 4.56,
      "text": "engineers to work together to to define"
    },
    {
      "start": 2672.319,
      "duration": 4.161,
      "text": "the interfaces of this and I think if"
    },
    {
      "start": 2674.24,
      "duration": 4.24,
      "text": "you nail that then you can really scale"
    },
    {
      "start": 2676.48,
      "duration": 4,
      "text": "up because you can then share tools"
    },
    {
      "start": 2678.48,
      "duration": 3.76,
      "text": "across the organization"
    },
    {
      "start": 2680.48,
      "duration": 4.4,
      "text": ">> and this also applies to agents by the"
    },
    {
      "start": 2682.24,
      "duration": 5.04,
      "text": "way in multi- aent setups."
    },
    {
      "start": 2684.88,
      "duration": 4.8,
      "text": ">> It's having that ownership of the tools"
    },
    {
      "start": 2687.28,
      "duration": 5.839,
      "text": "being able to clearly define this is"
    },
    {
      "start": 2689.68,
      "duration": 5.679,
      "text": "your tool. You're expected to keep it up"
    },
    {
      "start": 2693.119,
      "duration": 4.24,
      "text": "to date to make sure that it's working"
    },
    {
      "start": 2695.359,
      "duration": 4.72,
      "text": "and"
    },
    {
      "start": 2697.359,
      "duration": 5.76,
      "text": "that the agent can consume it in a way."
    },
    {
      "start": 2700.079,
      "duration": 6.161,
      "text": ">> Yeah, exactly. And when you create uh"
    },
    {
      "start": 2703.119,
      "duration": 5.601,
      "text": "tools that can um"
    },
    {
      "start": 2706.24,
      "duration": 5.2,
      "text": "that are directly connected to the"
    },
    {
      "start": 2708.72,
      "duration": 4.96,
      "text": "public image of the company like you"
    },
    {
      "start": 2711.44,
      "duration": 5.44,
      "text": "defining persona that represents the"
    },
    {
      "start": 2713.68,
      "duration": 5.2,
      "text": "company then um the type of people who"
    },
    {
      "start": 2716.88,
      "duration": 5.439,
      "text": "write these rules are not developers,"
    },
    {
      "start": 2718.88,
      "duration": 6.32,
      "text": "right? So the the person defining these"
    },
    {
      "start": 2722.319,
      "duration": 5.601,
      "text": "rules uh maybe is a designer or like"
    },
    {
      "start": 2725.2,
      "duration": 5.2,
      "text": "product team but you cannot give them to"
    },
    {
      "start": 2727.92,
      "duration": 4.8,
      "text": "the agent as they are. you need some"
    },
    {
      "start": 2730.4,
      "duration": 5.84,
      "text": "some translation layer in here and I"
    },
    {
      "start": 2732.72,
      "duration": 5.599,
      "text": "think uh yeah governance is really"
    },
    {
      "start": 2736.24,
      "duration": 3.839,
      "text": "it's really important uh and it's"
    },
    {
      "start": 2738.319,
      "duration": 4.721,
      "text": "important to get it right because once"
    },
    {
      "start": 2740.079,
      "duration": 6.561,
      "text": "you do it once then you know it's it's"
    },
    {
      "start": 2743.04,
      "duration": 6.559,
      "text": "more maintainable and if I would uh let"
    },
    {
      "start": 2746.64,
      "duration": 5.04,
      "text": "be used by other agents for instance uh"
    },
    {
      "start": 2749.599,
      "duration": 4.961,
      "text": "like expose it through agent to agent"
    },
    {
      "start": 2751.68,
      "duration": 5.679,
      "text": "framework or uh let other teams use it"
    },
    {
      "start": 2754.56,
      "duration": 4.32,
      "text": "then I also need to make sure that that"
    },
    {
      "start": 2757.359,
      "duration": 3.361,
      "text": "is used correctly"
    },
    {
      "start": 2758.88,
      "duration": 5.28,
      "text": "Yeah."
    },
    {
      "start": 2760.72,
      "duration": 7.599,
      "text": ">> Yeah. I I think I think what we've been"
    },
    {
      "start": 2764.16,
      "duration": 8.08,
      "text": "seeing, which echoes your experience"
    },
    {
      "start": 2768.319,
      "duration": 7.76,
      "text": "is it's very easy for an agent team to"
    },
    {
      "start": 2772.24,
      "duration": 7.359,
      "text": "get their agent working in, you know, in"
    },
    {
      "start": 2776.079,
      "duration": 8.24,
      "text": "a silo and they'll build the tools they"
    },
    {
      "start": 2779.599,
      "duration": 6.161,
      "text": "need and and it'll work."
    },
    {
      "start": 2784.319,
      "duration": 3.921,
      "text": ">> But there's almost always an"
    },
    {
      "start": 2785.76,
      "duration": 5.68,
      "text": "organizational context."
    },
    {
      "start": 2788.24,
      "duration": 6,
      "text": "um that agent team is focused on its"
    },
    {
      "start": 2791.44,
      "duration": 6.639,
      "text": "agent but its manager or the director or"
    },
    {
      "start": 2794.24,
      "duration": 6.8,
      "text": "the VP or the CTO or CIO is looking"
    },
    {
      "start": 2798.079,
      "duration": 4.321,
      "text": "horizontally and they're the or most"
    },
    {
      "start": 2801.04,
      "duration": 4.799,
      "text": "organizations are typically building"
    },
    {
      "start": 2802.4,
      "duration": 5.439,
      "text": "more than one agent and the same"
    },
    {
      "start": 2805.839,
      "duration": 6.161,
      "text": "problems that everybody saw in the last"
    },
    {
      "start": 2807.839,
      "duration": 6.801,
      "text": "cycle with APIs is is the exact same"
    },
    {
      "start": 2812,
      "duration": 4.8,
      "text": "problem now with tools"
    },
    {
      "start": 2814.64,
      "duration": 5.04,
      "text": ">> um MCP or not like take the wire"
    },
    {
      "start": 2816.8,
      "duration": 4.96,
      "text": "protocol out of it. It's okay, great."
    },
    {
      "start": 2819.68,
      "duration": 4.399,
      "text": "These two people are inserting user"
    },
    {
      "start": 2821.76,
      "duration": 4.319,
      "text": "records into the CRM."
    },
    {
      "start": 2824.079,
      "duration": 4.321,
      "text": "Why do they have two different tools"
    },
    {
      "start": 2826.079,
      "duration": 4.081,
      "text": "that are being maintained separately"
    },
    {
      "start": 2828.4,
      "duration": 3.52,
      "text": ">> with different logic? Like that should"
    },
    {
      "start": 2830.16,
      "duration": 2.56,
      "text": "all be the same thing. Let's elevate"
    },
    {
      "start": 2831.92,
      "duration": 2.399,
      "text": "that"
    },
    {
      "start": 2832.72,
      "duration": 3.359,
      "text": ">> and make that a shared tool. But then"
    },
    {
      "start": 2834.319,
      "duration": 3.201,
      "text": "when you do that, you suddenly introduce"
    },
    {
      "start": 2836.079,
      "duration": 2.641,
      "text": "a governance problem that's never been"
    },
    {
      "start": 2837.52,
      "duration": 3.28,
      "text": "resolved before"
    },
    {
      "start": 2838.72,
      "duration": 3.28,
      "text": ">> with tools. How, you know, how do we do"
    },
    {
      "start": 2840.8,
      "duration": 3.92,
      "text": "versioning?"
    },
    {
      "start": 2842,
      "duration": 6.4,
      "text": ">> Um, how do we do ownership? Who gets"
    },
    {
      "start": 2844.72,
      "duration": 5.04,
      "text": "access to which tools? team A which is"
    },
    {
      "start": 2848.4,
      "duration": 3.679,
      "text": "working on customerf facing. We talked"
    },
    {
      "start": 2849.76,
      "duration": 5.68,
      "text": "about this last night. Agent A is a"
    },
    {
      "start": 2852.079,
      "duration": 6.161,
      "text": "customerf facing agent and agent B is an"
    },
    {
      "start": 2855.44,
      "duration": 4.32,
      "text": "internally facing agent and those teams"
    },
    {
      "start": 2858.24,
      "duration": 2.72,
      "text": "probably shouldn't be seeing the same"
    },
    {
      "start": 2859.76,
      "duration": 3.599,
      "text": "tools"
    },
    {
      "start": 2860.96,
      "duration": 4.56,
      "text": ">> because the policy at an organization I"
    },
    {
      "start": 2863.359,
      "duration": 4.401,
      "text": "think which is the policy here is that"
    },
    {
      "start": 2865.52,
      "duration": 3.68,
      "text": "internally facing agents shouldn't have"
    },
    {
      "start": 2867.76,
      "duration": 6.16,
      "text": "any access to anything outside of the"
    },
    {
      "start": 2869.2,
      "duration": 6.639,
      "text": "organization. And so like sharing is the"
    },
    {
      "start": 2873.92,
      "duration": 3.76,
      "text": "beginning of it. But one the moment you"
    },
    {
      "start": 2875.839,
      "duration": 3.76,
      "text": "start sharing tools which is a a best"
    },
    {
      "start": 2877.68,
      "duration": 4.48,
      "text": "practice it looks at first like a"
    },
    {
      "start": 2879.599,
      "duration": 5.52,
      "text": "productivity gain but immediately you"
    },
    {
      "start": 2882.16,
      "duration": 7.76,
      "text": "inherit a bunch of governance challenges"
    },
    {
      "start": 2885.119,
      "duration": 6.561,
      "text": "and governance gains. So for example"
    },
    {
      "start": 2889.92,
      "duration": 5.439,
      "text": "who has access to the tool."
    },
    {
      "start": 2891.68,
      "duration": 5.76,
      "text": ">> Yeah. this agent. What's the policy for"
    },
    {
      "start": 2895.359,
      "duration": 3.601,
      "text": "how access is being doled out? Not just"
    },
    {
      "start": 2897.44,
      "duration": 3.6,
      "text": "to the individual developers on"
    },
    {
      "start": 2898.96,
      "duration": 4.159,
      "text": "different teams, but to the nature of"
    },
    {
      "start": 2901.04,
      "duration": 5.2,
      "text": "the agent itself, internally facing"
    },
    {
      "start": 2903.119,
      "duration": 4.641,
      "text": "agent versus externally facing agent."
    },
    {
      "start": 2906.24,
      "duration": 3.359,
      "text": "And how do you handle versioning? And if"
    },
    {
      "start": 2907.76,
      "duration": 5.04,
      "text": "and if you're the one that wrote the"
    },
    {
      "start": 2909.599,
      "duration": 6.561,
      "text": "user insert tool for the CRM and my"
    },
    {
      "start": 2912.8,
      "duration": 4,
      "text": "agent depends on it, who owns the tool?"
    },
    {
      "start": 2916.16,
      "duration": 3.6,
      "text": ">> Yeah."
    },
    {
      "start": 2916.8,
      "duration": 4.88,
      "text": ">> Like who's in charge of bug fixing it?"
    },
    {
      "start": 2919.76,
      "duration": 4,
      "text": "Is it me? Is it you?"
    },
    {
      "start": 2921.68,
      "duration": 5.439,
      "text": ">> Yeah. And when this impacts multiple"
    },
    {
      "start": 2923.76,
      "duration": 6,
      "text": "agents like changing a tool definition"
    },
    {
      "start": 2927.119,
      "duration": 6.72,
      "text": "is act changing the the prompt that the"
    },
    {
      "start": 2929.76,
      "duration": 6.16,
      "text": "agent has access to. So it's crucial to"
    },
    {
      "start": 2933.839,
      "duration": 3.361,
      "text": "evaluate because if you if you change"
    },
    {
      "start": 2935.92,
      "duration": 3.199,
      "text": "that you're going to impact all these"
    },
    {
      "start": 2937.2,
      "duration": 4.08,
      "text": "downstream tasks"
    },
    {
      "start": 2939.119,
      "duration": 4.321,
      "text": ">> and it's yeah it's really crucial to"
    },
    {
      "start": 2941.28,
      "duration": 4.079,
      "text": "have good evaluations in place not just"
    },
    {
      "start": 2943.44,
      "duration": 3.6,
      "text": "for the tool but for how the agent will"
    },
    {
      "start": 2945.359,
      "duration": 2.881,
      "text": "use this tool and will interact with"
    },
    {
      "start": 2947.04,
      "duration": 4,
      "text": "that"
    },
    {
      "start": 2948.24,
      "duration": 5.28,
      "text": ">> and and I I would to link it back I mean"
    },
    {
      "start": 2951.04,
      "duration": 6,
      "text": "I think this is where lading up tools"
    },
    {
      "start": 2953.52,
      "duration": 6.079,
      "text": "really matters because my agent"
    },
    {
      "start": 2957.04,
      "duration": 5.2,
      "text": "consuming the shared you know user"
    },
    {
      "start": 2959.599,
      "duration": 4.801,
      "text": "insertion into the CRM tool"
    },
    {
      "start": 2962.24,
      "duration": 2.879,
      "text": "is going to likely have different set of"
    },
    {
      "start": 2964.4,
      "duration": 1.199,
      "text": "evals."
    },
    {
      "start": 2965.119,
      "duration": 1.921,
      "text": ">> Yeah."
    },
    {
      "start": 2965.599,
      "duration": 2.48,
      "text": ">> Than your tool because we just have"
    },
    {
      "start": 2967.04,
      "duration": 2.319,
      "text": "different context. We have a different"
    },
    {
      "start": 2968.079,
      "duration": 2,
      "text": "intentions."
    },
    {
      "start": 2969.359,
      "duration": 5.521,
      "text": ">> Huh."
    },
    {
      "start": 2970.079,
      "duration": 6.641,
      "text": ">> And and I'm going to bloat your tool"
    },
    {
      "start": 2974.88,
      "duration": 4.32,
      "text": "irreparably for all the other agents if"
    },
    {
      "start": 2976.72,
      "duration": 5.52,
      "text": "I try and insert all of my needs and"
    },
    {
      "start": 2979.2,
      "duration": 6.639,
      "text": "demands onto it. But if I then if I'm"
    },
    {
      "start": 2982.24,
      "duration": 6,
      "text": "just if I instead I just layer up my own"
    },
    {
      "start": 2985.839,
      "duration": 4.72,
      "text": "domain specific tool or agent specific"
    },
    {
      "start": 2988.24,
      "duration": 5.119,
      "text": "tool that sits on top of yours then"
    },
    {
      "start": 2990.559,
      "duration": 4.881,
      "text": "suddenly sharing and repeatability still"
    },
    {
      "start": 2993.359,
      "duration": 5.041,
      "text": "works"
    },
    {
      "start": 2995.44,
      "duration": 5.2,
      "text": "without having to sacrifice accuracy and"
    },
    {
      "start": 2998.4,
      "duration": 4.48,
      "text": "consistency and latency for for the"
    },
    {
      "start": 3000.64,
      "duration": 4.32,
      "text": "agent. So now I can share the we can"
    },
    {
      "start": 3002.88,
      "duration": 4.08,
      "text": "share the same tool and I can have my"
    },
    {
      "start": 3004.96,
      "duration": 4.639,
      "text": "own little domain specific issues with"
    },
    {
      "start": 3006.96,
      "duration": 4.48,
      "text": "my own set of eval agent separate from"
    },
    {
      "start": 3009.599,
      "duration": 5.52,
      "text": "yours. I see what you're saying where"
    },
    {
      "start": 3011.44,
      "duration": 6.48,
      "text": "it's like you normally have to go really"
    },
    {
      "start": 3015.119,
      "duration": 5.281,
      "text": "deep on something and really craft it so"
    },
    {
      "start": 3017.92,
      "duration": 4.639,
      "text": "that you understand the problem set, you"
    },
    {
      "start": 3020.4,
      "duration": 4.4,
      "text": "understand how to build that agent in"
    },
    {
      "start": 3022.559,
      "duration": 5.601,
      "text": "the best way possible. But at the same"
    },
    {
      "start": 3024.8,
      "duration": 6.48,
      "text": "time, I feel like if you're getting that"
    },
    {
      "start": 3028.16,
      "duration": 5.679,
      "text": "detailed with it, you're now creating a"
    },
    {
      "start": 3031.28,
      "duration": 4.559,
      "text": "whole lot more work for every team."
    },
    {
      "start": 3033.839,
      "duration": 3.601,
      "text": ">> Yeah, you are. You are absolutely"
    },
    {
      "start": 3035.839,
      "duration": 3.361,
      "text": "creating more work. But this is this is"
    },
    {
      "start": 3037.44,
      "duration": 3.2,
      "text": "the trade-off, right? It's all about"
    },
    {
      "start": 3039.2,
      "duration": 4.32,
      "text": "knobs and dials."
    },
    {
      "start": 3040.64,
      "duration": 3.76,
      "text": ">> It's if you're a single agent team, you"
    },
    {
      "start": 3043.52,
      "duration": 1.36,
      "text": "don't need this."
    },
    {
      "start": 3044.4,
      "duration": 2.32,
      "text": ">> Yeah."
    },
    {
      "start": 3044.88,
      "duration": 4.16,
      "text": ">> Right. But the and and and the"
    },
    {
      "start": 3046.72,
      "duration": 3.599,
      "text": "individual agent developers,"
    },
    {
      "start": 3049.04,
      "duration": 2.48,
      "text": ">> you know, aren't going to be thinking"
    },
    {
      "start": 3050.319,
      "duration": 3.201,
      "text": "about this."
    },
    {
      "start": 3051.52,
      "duration": 3.599,
      "text": ">> It's the moment that you're running an"
    },
    {
      "start": 3053.52,
      "duration": 3.36,
      "text": "agent program,"
    },
    {
      "start": 3055.119,
      "duration": 3.521,
      "text": ">> you know, call it a center of excellence"
    },
    {
      "start": 3056.88,
      "duration": 3.92,
      "text": "or whatever. I mean the moment you're"
    },
    {
      "start": 3058.64,
      "duration": 4,
      "text": "building multiple agents"
    },
    {
      "start": 3060.8,
      "duration": 4.48,
      "text": ">> across an organization"
    },
    {
      "start": 3062.64,
      "duration": 4.08,
      "text": ">> if you're a Fortune 2000 and you're"
    },
    {
      "start": 3065.28,
      "duration": 4,
      "text": ">> you have you even here you have a"
    },
    {
      "start": 3066.72,
      "duration": 6.48,
      "text": "mandate for 30,000 agents"
    },
    {
      "start": 3069.28,
      "duration": 6.559,
      "text": ">> and this becomes a requirement at scale"
    },
    {
      "start": 3073.2,
      "duration": 6.8,
      "text": "if everybody's rebuilding the wheel"
    },
    {
      "start": 3075.839,
      "duration": 6.881,
      "text": "every single time you have you"
    },
    {
      "start": 3080,
      "duration": 5.28,
      "text": "the productivity gains"
    },
    {
      "start": 3082.72,
      "duration": 3.28,
      "text": "of of flipping the script become pretty"
    },
    {
      "start": 3085.28,
      "duration": 4.24,
      "text": "high"
    },
    {
      "start": 3086,
      "duration": 5.359,
      "text": ">> because when I go start my my new agent."
    },
    {
      "start": 3089.52,
      "duration": 2.88,
      "text": "I don't have to go build all this stuff"
    },
    {
      "start": 3091.359,
      "duration": 3.841,
      "text": "from scratch."
    },
    {
      "start": 3092.4,
      "duration": 4.4,
      "text": ">> I can go see in the registry, oh, what"
    },
    {
      "start": 3095.2,
      "duration": 3.84,
      "text": "are all the different tools that already"
    },
    {
      "start": 3096.8,
      "duration": 3.84,
      "text": "exist? Oh, let me pick that one. Let me"
    },
    {
      "start": 3099.04,
      "duration": 3.44,
      "text": "pick this one. Let me pick this one. And"
    },
    {
      "start": 3100.64,
      "duration": 3.36,
      "text": "then I can build my own tools on top to"
    },
    {
      "start": 3102.48,
      "duration": 3.76,
      "text": "personalize them"
    },
    {
      "start": 3104,
      "duration": 4.24,
      "text": ">> and everybody wins. But that's just the"
    },
    {
      "start": 3106.24,
      "duration": 5.359,
      "text": "developer productivity piece. If you"
    },
    {
      "start": 3108.24,
      "duration": 6.16,
      "text": "think about senior leadership and and"
    },
    {
      "start": 3111.599,
      "duration": 5.201,
      "text": "the governance problems, it becomes"
    },
    {
      "start": 3114.4,
      "duration": 5.28,
      "text": "possible to put your arms around it. If"
    },
    {
      "start": 3116.8,
      "duration": 6.08,
      "text": "you don't have any kind of reuse or"
    },
    {
      "start": 3119.68,
      "duration": 5.76,
      "text": "reusability or registry or things like"
    },
    {
      "start": 3122.88,
      "duration": 4.719,
      "text": "that, you know, when the CISO or the"
    },
    {
      "start": 3125.44,
      "duration": 5.2,
      "text": "compliance team or senior leadership"
    },
    {
      "start": 3127.599,
      "duration": 5.601,
      "text": "worried about performance wants to go"
    },
    {
      "start": 3130.64,
      "duration": 5.12,
      "text": "see what's happening, they have to go"
    },
    {
      "start": 3133.2,
      "duration": 4,
      "text": "look at what 300,000 tools. That's not"
    },
    {
      "start": 3135.76,
      "duration": 3.28,
      "text": "going to work."
    },
    {
      "start": 3137.2,
      "duration": 2.879,
      "text": ">> They're all marginally different. That's"
    },
    {
      "start": 3139.04,
      "duration": 2.4,
      "text": "that's a fail, right?"
    },
    {
      "start": 3140.079,
      "duration": 3.76,
      "text": ">> Yeah. At the same time, there is no"
    },
    {
      "start": 3141.44,
      "duration": 5.28,
      "text": "substitute for really digging deep into"
    },
    {
      "start": 3143.839,
      "duration": 5.041,
      "text": "a problem. Um cuz starting the other way"
    },
    {
      "start": 3146.72,
      "duration": 4.08,
      "text": "around uh I think would be a disaster."
    },
    {
      "start": 3148.88,
      "duration": 5.28,
      "text": "Like if you start from defining what"
    },
    {
      "start": 3150.8,
      "duration": 4.88,
      "text": "tools can be built for the teams before"
    },
    {
      "start": 3154.16,
      "duration": 2.72,
      "text": "even you're solving the business"
    },
    {
      "start": 3155.68,
      "duration": 3.52,
      "text": "problem."
    },
    {
      "start": 3156.88,
      "duration": 4.08,
      "text": ">> Uh that is a recipe for disaster like"
    },
    {
      "start": 3159.2,
      "duration": 3.2,
      "text": "you're going to overengineer things and"
    },
    {
      "start": 3160.96,
      "duration": 4.879,
      "text": "like the tool is going to have to be"
    },
    {
      "start": 3162.4,
      "duration": 6.8,
      "text": "changed so many times. So yeah, what we"
    },
    {
      "start": 3165.839,
      "duration": 5.52,
      "text": "found at works was really to to build"
    },
    {
      "start": 3169.2,
      "duration": 3.84,
      "text": "something, you know, you know, like"
    },
    {
      "start": 3171.359,
      "duration": 4.161,
      "text": "building an agent in production is way"
    },
    {
      "start": 3173.04,
      "duration": 5.92,
      "text": "different from thinking about an agent"
    },
    {
      "start": 3175.52,
      "duration": 5.68,
      "text": "like um you you you find challenges you"
    },
    {
      "start": 3178.96,
      "duration": 3.92,
      "text": "didn't even think about. So before you"
    },
    {
      "start": 3181.2,
      "duration": 5.04,
      "text": "have done that, I think you shouldn't"
    },
    {
      "start": 3182.88,
      "duration": 5.679,
      "text": "even even start thinking about uh how"
    },
    {
      "start": 3186.24,
      "duration": 3.359,
      "text": "this can be shared across teams."
    },
    {
      "start": 3188.559,
      "duration": 5.601,
      "text": ">> Um"
    },
    {
      "start": 3189.599,
      "duration": 5.681,
      "text": ">> I I I I agree with a few nuances. I"
    },
    {
      "start": 3194.16,
      "duration": 3.04,
      "text": "think that's that's generally the best"
    },
    {
      "start": 3195.28,
      "duration": 3.44,
      "text": "practice. We"
    },
    {
      "start": 3197.2,
      "duration": 2.32,
      "text": ">> again we talk to a lot of customers and"
    },
    {
      "start": 3198.72,
      "duration": 2.32,
      "text": "they're all coming from different"
    },
    {
      "start": 3199.52,
      "duration": 3.2,
      "text": "angles, right? You know, there's an"
    },
    {
      "start": 3201.04,
      "duration": 3.76,
      "text": "particular agent team that needs to go"
    },
    {
      "start": 3202.72,
      "duration": 4,
      "text": "unlock a particular piece of"
    },
    {
      "start": 3204.8,
      "duration": 5.039,
      "text": "functionality. they want to talk to"
    },
    {
      "start": 3206.72,
      "duration": 5.2,
      "text": "email or calendar or you know some"
    },
    {
      "start": 3209.839,
      "duration": 4.72,
      "text": "custom service"
    },
    {
      "start": 3211.92,
      "duration": 4.8,
      "text": "and then we'll also talk to CIOS and you"
    },
    {
      "start": 3214.559,
      "duration": 3.76,
      "text": "know their VPs who are trying to"
    },
    {
      "start": 3216.72,
      "duration": 3.44,
      "text": "architect the organization and the"
    },
    {
      "start": 3218.319,
      "duration": 4.721,
      "text": "enterprise for agents"
    },
    {
      "start": 3220.16,
      "duration": 6.88,
      "text": ">> and we we have a saying internally which"
    },
    {
      "start": 3223.04,
      "duration": 7.2,
      "text": "is uh regardless of where we come in as"
    },
    {
      "start": 3227.04,
      "duration": 5.76,
      "text": "a vendor and to help an organization we"
    },
    {
      "start": 3230.24,
      "duration": 4.079,
      "text": "always drive the conversation to the"
    },
    {
      "start": 3232.8,
      "duration": 2.96,
      "text": "first agent"
    },
    {
      "start": 3234.319,
      "duration": 4.401,
      "text": ">> for that same reason. It's like, well,"
    },
    {
      "start": 3235.76,
      "duration": 5.28,
      "text": "before anybody gets caught up, you know,"
    },
    {
      "start": 3238.72,
      "duration": 5.599,
      "text": "in in in building like the cysteine"
    },
    {
      "start": 3241.04,
      "duration": 5.36,
      "text": "chapel of of complex agent governance"
    },
    {
      "start": 3244.319,
      "duration": 4.8,
      "text": "and systems, let let's first make sure"
    },
    {
      "start": 3246.4,
      "duration": 4.88,
      "text": "that you've got your agent, your first"
    },
    {
      "start": 3249.119,
      "duration": 4,
      "text": "agent at least, successful and working"
    },
    {
      "start": 3251.28,
      "duration": 3.839,
      "text": "and you got the right patterns."
    },
    {
      "start": 3253.119,
      "duration": 3.921,
      "text": ">> And you're absolutely right. You should"
    },
    {
      "start": 3255.119,
      "duration": 3.601,
      "text": "go deep first and then once it's"
    },
    {
      "start": 3257.04,
      "duration": 3.76,
      "text": "working, then abstract out and then"
    },
    {
      "start": 3258.72,
      "duration": 3.839,
      "text": "start optimizing for sharing and"
    },
    {
      "start": 3260.8,
      "duration": 3.92,
      "text": "reusability and all that fun stuff. But"
    },
    {
      "start": 3262.559,
      "duration": 5.52,
      "text": "you can't start there. However, with uh"
    },
    {
      "start": 3264.72,
      "duration": 5.92,
      "text": "some um third party tools that are, you"
    },
    {
      "start": 3268.079,
      "duration": 5.841,
      "text": "know, pretty widely accepted by now,"
    },
    {
      "start": 3270.64,
      "duration": 6.4,
      "text": "like managing calendar, emails, I think,"
    },
    {
      "start": 3273.92,
      "duration": 4.24,
      "text": "you know, that's a it's a good bet to"
    },
    {
      "start": 3277.04,
      "duration": 1.68,
      "text": ">> Yeah, those are easier, which is how you"
    },
    {
      "start": 3278.16,
      "duration": 2.32,
      "text": "guys use"
    },
    {
      "start": 3278.72,
      "duration": 2.56,
      "text": ">> a good reason to incorporate those,"
    },
    {
      "start": 3280.48,
      "duration": 4,
      "text": "right?"
    },
    {
      "start": 3281.28,
      "duration": 3.68,
      "text": ">> Yeah, everybody should use arcade."
    },
    {
      "start": 3284.48,
      "duration": 2.639,
      "text": ">> Awesome."
    },
    {
      "start": 3284.96,
      "duration": 4.879,
      "text": ">> And on that we can"
    },
    {
      "start": 3287.119,
      "duration": 4.24,
      "text": ">> dude, the governance piece is wild."
    },
    {
      "start": 3289.839,
      "duration": 3.28,
      "text": ">> Oh my god, it's become like the"
    },
    {
      "start": 3291.359,
      "duration": 4.081,
      "text": "conversation everywhere. Yeah,"
    },
    {
      "start": 3293.119,
      "duration": 4.561,
      "text": ">> it's crazy because like"
    },
    {
      "start": 3295.44,
      "duration": 3.76,
      "text": ">> 3 months ago I never heard the word."
    },
    {
      "start": 3297.68,
      "duration": 3.12,
      "text": ">> Well, I remember I told you after I was"
    },
    {
      "start": 3299.2,
      "duration": 2.879,
      "text": "in San Francisco I was like all these"
    },
    {
      "start": 3300.8,
      "duration": 2.88,
      "text": "CEOs talking about governance."
    },
    {
      "start": 3302.079,
      "duration": 2.161,
      "text": ">> Yeah. When you and I spoke I was like ah"
    },
    {
      "start": 3303.68,
      "duration": 0.96,
      "text": "governance."
    },
    {
      "start": 3304.24,
      "duration": 2,
      "text": ">> Yeah."
    },
    {
      "start": 3304.64,
      "duration": 2.88,
      "text": ">> Now it has been every single"
    },
    {
      "start": 3306.24,
      "duration": 3.119,
      "text": "conversation we're in."
    },
    {
      "start": 3307.52,
      "duration": 2.88,
      "text": ">> It is just it's wild to me how fast"
    },
    {
      "start": 3309.359,
      "duration": 2.641,
      "text": "everything's changing."
    },
    {
      "start": 3310.4,
      "duration": 4.88,
      "text": ">> The maturity curve for most"
    },
    {
      "start": 3312,
      "duration": 6.24,
      "text": "organizations is rapid. We notice also"
    },
    {
      "start": 3315.28,
      "duration": 5.279,
      "text": "teams using multi- aent setups way more"
    },
    {
      "start": 3318.24,
      "duration": 3.76,
      "text": "and sometimes agents look like they have"
    },
    {
      "start": 3320.559,
      "duration": 4.321,
      "text": "a multi-agent setup where agents look"
    },
    {
      "start": 3322,
      "duration": 5.2,
      "text": "very similar to each other and when when"
    },
    {
      "start": 3324.88,
      "duration": 3.52,
      "text": "you start to dig deeper into the reasons"
    },
    {
      "start": 3327.2,
      "duration": 1.919,
      "text": "it's governance."
    },
    {
      "start": 3328.4,
      "duration": 2.48,
      "text": ">> Yeah."
    },
    {
      "start": 3329.119,
      "duration": 3.121,
      "text": ">> I'll tell you what I'm seeing though"
    },
    {
      "start": 3330.88,
      "duration": 3.679,
      "text": "here's my bet a year from now when we do"
    },
    {
      "start": 3332.24,
      "duration": 3.599,
      "text": "this podcast again I think multi-agent"
    },
    {
      "start": 3334.559,
      "duration": 2,
      "text": "systems are going to be a lot less"
    },
    {
      "start": 3335.839,
      "duration": 1.441,
      "text": "common."
    },
    {
      "start": 3336.559,
      "duration": 1.841,
      "text": ">> Oh interesting."
    },
    {
      "start": 3337.28,
      "duration": 2,
      "text": ">> Yeah. We're starting to see the early"
    },
    {
      "start": 3338.4,
      "duration": 5.12,
      "text": "signs of"
    },
    {
      "start": 3339.28,
      "duration": 6.16,
      "text": "felt like as we talked through this"
    },
    {
      "start": 3343.52,
      "duration": 3.68,
      "text": "agents and tools can be almost like"
    },
    {
      "start": 3345.44,
      "duration": 4.32,
      "text": "interchanged in a way."
    },
    {
      "start": 3347.2,
      "duration": 8,
      "text": ">> Yeah. Actually, we um actually our sales"
    },
    {
      "start": 3349.76,
      "duration": 8.64,
      "text": "engineer Schu um who is incredible um he"
    },
    {
      "start": 3355.2,
      "duration": 4.639,
      "text": "he basically proved to all of us in a"
    },
    {
      "start": 3358.4,
      "duration": 3.679,
      "text": "really dramatic way. I don't think he"
    },
    {
      "start": 3359.839,
      "duration": 3.76,
      "text": "was even doing it on purpose that an"
    },
    {
      "start": 3362.079,
      "duration": 2.72,
      "text": "agent is really just a collection of"
    },
    {
      "start": 3363.599,
      "duration": 2,
      "text": "prompts and tools."
    },
    {
      "start": 3364.799,
      "duration": 2.8,
      "text": ">> Yeah."
    },
    {
      "start": 3365.599,
      "duration": 3.52,
      "text": ">> And people say it but nobody really"
    },
    {
      "start": 3367.599,
      "duration": 3.921,
      "text": "believes it. Sus, you know, they all"
    },
    {
      "start": 3369.119,
      "duration": 4,
      "text": "want to use all all the big systems and"
    },
    {
      "start": 3371.52,
      "duration": 4.24,
      "text": "Schube just like slammed together a"
    },
    {
      "start": 3373.119,
      "duration": 4,
      "text": "little YAML based agent builder"
    },
    {
      "start": 3375.76,
      "duration": 2.319,
      "text": ">> and it [__] works, man."
    },
    {
      "start": 3377.119,
      "duration": 2.72,
      "text": ">> Like take that."
    },
    {
      "start": 3378.079,
      "duration": 3.04,
      "text": ">> Yeah, it just works. You just need"
    },
    {
      "start": 3379.839,
      "duration": 3.601,
      "text": "prompts and tools and you're done. And"
    },
    {
      "start": 3381.119,
      "duration": 5.68,
      "text": "it's got land graph under the hood,"
    },
    {
      "start": 3383.44,
      "duration": 7.04,
      "text": ">> but it's wild, right? And um what we've"
    },
    {
      "start": 3386.799,
      "duration": 5.121,
      "text": "been seeing is the scope definition of a"
    },
    {
      "start": 3390.48,
      "duration": 5.119,
      "text": "of an of a sub agent."
    },
    {
      "start": 3391.92,
      "duration": 5.84,
      "text": ">> Mhm. is uh is getting bigger and bigger"
    },
    {
      "start": 3395.599,
      "duration": 5.041,
      "text": "and bigger as context windows get"
    },
    {
      "start": 3397.76,
      "duration": 4.64,
      "text": "bigger, as it can handle more tools,"
    },
    {
      "start": 3400.64,
      "duration": 3.36,
      "text": ">> all of a sudden like you're seeing"
    },
    {
      "start": 3402.4,
      "duration": 4.08,
      "text": "bigger sub agents."
    },
    {
      "start": 3404,
      "duration": 5.2,
      "text": ">> And so if you take that to the limit,"
    },
    {
      "start": 3406.48,
      "duration": 4.319,
      "text": "like you're not going to see as complex"
    },
    {
      "start": 3409.2,
      "duration": 4.599,
      "text": "of sub agents as people have been"
    },
    {
      "start": 3410.799,
      "duration": 3,
      "text": "saying."
    },
    {
      "start": 3420.72,
      "duration": 3.72,
      "text": "Love you, baby."
    }
  ],
  "fullText": "We've got Kiara to my left, Alex to my right, CEO of Arcade. Kiara's working on IUD. She's a process lead data scientist. >> Data scientist. >> You're leading our book. >> You've been working on a project at I Food. You gave a talk last night. I loved it. I wanted to bring you on here to talk about some of your learnings. >> For those who don't know, I food is the biggest uh food delivery company in Brazil. Um it has a huge order volume 160 million per month. Um Brazilians use it a lot. What we realize is that users often go to the app and they don't know what to order. Uh they are bit undecided and sometimes they get frustrated because they have too many options. It's a paradox of choice, right? So the problem we solve with this agent is to help them decide. We built something that um knows who the users are, knows uh their preferences, their habits, and um the price range they're willing to pay. And we use that plus uh the users questions to suggest the best options for them even proactively. And we yeah, we have a flow where the user can can search and refine uh and then order at the end. We prepared two interfaces for the agent. One is in the app and one is on WhatsApp. Uh WhatsApp is very uh popular in Brazil. I think there are 160 million uh active users. So they they use it a lot. If you don't know uh people use it uh to order food with just voice messages. It's it's really smooth. They just send a voice note to the to the restaurant and they can order like that. So we we leverage this familiarity with um the conversational interface. uh both had different challenges uh in terms of um UX how we uh show results to the user. It often happens with agents, right? So the the biggest challenges are not AI related but uh UX and adoption related. So the agent that uh we built is um kind of a react agent. We didn't use like too fancy multi- aent setup because we needed things to go very fast. >> Users are hungry. They don't want to wait. So we need to have the simplest flow. We need to make sure that the recommendations that we give to them uh are are good. They work for them. And we also need to remind to remember if they don't like certain foods like the agent really needs to be a smart companion uh almost reading their mind. One of the things we wanted to make sure is that the conversational interface was not just textual and there were multiple modalities for the user to talk to the agent because when they're hungry they don't want to spend time typing, right? Um so we we made sure that tools that we built were connected to UX and UI elements so that the user could directly interact with them. um to have some uh short circuit uh let's say >> it's like swiping and >> also yeah we also implemented a swiping interface >> voice also >> also voice yeah yeah so voice is a modality but it's still textual in a way um what we we did was also making sure that there were buttons to click to do actions quickly without having to type like I want the third item that you're showing me and that's not needed one interesting thing we noticed is that uh people on WhatsApp were way more lenient towards this conversational behavior than in app. Uh in app really people really want to use buttons. They expect a different type of interface. >> So our tools needed to work very well. Uh one of the challenges we encountered was that the tool definitions that we had made a lot of sense for us but it didn't make sense uh to someone external that would see them for the first time. We realized this afterwards of course with trial and and error. What we noticed was that um we we created the tools right uh things made sense but as soon as we were getting edge cases in production we were adding this to the tool. So whenever the user uh wants to order something and you don't have uh enough information about it, make sure to call the get information tool like a lot of edge cases for these flows and it quickly becomes uh code like a statement and that you don't want right uh so the exercises we made was to try to to standardize this tool like think if I would share this tool with another team and if they would want know use it in their own agent. How would I write things there? Like the idea is to make them as clear as possible. Uh would the name of the tool even make sense? Right? >> And after that we had a massive improvement in latency because we could cut a lot of tokens and our system become became much more stable. >> Making sure that a tool encapsulates the right things is the hardest part of the problem. Um, and I think people really struggle with that. They they think of it as an API. Oh, we just have an API. We'll call it. Well, that's not really going to work, right? You know, there's a lot of usability. It's like, well, what's the user experience going to be? What's the intention that the user has? What's the intention that the agent needs to have? And then figuring out, okay, well, what's what's the right encapsulation of that in a tool >> is what everybody's struggling with. It's a new paradigm. It's a mental model. What we what we see as a best practice as people try and build that is that it's you know there's like a lading of tools and so you might have a shared tool >> that is a workflow or maybe even an MCP server that's integrating to another service. But even if you have those things, the agents tend to do better if you then build a very domain specific or agent specific tool to capture that particular agent's nuances. >> And so when you get that, you get both the accuracy and the lower latency that you're looking for because you're pushing more off to deterministic software. And then you're able to abstract out the common elements so that other teams can reuse them really easily. I love how you talk about the difference between just a basic API and then an agent needing to consume some kind of a service and that one key word which is the intention. >> Yeah. >> And how that intention plays such a big part in what is trying to consume. >> Yeah. I think there's a lot of confusion right now because every every engineer is familiar with APIs. >> Yeah. And then you throw in MCP and people go, \"Oh, it's the same thing. >> Let me just wrap an API and MCP and success. We we have an agent and we have tools and it doesn't work.\" >> Um, for a bunch of reasons. MCP is just a wire protocol. But more importantly, tools are not APIs. And so in engineering speak, an API is a service contract for the downstream service. So we'll use Google Drive as an example. It has an API. that API is a service contract on how Google Drive works. And yes, there's a lot of work that goes into building a really nice Google Drive MCP server like we have um to make it a bit more workflowish, be make it more intention based to kind of remove or at least abstract away the structured inputs that are required. So >> an LLM has no idea what a Unix time stamp is. Um, so your MCP tool has to like know what yesterday is as a concept and then translate that to unique time stamp. >> But even with all of that, if you're building a sales agent, for example, and and a and a rep is going to ask, \"Hey, I need the brochure for this product because I'm going into this customer account.\" >> The agent doesn't care at all about Google Drive. That's not its intention. its intention is to find the brochure that it needs. And so if you give it even a pristine, beautiful Google Drive MCP server, you're asking for higher latency and you're asking for hallucinations because now you have to stuff the context window with explanations of how to find the brochure using the MCP server, >> which means it's going to have to take multiple turns figuring out what the right folder is and where the right files are and how to determine which ones are brochures and which ones aren't brochures and which is the right brochure. But if you instead give it a get brochure tool and that get brochure tool can call the Google Drive MCP server, then all of a sudden all the agent has to do is say, \"Oh, I need a brochure. There's a get brochure tool. I have the context that I need. Let me submit that as arguments.\" And then it's done. It's one call. It's low latency. You don't have to stuff the context window. You minimize the amount of tool definitions that you passed over. And then likely much of the code inside of the get brochure tool is deterministic. >> You know, chances are it's not calling a model or if it is, it's calling one maybe once I think very specific. So the whole system just gets more accurate and faster. And so what that means is a tool is actually kind of the inverse of an API. Well, an API is a service contract of what a of what a downstream service looks like like Google Drive. In my opinion, a tool is kind of like the service contract for the agents intentions. >> It's it's what it expects to do. >> Okay. And being able to write the proper tool definition is really the key though. >> It's like it's like half the battle. >> Yeah. >> It's like half the battle. >> That's why evaluations are so important as well. Well, I think also I just want to highlight such an important thing that you said yesterday and just now again, which is let somebody else look at your tool definitions. Let them see if they can understand it. And if they can, then you can try it with the agent. But if they can't, you already know, all right, this is probably where the problem is. >> Yeah. Exactly. Um, and this exercise really forces you to to have clear tool definitions. And I think it's also important to try to limit the agent choices as much as possible. I think if there is a lesson I've learned in this year's building agents, that's that's this one. Um, it decreases hallucinations. It decreases um context bloating as well. Um, if you have tool that's like tools that are always called together like in the get brochure case, it makes so much more sense to create a workflow and encapsulate that into a tool. A tool is um something that LLM can use to take action. It doesn't need to know what's inside. It can be a it can even be another agent, right? >> Um so yeah, one way is also to use multi- aent setup, of course. Uh but for from the point of view of the main agent, it doesn't really matter. >> Yeah, we we think a lot about this. Um so yeah, in a perfect world, you give it you give it one tool, right? In a perfect world, uh the agent doesn't have to think at all and you don't even need an LLM. >> Yeah. >> Right. Um because it's faster, it's cheaper, it's deterministic. But that's not the real world. The power of of an agent is that it can handle generality. And so there's this careful balance. You know, Sam, my co-founder, talks about turning the knob on determinism. And so you can give it fewer tools and you and arguably today you should because you want to minimize error rates. Um but the point of all of this where all this is going uh where all the investments are going where the model companies are investing heavily where the orchestration systems like Langraph are investing heavily where we're investing heavily as a world which is the opposite where you can turn up the the you know the non-determinism you can turn up the ability to give it as many tools as you want and then let the agent intelligently decide what to That's very hard. That's where we're going to get to at the limit. >> You know, we ourselves have achieved, you know, incredible things in the lab that we haven't yet announced. >> Uh where we're making it possible to kind of turn that that dial up on the tool level. >> But for most people today, you're right. You're better off really thinking through in a multi- aent system. you know, which are the right tools based on the node that I'm in or the state that I'm in and trying to be very specific. But the benefits of giving it more tools are huge because then you have fewer nodes, the agents more intelligent, but it really depends on what you're trying to do. >> Yeah. Also I think the we haven't touched on this topic but the way output um the way you construct a tool output is also important because you can put a lot of instructions there as well. So by limiting the amount of choices I don't mean the agent shouldn't have tools like we should try to make it as deterministic as possible. Uh we can still leave freedom but I think we need to be smart in where we put the information where we put the instructions. So if um for instance I always have a certain options for tools after a given tool is called I can put the instructions in the tool response. I don't need to to bloat the system prompt with those instructions. >> I've heard that a ton that dynamically inserting context in there. That's one way of doing it. There's all kinds of fancy ways that you can make sure to leave things out that need to be left out and then when it needs it if it needs it. It's like this is a need to know basis here. >> Yeah. >> Well, I think I'll I'll go back to this concept of uh layering up tools. >> If you look at APIs, this pattern already exists. >> You've got your your low-level system APIs, you've got your workflow APIs in the back end, and then you have the APIs that that the that the mobile application or the JavaScript application talks to. And there are like three different sets of APIs. >> Mh. >> And when you get all the way to the top where it's a JavaScript app talking to the back ends, those APIs are very very specific to that application most of the time. And similarly in what you're describing, and we talked a little more about this last night, so I'm going to I'm going to steal from last night. You can insert UI code in the response, >> right? You can present a table. It doesn't have to be just text. You can present a React component in a tool that gets very agent specific, but that's kind of the point. You minimize the amount of work being done by the rest of the system by the tool carrying and doing a lot of the heavy lifting. And you know, I'll go back to the Google Drive example, right? Sure, it can pull the brochure, but it can also go pull a bunch of context that you know the model's going to need on the next turn. Yeah, it reminds me of a conversation I had with Zach uh from Sierra and he was saying that a lot of times since they're doing voice agents and it's real-time voice agents, what happens is they'll have almost like a supervisor agent that will recognize and preemptively assume if this conversation is going in a direction that I think I may need this context for. they just go and grab it just in case it comes up and all right we have it now I can give it to you and then you don't have that user experience where the person is waiting on the other line because the context needs to go and you need to grab it and bring it back and that takes a little bit longer. It's just like let's have everything kind of loaded up and then if we need it we can serve it to the agent that's interacting with the human. >> Well, I mean I I think that speaks to you know how quickly the industry's changed. It's November of 2025 right now and the conversation is no longer about accuracy and consistency being the blocker to production. >> Mhm. >> 5 months ago, maybe even less, that was the only conversation we were having. Now we're talking about latency. >> Yeah. >> Every like that is the biggest problem. We're going to prod now, but now we're just having, you know, mediocre experience because we're all waiting 30 seconds. >> Yeah. and and now and it's it's amusing to me because if we were waiting 30 seconds five months ago, we would have been totally cool with it. >> But now we're like 30 seconds, right? >> This also connects to what I said earlier about WhatsApp versus app experience. So on WhatsApp, people are totally fine with waiting because they expect it. It's it's a familiar interface. Uh they don't expect it to go so fast probably because normally you have another person speaking on the other side. But on app you're punished if you if you don't deliver in time. The the expectations are completely different even for the same user. >> In a perfect world where you had user feedback from everybody who's using interacting with your agent in real time. I'd be very curious to see a generational distribution >> on on patients for waiting for the agent >> because one of the things that one of the things that I see >> but I'm very curious uh is the the generation of people who are let's say under 30 expect everything to be agentic. if they see a menu, you know, they've got to click around, they just they bail, right? The later generations are the opposite. They expect a snappy UI, very snappy and responsive buttons and clicks, but I'm very curious how the the generational distribution might be on on patients for latency. M and I also feel like when you're in WhatsApp, you can go and you can talk to your friend, you can look at something else and then come back and so you get that cuz I imagine that you get a notification when the agent is done and it's sending you the information. You don't have to sit there and wait the 30 seconds looking at the WhatsApp chat. When I'm in WhatsApp, I'm talking with three or four people at the same time and I'm going back and forth between those conversations. >> Exactly. The data that we got was really clear about this. That's why we spent so much time refining UX thinking how to present you know the data to the user. There's a lot of work done around the agent that is not agent itself. And I think this was one of the biggest challenges. Um also users you know they are familiar with AI by now but uh it's still hard to to trust an AI interface to suggest you food. People are pretty sensitive around that. they have their preferences. Um, so we really needed to build customer adoption, make it uh like also in terms of the persona that we developed, it needed to be friendly but also engaging. Uh, we wanted people to come back, right? It all connects to tools at the end that wasn't uh how do you define it, how you use it, um how smart you want it to be. >> Can I call something you said that I think is perfectly on point? Um, today the the intersection between an application and an agent is now complete. >> And you mentioned earlier, right? Like so many of the things that you ran into as you were building this weren't necessarily like the model or the AI. It was the the application. >> Yeah. >> And and I feel again, you know, speaking at least today and you know, we'll see what the world looks like in 3 months. Um that's itself a huge transition you know now we're having the debate is now well how do I make this UI work properly and you know how do I deliver this to the to the to the to the user properly as opposed to getting all caught up in this super deep ML data science of the AI >> and this also connects to evaluations how do you evaluate such a system because when we talk about evaluations we have the standard metrics in mind like faithfulness helpfulness, you name it, but they're not necessarily connected to the business value that your app brings. >> Mh. >> Um, like how can you leave UX out of the evaluation? Like you you need to take this UX elements into account. That's part of the of the user journey and that's also part of the agent. It's really really hard to to separate these two. We were joking last night that every developer uh believes so strongly in test-driven development that they recommend every other developer do test driven development. They just too lazy to do it themselves, >> right? But I feel with agents, especially around evals, you have to start there. >> Um and so I'm curious on this point, which I think is a really incredible point around assessing the connection between business value and and and the user UI. How did you how did you structure your evals? What what were the evals you you ultimately landed on? >> We have different levels of evals, right? Uh you have those more connected to development. Uh like making sure everything works like regression test um things you can evaluate with code that that's like the foundation. Uh we also have a golden data set that we run. What we realized after I think the the evol community is shifting towards uh towards this as well is to that error analysis is really really important like we we started like many teams to think of metrics like is the agent helpful? Uh did the agent satisfy the user request? Uh which are like they're okay but they're very generic. you need to write them in a way that is very specific for your product. >> And when you don't have a product yet, this is really really hard to define. >> So we were lucky enough to have a community of uh I food employees. There are more than 7,000 people employed at food. So they used our app and they gave us feedback. Um uh there's nothing that can substitute looking at the data. So we had to go and look at the the traces identify the the errors that we were seeing and once you have the you have a good overview of what can go wrong in in your application uh that's when you can build a taxonomy of errors. So with this error taxonomy uh you you can uh build a test set uh and it can it can inform you of you know things like like how how good you're doing uh with your evaluation and if the agent is performing better or not. And this is connected to LLM as judge. When you write an LLM as judge having this uh very specific u domain knowledge helps a lot. So we couldn't separate it from error analysis. It's something we learned later. If I would start a new project, I would start from that straight away. >> And but you're also checking for evals on the tools and >> yeah, >> which tools were called? Was it the right tool? >> So there's like higher level objectives. Did it satisfy the user? But then there's those very nuanced pieces, right? >> Yeah. We we have of course for the tools. Some of our tools are smart tools. Um you could call them agents themselves like searching in our food catalog. you need to take into account user preferences, sort the items, pick the ones that have most variety and like match with the user intent and profile. So that's uh that's just a tool but it deserves a whole set of evaluation itself. >> Is that and just is that how you were able to see which tools were used together and then create workflows from the tools? >> We analyze the data like we did a lot of uh ADOC analysis. uh a team member of us is completely completely dedicated to this um like assessing the quality of the agent and like understanding what goes on uh behind the scenes and also what goes on in front of the of the user. Another thing that we did I didn't mention yet but I presented it yesterday was to create an evil set that was um going to pick be picked up by an agent that would impersonate a user. So that was something uh that was defined by product team. So uh what what we noticed was that was very easy to define scenarios and what the agent should do in those scenarios. >> What was hard was to create a LLM judge that could judge any scenario but given a scenario you could say like the agent should do this and that. So we started with a set of uh of queries defined this way and um sometimes you needed some uh pre-processing steps to get there like for instance when you have an item in the cart like when you start you need to make sure there is already an item things like that um and then we we built an interface um between the agent that would would test our endpoint and the endpoint and this interface made sure that when we were returning UI elements these were also shown to the user impersonating agent. So we like the agent could choose to click on certain UI elements and at the end we would judge the outcome of all of this. So I think this allowed us to also test the UX in a way. It doesn't substitute uh AB testing of course that's uh like online testing is another story but uh it helped us to identify regressions >> on the tool side. How much work went into evaluating the tools themselves to make sure that you designed them or at least their definitions properly and the parameters the parameter definitions properly to see if the model was selecting them correctly at the right time. >> Yeah. So we we did evaluate if the agent was calling the right tools. Of course um depends on the tools. I think uh like some tools are so clear to use like uh create cart you know some definitions are so clear that you don't need to spend too much time on that. You just want to know that the agent can pick it up correctly. But some others are whole workflows like searching uh what I was talking about before that had a lot of evaluation being done and there is still a lot going on there >> because it's building a recommendation system basically right uh >> the truth >> uh yeah so >> like what we have is a user who's searching for something or maybe just exploring options they just say I'm hungry surprise me give me promotions without any intent >> what you're building is is a homepage right in the agent. So you want to show options that uh are really really good for them even when they don't specify anything. So that's uh yeah that's a recommendation problem. >> Mhm. Is there ways that you're plugging in because I imagine when it comes to the workflow, you're plugging in structured data and unstructured data in this like you're giving the context to the agent of the last three, five meals that this person ordered, when they ordered it, the timing, what they like in general, all of these features, quote unquote, that you would normally put in a recommendation model, but now you're serving it up to the agent in different moments of that workflow. >> Yeah. Yeah. Exactly. Um we have a team uh at process AI that is completely dedicated to building a model we call LCM large commerce model. So it's a model that um was fine-tuned based on user behavior in our apps in the ecosystem. So whether user uh searches for something, likes something, orders uh so using this model we built representations of who the users are. So it goes way beyond the last orders. We know what type of customer they are. We have some segmentation as well in there that uh occurred naturally while um while using this model. Um we know their their patterns. Uh so that that's like the core of who the user is and we have similar things for restaurants items. So it's um it's much more nuanced than just a list of uh like order history. So we use that in the main agent to to select the best uh way to communicate to them like select to select the tools in the best way. But within the tools also we are connecting to white food recommendation system. So when we plug um dishes, we also have models that were trained to um to show the best recommendation. So it it's in several places that we're doing this. >> It's almost like there's very complex. >> Yeah. There's like a Rexus tool in a way or like I'm going to use the recommendation tool and it's calls a machine learning model. >> Yeah. Yeah. When there are several models for different use cases for that. >> Yeah. Plus, the agent has the brain and we have LLM friendly representation of the user. >> Like for instance, if you order pizza in Brazil, you can put a lot of toppings and customization. If you always put pepperoni on your pizza, I know you're a meat lover. This you don't see it from the order history, but I can extract this nuanced information. So, the next time you say, \"I want something healthy, I'm going to propose you something with meat >> because I know you like it, right?\" So the yeah there is a lot of emergent patterns that uh >> you just can't get with traditional machine learning models because they're so specific and so here you can infer it because of the LLM being that intelligence. >> Yeah, exactly. >> That's the the beauty of exploring this field. Uh >> and we learn this as we go. There is so much uh yeah so many learnings on this and we also get feedback from the user which is uh amazing to see. >> I feel like I feel like I I'm now like excited for this app. When are you guys when you when are you guys going to be in San Francisco? >> Yeah. >> Where are we going? We can go to Brazil. >> Yeah, that's it. We got to go to Brazil. That's the easier option than them coming to San Fran. Do you have some kind of a checker agent that makes sure what's happening is actually what should be happening like overseer? I don't know what that would how you architect it but >> we have a system in place for guard rails and making sure you know the response that we were given as uh makes sense let's say um but we didn't uh choose a full-blown multi- aent setup uh because we wanted to keep it simple our use case is relatively simple I think what's uh what's difficult is given the right recommendations um having the context, but you know that the the context of the agent is pretty self-contained. We don't have an agent to schedule a trip for instance. That would be another agent. But the set of tools that our agent has um are, you know, compatible with each other. We we don't need another agent for that. What we did, however, was to have a dynamic system prompt that would change based on the state so that we would not need to to have so much information every time. And yeah, that of course helped with latency and having less choices to make >> to go back to the stratification we were talking about earlier. The way that someone interacts with i food on WhatsApp is still almost like through the i food app but that's just to verify their profile and then they go back to WhatsApp. >> Did I understand it correctly? >> This is just uh to kick off the first authorization flow. So we need to make sure that you or you you know connect to your profile. Um, so yeah, they they if they don't have an account, if they write to us from a phone number, they don't have an iPhone account, we need to make sure that they create one like uh >> and then you have all of the information about that user in i food. >> Yeah. And we connect. Yeah. >> Including the payment options and all of that stuff. And so the agent, I'm assuming, just says, do you want to use your regular credit card or do you want to use one of these options? There are some systems in Brazil uh for payments that uh we are connecting with. Yeah. But >> I remember Nishi talking to me about how hard it was to context engineer the types of payment systems that people would ask for. >> Mhm. And it goes back to what you were talking about at the beginning of you end up just adding all these edge cases to the prompt and before you know it your prompt is so bloated and if last night 6 hours stream taught me anything it is like the least amount of context as necessary. If you think about uh what a user can ask in an app to order food, uh they could ask for specific payment method, price range, delivery time, uh like distance from the restaurant or they're vegetarian, they want gluten-free discounts, they have a specific membership uh that they want to like that allows them specific discounts, they want to use that. Like there is so much it's really impossible to give all this information to the agent because then you need to like the agent needs to convert that in the qu into a query, right? If you give all this information to the main agent, it's going to blow up the the prompt. So what we did was um like having a converting the query into something more LLM friendly um with some basic knowledge from the main agent and then giving context of like who the user what the user wants and in a way this is like preparing a task for another agent. So we we delegate and the main agent doesn't need to worry about anything. >> And that first touch is just through like a small language model or sentiment analysis or it still is an LLM call. >> No, we we use an LLM straight away for that. Yeah, it's it's simpler. Um but we implemented some classification later in the way. So yeah, we we have some classifier steps to simplify. >> Nice. How much are you using the foundation foundational models like OpenAI or Claude versus your own? >> I would say we use foundational uh almost everywhere. Um we use smaller models, fine-tuned models for specific steps in the workflow like creating uh representations for the users for instance uh it's a task where there is a fine-tuned model. Um but for the conversational part we haven't explored yet. >> I think foundational model models are so good right now that uh if you don't need to fine-tune that's probably you shouldn't do it. It's >> I think I hear a lot about fine-tuning like maybe we should fine-tune that to fix the output. No, it's it's a specification problem. you're not specifying enough uh or you maybe you're specifying too much in the prompt if something can be fixed there >> as the first step. >> Well, I I think it's a great I think it's a that's a great point I'd love to dig into because you know you know so much more about this than most people. Where do you draw the line on when and where to finetune me? You guys have an incredible amount of data and I know that much of it is leveraged where do you decide to do that work? >> So, I think one of the the biggest reasons why you might want to fine-tune is cost and and latency as well. So, if you're building a model for a very specific task and the model doesn't need to be able to converse with the user, uh they just need to take user data and build a representation of the user for instance. That's a very specific task. and then you you want to scale it to 60 million users and you want to do it every day. >> Foundational model is not going to going to work very well. >> It's going to be extremely expensive. Yeah. So, and also performance-wise, right? Uh because at the end we're talking about embeddings and you want if you if you're working on a very specific uh space like uh food delivery, you want to you want the model to clearly differentiate terms that might look the same but are actually sematically different. >> Mhm. >> And that nuance you don't get in foundation model. Um, so you at the end when you're fine-tuning, you're changing the space where your model moves and you're making this um the meaning of words that might look similar, more far apart from each other. >> So that that that thing you want to do um and we proved that for our application it's better actually. Uh we AB tested this and um yeah, it gave better results. If you want to just kickstart a project then yeah first you know make it work then make it cheap then make it fast etc. >> Yeah it's interesting we see this as well with a lot of customers um is again today versus last year >> people used to start with all of their own data and with fine-tuning and that's that was the beginning of the journey and now today it's the end of the journey you instead you throw a financial model at it. Most of the time it's good enough. You do some prompt engineering, you attach some tools, and you're good to go. But when you want that extra last inch, now that's where everybody's using fine-tuning. I'm curious within the work that you've been doing, where's the dividing line of fine-tuning an existing large language model, whether it's a foundational model, open source one, >> versus building your own model that might not be LLM based. Yeah, it's very fine line sometimes. Um I think regular like more traditional machine learning approaches uh are good to get patterns from the data like when the data is numeric or uh when you have graph type of data like collaborative filtering for instance. So we're also working on that. Um I think traditional ML can find patterns that um an um an LLM like conversational type of LLM would not necessarily find because it can leverage also connections between user data points um you're embedding different type of information. So for instance to give you an example with collaborative filtering um the the model um might know that we are similar users and I order some food that you haven't ordered yet and it will suggest you this food. >> I don't necessarily have this connection in an LLM um that is conversational. Mhm. >> Um so yeah that's um there is a very fine line. What what we're trying to do is use LLM um for finding patterns based on uh the user behavior things that are not just hard data like the the example I mentioned before where you order pizza with pepperoni might be a meat lover. I know you're not but >> I'm the opposite but I understand for sake of argument >> you know just to to give you an idea. and then I can extract a filter that I will use in every query uh uh to to filter the data that I show you. Um yeah, with traditional machine learning I wouldn't get this patterns out. Yeah, it's it's a hard question. Uh I think because it yeah at the end it boils down what what type of data you want to show to the user. I think for data to fit to LLMs sometimes it makes more sense to get like text based representation but when you you need to do operations like search in a database yeah there you need vectors you need to to optimize um yeah based on vector representations yeah it's a it's a very good question >> yeah it's cool to hear that you're still grappling with it and there are these pros pros and cons of each and obviously it's always a trade-off. I like the idea of how you can leverage one and at the same time kind of plug in the machine learning models. So it's like the majority of the stuff is happening with the large language models and the agents that are going and they're doing stuff and maybe one node or one tool that it can call is a machine learning model. I think one of the things that I find most most interesting about process is how far how far out ahead and how advanced you folks are in agent building. You got a target for what 30,000 agents in the organization. >> Yeah. >> Which >> that was in the keynote which is funny cuz you know we can laugh about how crazy that number is but then how many do you actually have right now? >> It's it's more than anyone else and so >> it's not that far off. It's >> Yeah. Like you you have at least over a thousand at this point and >> Yeah. over 10,000. >> Yeah. And so, you know, we can joke about 30,000, but most people are struggling to get one out, right? and and we've talked and we've talked a fair bit and I'm sure we'll talk more in different sessions about how what it took to get there both from a technical perspective and from an organizational perspective but you had made a really interesting point about tools >> and and how you know different teams start in one way but then eventually you got to start think you start layering in governance. I'm wondering if you could share more about that. Yeah, this is uh I think um trans transition that happens in other organization as well where we are approaching genai and we have very uh vertical type of vision. We're trying to build a product for specific uh use case, right? So what uh what you do if you're a team building this is you go very all in and very deep in this vertical direction. But if you do this and you multiply it for 10 20 teams in an organization, you realize that uh often similar tools are being built. >> For instance, uh answer the user questions using knowledge base, right? Um so what uh what I think tools are really good for is also creating layers of governance where for instance in the case of the knowledge base there is a team that uh makes sure that that works very well and then can be shared across different teams. The the trick here is that the teams def defining these rules needs to be very LLM savy as well because the interface that this tool would use needs to be used by an agent. What we see sometimes is that um these definitions get too verbose. Uh there is a lot of requirements for how the tool should be used and um like the language that should be used. Sometimes you don't need all of that and you really need engineers to work together to to define the interfaces of this and I think if you nail that then you can really scale up because you can then share tools across the organization >> and this also applies to agents by the way in multi- aent setups. >> It's having that ownership of the tools being able to clearly define this is your tool. You're expected to keep it up to date to make sure that it's working and that the agent can consume it in a way. >> Yeah, exactly. And when you create uh tools that can um that are directly connected to the public image of the company like you defining persona that represents the company then um the type of people who write these rules are not developers, right? So the the person defining these rules uh maybe is a designer or like product team but you cannot give them to the agent as they are. you need some some translation layer in here and I think uh yeah governance is really it's really important uh and it's important to get it right because once you do it once then you know it's it's more maintainable and if I would uh let be used by other agents for instance uh like expose it through agent to agent framework or uh let other teams use it then I also need to make sure that that is used correctly Yeah. >> Yeah. I I think I think what we've been seeing, which echoes your experience is it's very easy for an agent team to get their agent working in, you know, in a silo and they'll build the tools they need and and it'll work. >> But there's almost always an organizational context. um that agent team is focused on its agent but its manager or the director or the VP or the CTO or CIO is looking horizontally and they're the or most organizations are typically building more than one agent and the same problems that everybody saw in the last cycle with APIs is is the exact same problem now with tools >> um MCP or not like take the wire protocol out of it. It's okay, great. These two people are inserting user records into the CRM. Why do they have two different tools that are being maintained separately >> with different logic? Like that should all be the same thing. Let's elevate that >> and make that a shared tool. But then when you do that, you suddenly introduce a governance problem that's never been resolved before >> with tools. How, you know, how do we do versioning? >> Um, how do we do ownership? Who gets access to which tools? team A which is working on customerf facing. We talked about this last night. Agent A is a customerf facing agent and agent B is an internally facing agent and those teams probably shouldn't be seeing the same tools >> because the policy at an organization I think which is the policy here is that internally facing agents shouldn't have any access to anything outside of the organization. And so like sharing is the beginning of it. But one the moment you start sharing tools which is a a best practice it looks at first like a productivity gain but immediately you inherit a bunch of governance challenges and governance gains. So for example who has access to the tool. >> Yeah. this agent. What's the policy for how access is being doled out? Not just to the individual developers on different teams, but to the nature of the agent itself, internally facing agent versus externally facing agent. And how do you handle versioning? And if and if you're the one that wrote the user insert tool for the CRM and my agent depends on it, who owns the tool? >> Yeah. >> Like who's in charge of bug fixing it? Is it me? Is it you? >> Yeah. And when this impacts multiple agents like changing a tool definition is act changing the the prompt that the agent has access to. So it's crucial to evaluate because if you if you change that you're going to impact all these downstream tasks >> and it's yeah it's really crucial to have good evaluations in place not just for the tool but for how the agent will use this tool and will interact with that >> and and I I would to link it back I mean I think this is where lading up tools really matters because my agent consuming the shared you know user insertion into the CRM tool is going to likely have different set of evals. >> Yeah. >> Than your tool because we just have different context. We have a different intentions. >> Huh. >> And and I'm going to bloat your tool irreparably for all the other agents if I try and insert all of my needs and demands onto it. But if I then if I'm just if I instead I just layer up my own domain specific tool or agent specific tool that sits on top of yours then suddenly sharing and repeatability still works without having to sacrifice accuracy and consistency and latency for for the agent. So now I can share the we can share the same tool and I can have my own little domain specific issues with my own set of eval agent separate from yours. I see what you're saying where it's like you normally have to go really deep on something and really craft it so that you understand the problem set, you understand how to build that agent in the best way possible. But at the same time, I feel like if you're getting that detailed with it, you're now creating a whole lot more work for every team. >> Yeah, you are. You are absolutely creating more work. But this is this is the trade-off, right? It's all about knobs and dials. >> It's if you're a single agent team, you don't need this. >> Yeah. >> Right. But the and and and the individual agent developers, >> you know, aren't going to be thinking about this. >> It's the moment that you're running an agent program, >> you know, call it a center of excellence or whatever. I mean the moment you're building multiple agents >> across an organization >> if you're a Fortune 2000 and you're >> you have you even here you have a mandate for 30,000 agents >> and this becomes a requirement at scale if everybody's rebuilding the wheel every single time you have you the productivity gains of of flipping the script become pretty high >> because when I go start my my new agent. I don't have to go build all this stuff from scratch. >> I can go see in the registry, oh, what are all the different tools that already exist? Oh, let me pick that one. Let me pick this one. Let me pick this one. And then I can build my own tools on top to personalize them >> and everybody wins. But that's just the developer productivity piece. If you think about senior leadership and and the governance problems, it becomes possible to put your arms around it. If you don't have any kind of reuse or reusability or registry or things like that, you know, when the CISO or the compliance team or senior leadership worried about performance wants to go see what's happening, they have to go look at what 300,000 tools. That's not going to work. >> They're all marginally different. That's that's a fail, right? >> Yeah. At the same time, there is no substitute for really digging deep into a problem. Um cuz starting the other way around uh I think would be a disaster. Like if you start from defining what tools can be built for the teams before even you're solving the business problem. >> Uh that is a recipe for disaster like you're going to overengineer things and like the tool is going to have to be changed so many times. So yeah, what we found at works was really to to build something, you know, you know, like building an agent in production is way different from thinking about an agent like um you you you find challenges you didn't even think about. So before you have done that, I think you shouldn't even even start thinking about uh how this can be shared across teams. >> Um >> I I I I agree with a few nuances. I think that's that's generally the best practice. We >> again we talk to a lot of customers and they're all coming from different angles, right? You know, there's an particular agent team that needs to go unlock a particular piece of functionality. they want to talk to email or calendar or you know some custom service and then we'll also talk to CIOS and you know their VPs who are trying to architect the organization and the enterprise for agents >> and we we have a saying internally which is uh regardless of where we come in as a vendor and to help an organization we always drive the conversation to the first agent >> for that same reason. It's like, well, before anybody gets caught up, you know, in in in building like the cysteine chapel of of complex agent governance and systems, let let's first make sure that you've got your agent, your first agent at least, successful and working and you got the right patterns. >> And you're absolutely right. You should go deep first and then once it's working, then abstract out and then start optimizing for sharing and reusability and all that fun stuff. But you can't start there. However, with uh some um third party tools that are, you know, pretty widely accepted by now, like managing calendar, emails, I think, you know, that's a it's a good bet to >> Yeah, those are easier, which is how you guys use >> a good reason to incorporate those, right? >> Yeah, everybody should use arcade. >> Awesome. >> And on that we can >> dude, the governance piece is wild. >> Oh my god, it's become like the conversation everywhere. Yeah, >> it's crazy because like >> 3 months ago I never heard the word. >> Well, I remember I told you after I was in San Francisco I was like all these CEOs talking about governance. >> Yeah. When you and I spoke I was like ah governance. >> Yeah. >> Now it has been every single conversation we're in. >> It is just it's wild to me how fast everything's changing. >> The maturity curve for most organizations is rapid. We notice also teams using multi- aent setups way more and sometimes agents look like they have a multi-agent setup where agents look very similar to each other and when when you start to dig deeper into the reasons it's governance. >> Yeah. >> I'll tell you what I'm seeing though here's my bet a year from now when we do this podcast again I think multi-agent systems are going to be a lot less common. >> Oh interesting. >> Yeah. We're starting to see the early signs of felt like as we talked through this agents and tools can be almost like interchanged in a way. >> Yeah. Actually, we um actually our sales engineer Schu um who is incredible um he he basically proved to all of us in a really dramatic way. I don't think he was even doing it on purpose that an agent is really just a collection of prompts and tools. >> Yeah. >> And people say it but nobody really believes it. Sus, you know, they all want to use all all the big systems and Schube just like slammed together a little YAML based agent builder >> and it [__] works, man. >> Like take that. >> Yeah, it just works. You just need prompts and tools and you're done. And it's got land graph under the hood, >> but it's wild, right? And um what we've been seeing is the scope definition of a of an of a sub agent. >> Mhm. is uh is getting bigger and bigger and bigger as context windows get bigger, as it can handle more tools, >> all of a sudden like you're seeing bigger sub agents. >> And so if you take that to the limit, like you're not going to see as complex of sub agents as people have been saying. Love you, baby.",
  "fetchedAt": "2026-01-18T18:34:24.702Z"
}