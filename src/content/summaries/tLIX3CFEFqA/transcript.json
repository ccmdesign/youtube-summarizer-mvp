{
  "videoId": "tLIX3CFEFqA",
  "language": "en",
  "source": "caption-extractor",
  "segments": [
    {
      "start": 0.16,
      "duration": 5.04,
      "text": "The last release from OpenAI was GPT5"
    },
    {
      "start": 2.72,
      "duration": 5.76,
      "text": "from August 7, 2025, which means the"
    },
    {
      "start": 5.2,
      "duration": 5.76,
      "text": "upgrade GPT 5.1 on November 12th makes"
    },
    {
      "start": 8.48,
      "duration": 5.279,
      "text": "the release cycle 97 days. Now for"
    },
    {
      "start": 10.96,
      "duration": 5.04,
      "text": "Google, the release of Gemini 2.5 was"
    },
    {
      "start": 13.759,
      "duration": 4.321,
      "text": "made on March 25th, and the entire"
    },
    {
      "start": 16,
      "duration": 4.8,
      "text": "community was waiting for the release of"
    },
    {
      "start": 18.08,
      "duration": 4.8,
      "text": "a much anticipated Gemini 3, which came"
    },
    {
      "start": 20.8,
      "duration": 5.28,
      "text": "out on November 18, which makes their"
    },
    {
      "start": 22.88,
      "duration": 5.52,
      "text": "release cycle 238 days as far as major"
    },
    {
      "start": 26.08,
      "duration": 4.08,
      "text": "releases go. Okay, why am I bringing all"
    },
    {
      "start": 28.4,
      "duration": 3.999,
      "text": "of this up? is because during this"
    },
    {
      "start": 30.16,
      "duration": 4.48,
      "text": "period a lot has happened in the AI"
    },
    {
      "start": 32.399,
      "duration": 4.16,
      "text": "industry. Chinese Open models has had"
    },
    {
      "start": 34.64,
      "duration": 5.04,
      "text": "huge progress with their releases like"
    },
    {
      "start": 36.559,
      "duration": 6.481,
      "text": "Kim K2 thinking on November 6th, Ling on"
    },
    {
      "start": 39.68,
      "duration": 5.52,
      "text": "October 9, Miniax M2 on October 27th,"
    },
    {
      "start": 43.04,
      "duration": 4.16,
      "text": "Quen 3 on April 28th, as well as"
    },
    {
      "start": 45.2,
      "duration": 5.6,
      "text": "American counterparts like Cloud 4,"
    },
    {
      "start": 47.2,
      "duration": 5.28,
      "text": "Cloud Opus 4.1, Clad Son 4.5. All of"
    },
    {
      "start": 50.8,
      "duration": 3.759,
      "text": "which are impressive in their release"
    },
    {
      "start": 52.48,
      "duration": 3.68,
      "text": "cycle. And we're also expecting big"
    },
    {
      "start": 54.559,
      "duration": 4.241,
      "text": "things from Grok since their last"
    },
    {
      "start": 56.16,
      "duration": 5.36,
      "text": "release of Gro 4 on July 9th with recent"
    },
    {
      "start": 58.8,
      "duration": 4.64,
      "text": "4.1 upgrade and now we are anticipating"
    },
    {
      "start": 61.52,
      "duration": 4.48,
      "text": "what the next model holds. And before"
    },
    {
      "start": 63.44,
      "duration": 4.88,
      "text": "talking about the specifics of GPT 5.1"
    },
    {
      "start": 66,
      "duration": 4.56,
      "text": "and Gemini 3, it's important to address"
    },
    {
      "start": 68.32,
      "duration": 4.159,
      "text": "that even just a few weeks ago, the AI"
    },
    {
      "start": 70.56,
      "duration": 4.08,
      "text": "industry was raving about Chinese"
    },
    {
      "start": 72.479,
      "duration": 4.401,
      "text": "models. And now our news feed is"
    },
    {
      "start": 74.64,
      "duration": 4.479,
      "text": "inundated with the American models and"
    },
    {
      "start": 76.88,
      "duration": 4.48,
      "text": "the competition is boiling up hotter"
    },
    {
      "start": 79.119,
      "duration": 4.721,
      "text": "than ever considering that the Deep Seek"
    },
    {
      "start": 81.36,
      "duration": 4.56,
      "text": "R1 event that shook the world wasn't"
    },
    {
      "start": 83.84,
      "duration": 3.919,
      "text": "even a year ago when it happened back in"
    },
    {
      "start": 85.92,
      "duration": 4.08,
      "text": "January this year. But here's a critical"
    },
    {
      "start": 87.759,
      "duration": 5.521,
      "text": "question. Why does the release of Gemini"
    },
    {
      "start": 90,
      "duration": 5.759,
      "text": "3 and GPT 5.1 matter? First, Gemini 3"
    },
    {
      "start": 93.28,
      "duration": 4.479,
      "text": "was trained completely on Google's TPU."
    },
    {
      "start": 95.759,
      "duration": 4.161,
      "text": "And this has a huge implication when it"
    },
    {
      "start": 97.759,
      "duration": 4.161,
      "text": "comes to the AI industry's reliance on"
    },
    {
      "start": 99.92,
      "duration": 4.72,
      "text": "Nvidia's card, especially given that"
    },
    {
      "start": 101.92,
      "duration": 5.76,
      "text": "Google is also lending out their TPUs to"
    },
    {
      "start": 104.64,
      "duration": 4.88,
      "text": "Enthropic and Midjourney. So Gemini 3,"
    },
    {
      "start": 107.68,
      "duration": 3.6,
      "text": "which they're claiming as the most"
    },
    {
      "start": 109.52,
      "duration": 3.84,
      "text": "intelligent model, goes to show that"
    },
    {
      "start": 111.28,
      "duration": 4.32,
      "text": "even the top state-of-the-art models,"
    },
    {
      "start": 113.36,
      "duration": 4.16,
      "text": "can be done without relying on Nvidia"
    },
    {
      "start": 115.6,
      "duration": 4.32,
      "text": "chips. Now, that's not to say Nvidia"
    },
    {
      "start": 117.52,
      "duration": 4.559,
      "text": "isn't dire streets. Nvidia is doing just"
    },
    {
      "start": 119.92,
      "duration": 4.479,
      "text": "fine. In fact, their earnings call today"
    },
    {
      "start": 122.079,
      "duration": 4.64,
      "text": "show that they beat analyst expectation,"
    },
    {
      "start": 124.399,
      "duration": 4.241,
      "text": "not only in their Q3 revenue, but also"
    },
    {
      "start": 126.719,
      "duration": 4.24,
      "text": "in their earnings per share. And as you"
    },
    {
      "start": 128.64,
      "duration": 4.959,
      "text": "can see, their aftermarket is definitely"
    },
    {
      "start": 130.959,
      "duration": 5.36,
      "text": "rewarding this. But I do think Gemini 3"
    },
    {
      "start": 133.599,
      "duration": 4.64,
      "text": "is yet another reminder of how strong of"
    },
    {
      "start": 136.319,
      "duration": 4.481,
      "text": "a position that they are in for a long"
    },
    {
      "start": 138.239,
      "duration": 4.881,
      "text": "term. If the AR race is a marathon,"
    },
    {
      "start": 140.8,
      "duration": 4.88,
      "text": "Google has a strong capital expenditure"
    },
    {
      "start": 143.12,
      "duration": 5.199,
      "text": "position, huge access to training data,"
    },
    {
      "start": 145.68,
      "duration": 4.48,
      "text": "and their own TPUs. And I wonder if this"
    },
    {
      "start": 148.319,
      "duration": 4.321,
      "text": "is one of the reasons why Berkshire"
    },
    {
      "start": 150.16,
      "duration": 4.4,
      "text": "Hathaway continues to invest in Google"
    },
    {
      "start": 152.64,
      "duration": 4.4,
      "text": "in the midst of them growing their cash"
    },
    {
      "start": 154.56,
      "duration": 5.36,
      "text": "positions. Now, OpenAI also released the"
    },
    {
      "start": 157.04,
      "duration": 5.68,
      "text": "model GPT 5.1 and they also silently"
    },
    {
      "start": 159.92,
      "duration": 4.8,
      "text": "released a new model called GPT 5.1 Pro,"
    },
    {
      "start": 162.72,
      "duration": 4.72,
      "text": "which is just 1 day after the release of"
    },
    {
      "start": 164.72,
      "duration": 5.2,
      "text": "Gemini 3. This just goes to show how"
    },
    {
      "start": 167.44,
      "duration": 4.879,
      "text": "much strategy goes into model releases."
    },
    {
      "start": 169.92,
      "duration": 4.72,
      "text": "Even looking at how Grock 4.1 was"
    },
    {
      "start": 172.319,
      "duration": 3.92,
      "text": "released one day prior to Gemini 3's"
    },
    {
      "start": 174.64,
      "duration": 3.92,
      "text": "release. Now, let's take it back to the"
    },
    {
      "start": 176.239,
      "duration": 4.241,
      "text": "basics. When we're talking about AI,"
    },
    {
      "start": 178.56,
      "duration": 4.399,
      "text": "what we're really talking about is the"
    },
    {
      "start": 180.48,
      "duration": 4.08,
      "text": "intelligence. How good is Google at"
    },
    {
      "start": 182.959,
      "duration": 4.081,
      "text": "demonstrating intelligence with their"
    },
    {
      "start": 184.56,
      "duration": 4.319,
      "text": "Gemini 3 model? And how good is OpenAI"
    },
    {
      "start": 187.04,
      "duration": 4.4,
      "text": "at demonstrating their intelligence with"
    },
    {
      "start": 188.879,
      "duration": 4.401,
      "text": "the GPT 5.1 Pro model? And we have"
    },
    {
      "start": 191.44,
      "duration": 3.92,
      "text": "people on two different sides of the"
    },
    {
      "start": 193.28,
      "duration": 4.08,
      "text": "camps. We have people who care about how"
    },
    {
      "start": 195.36,
      "duration": 3.92,
      "text": "the model performs in the real world,"
    },
    {
      "start": 197.36,
      "duration": 4.08,
      "text": "like coding tasks. And we also have"
    },
    {
      "start": 199.28,
      "duration": 4.08,
      "text": "people who go by how the model actually"
    },
    {
      "start": 201.44,
      "duration": 3.68,
      "text": "feels. And depending on what actually"
    },
    {
      "start": 203.36,
      "duration": 4,
      "text": "matters to you, your opinion on the"
    },
    {
      "start": 205.12,
      "duration": 4.72,
      "text": "matter will be different. And honestly,"
    },
    {
      "start": 207.36,
      "duration": 4.799,
      "text": "where all of this leads to is AGI. And"
    },
    {
      "start": 209.84,
      "duration": 4.88,
      "text": "yeah, I fully understand and fully agree"
    },
    {
      "start": 212.159,
      "duration": 5.281,
      "text": "that LLMs alone probably will never"
    },
    {
      "start": 214.72,
      "duration": 4.96,
      "text": "reach AGI. Setting aside what AGI even"
    },
    {
      "start": 217.44,
      "duration": 4.719,
      "text": "means, which is totally a separate video"
    },
    {
      "start": 219.68,
      "duration": 4.479,
      "text": "for another time. But my point is this."
    },
    {
      "start": 222.159,
      "duration": 4.401,
      "text": "Right now, we're doing all the manual"
    },
    {
      "start": 224.159,
      "duration": 4.881,
      "text": "work that actually goes into training AI"
    },
    {
      "start": 226.56,
      "duration": 4.239,
      "text": "models. But what if all of these manual"
    },
    {
      "start": 229.04,
      "duration": 3.44,
      "text": "tasks like gathering data for"
    },
    {
      "start": 230.799,
      "duration": 3.921,
      "text": "pre-training, optimizing"
    },
    {
      "start": 232.48,
      "duration": 4.64,
      "text": "hyperparameters, aligning the model in"
    },
    {
      "start": 234.72,
      "duration": 4.48,
      "text": "post- trainining are all automated? Will"
    },
    {
      "start": 237.12,
      "duration": 3.679,
      "text": "we then reach singularity at that point?"
    },
    {
      "start": 239.2,
      "duration": 3.599,
      "text": "I mean, if we figure out a way to"
    },
    {
      "start": 240.799,
      "duration": 4.08,
      "text": "automate all of these manual tasks,"
    },
    {
      "start": 242.799,
      "duration": 4.241,
      "text": "could we then have reached AGI by"
    },
    {
      "start": 244.879,
      "duration": 4.881,
      "text": "inherently letting it do all of that by"
    },
    {
      "start": 247.04,
      "duration": 5.199,
      "text": "itself? Now, I realize that LLMs have a"
    },
    {
      "start": 249.76,
      "duration": 4.559,
      "text": "huge flaw where it basically freezes its"
    },
    {
      "start": 252.239,
      "duration": 4.56,
      "text": "knowledge the moment training is done."
    },
    {
      "start": 254.319,
      "duration": 4.721,
      "text": "But once we have gigawatt level compute"
    },
    {
      "start": 256.799,
      "duration": 5.601,
      "text": "available like Stargate in Colossus"
    },
    {
      "start": 259.04,
      "duration": 5.599,
      "text": "where AI models like GPT 5.1 or Gemini 3"
    },
    {
      "start": 262.4,
      "duration": 5.2,
      "text": "can theoretically be trained in less"
    },
    {
      "start": 264.639,
      "duration": 4.961,
      "text": "than 24 hours. The path to singularity"
    },
    {
      "start": 267.6,
      "duration": 3.76,
      "text": "now starts to seem decently close,"
    },
    {
      "start": 269.6,
      "duration": 5.28,
      "text": "doesn't it? With that said, I do think"
    },
    {
      "start": 271.36,
      "duration": 5.6,
      "text": "the release of Gemini 3 and GPT 5.1 Pro,"
    },
    {
      "start": 274.88,
      "duration": 3.759,
      "text": "we're still working out the kinks. And"
    },
    {
      "start": 276.96,
      "duration": 3.6,
      "text": "one benchmark that I'm personally"
    },
    {
      "start": 278.639,
      "duration": 4.321,
      "text": "interested in is from artificial"
    },
    {
      "start": 280.56,
      "duration": 4.639,
      "text": "analysis called Omniscience Index. This"
    },
    {
      "start": 282.96,
      "duration": 4.239,
      "text": "benchmark shows you the credibility of"
    },
    {
      "start": 285.199,
      "duration": 4.801,
      "text": "the model where if the model scored"
    },
    {
      "start": 287.199,
      "duration": 4.881,
      "text": "zero, then the model is as often correct"
    },
    {
      "start": 290,
      "duration": 4.24,
      "text": "as it's often wrong. And if it tilts"
    },
    {
      "start": 292.08,
      "duration": 4.16,
      "text": "positively, the model is actually more"
    },
    {
      "start": 294.24,
      "duration": 4.56,
      "text": "often correct than it's false and vice"
    },
    {
      "start": 296.24,
      "duration": 4.48,
      "text": "versa. And this also rewards abstension,"
    },
    {
      "start": 298.8,
      "duration": 3.76,
      "text": "which basically means if the model isn't"
    },
    {
      "start": 300.72,
      "duration": 3.919,
      "text": "sure about its answer, it says it's"
    },
    {
      "start": 302.56,
      "duration": 4,
      "text": "unsure rather than guessing the answer"
    },
    {
      "start": 304.639,
      "duration": 5.12,
      "text": "or just hallucinating it. And we got"
    },
    {
      "start": 306.56,
      "duration": 5.359,
      "text": "Gemini 3 Pro that scored 13. Claude 4.1"
    },
    {
      "start": 309.759,
      "duration": 5.521,
      "text": "Opus still taking the second place at"
    },
    {
      "start": 311.919,
      "duration": 6.081,
      "text": "five and GPT 5.1 high at two and close"
    },
    {
      "start": 315.28,
      "duration": 5.28,
      "text": "fourth for Gro 4. And as we reach closer"
    },
    {
      "start": 318,
      "duration": 4.8,
      "text": "and closer to AGI, I think credibility"
    },
    {
      "start": 320.56,
      "duration": 4,
      "text": "of the model is going to matter more and"
    },
    {
      "start": 322.8,
      "duration": 3.6,
      "text": "more where the model is able to"
    },
    {
      "start": 324.56,
      "duration": 3.76,
      "text": "demonstrate its ability to be more"
    },
    {
      "start": 326.4,
      "duration": 4.239,
      "text": "objective rather than actually"
    },
    {
      "start": 328.32,
      "duration": 4.48,
      "text": "hallucinating answer. Okay, I realized"
    },
    {
      "start": 330.639,
      "duration": 4.241,
      "text": "that I only covered the significance of"
    },
    {
      "start": 332.8,
      "duration": 4.48,
      "text": "these models rather than covering the"
    },
    {
      "start": 334.88,
      "duration": 4.4,
      "text": "actual use cases and the typical ways"
    },
    {
      "start": 337.28,
      "duration": 3.6,
      "text": "that model reviews are actually done."
    },
    {
      "start": 339.28,
      "duration": 3.359,
      "text": "And thankfully, you have a lot of"
    },
    {
      "start": 340.88,
      "duration": 3.68,
      "text": "YouTubers who are faithfully doing that."
    },
    {
      "start": 342.639,
      "duration": 3.921,
      "text": "So, I fully recommend checking out those"
    },
    {
      "start": 344.56,
      "duration": 3.359,
      "text": "channels for more in-depth reviews."
    },
    {
      "start": 346.56,
      "duration": 3.6,
      "text": "Well, I'm just trying to share my"
    },
    {
      "start": 347.919,
      "duration": 4.241,
      "text": "thoughts on the AI industry in general"
    },
    {
      "start": 350.16,
      "duration": 4.96,
      "text": "and how I'm excited about these models"
    },
    {
      "start": 352.16,
      "duration": 2.96,
      "text": "and why they matter."
    }
  ],
  "fullText": "The last release from OpenAI was GPT5 from August 7, 2025, which means the upgrade GPT 5.1 on November 12th makes the release cycle 97 days. Now for Google, the release of Gemini 2.5 was made on March 25th, and the entire community was waiting for the release of a much anticipated Gemini 3, which came out on November 18, which makes their release cycle 238 days as far as major releases go. Okay, why am I bringing all of this up? is because during this period a lot has happened in the AI industry. Chinese Open models has had huge progress with their releases like Kim K2 thinking on November 6th, Ling on October 9, Miniax M2 on October 27th, Quen 3 on April 28th, as well as American counterparts like Cloud 4, Cloud Opus 4.1, Clad Son 4.5. All of which are impressive in their release cycle. And we're also expecting big things from Grok since their last release of Gro 4 on July 9th with recent 4.1 upgrade and now we are anticipating what the next model holds. And before talking about the specifics of GPT 5.1 and Gemini 3, it's important to address that even just a few weeks ago, the AI industry was raving about Chinese models. And now our news feed is inundated with the American models and the competition is boiling up hotter than ever considering that the Deep Seek R1 event that shook the world wasn't even a year ago when it happened back in January this year. But here's a critical question. Why does the release of Gemini 3 and GPT 5.1 matter? First, Gemini 3 was trained completely on Google's TPU. And this has a huge implication when it comes to the AI industry's reliance on Nvidia's card, especially given that Google is also lending out their TPUs to Enthropic and Midjourney. So Gemini 3, which they're claiming as the most intelligent model, goes to show that even the top state-of-the-art models, can be done without relying on Nvidia chips. Now, that's not to say Nvidia isn't dire streets. Nvidia is doing just fine. In fact, their earnings call today show that they beat analyst expectation, not only in their Q3 revenue, but also in their earnings per share. And as you can see, their aftermarket is definitely rewarding this. But I do think Gemini 3 is yet another reminder of how strong of a position that they are in for a long term. If the AR race is a marathon, Google has a strong capital expenditure position, huge access to training data, and their own TPUs. And I wonder if this is one of the reasons why Berkshire Hathaway continues to invest in Google in the midst of them growing their cash positions. Now, OpenAI also released the model GPT 5.1 and they also silently released a new model called GPT 5.1 Pro, which is just 1 day after the release of Gemini 3. This just goes to show how much strategy goes into model releases. Even looking at how Grock 4.1 was released one day prior to Gemini 3's release. Now, let's take it back to the basics. When we're talking about AI, what we're really talking about is the intelligence. How good is Google at demonstrating intelligence with their Gemini 3 model? And how good is OpenAI at demonstrating their intelligence with the GPT 5.1 Pro model? And we have people on two different sides of the camps. We have people who care about how the model performs in the real world, like coding tasks. And we also have people who go by how the model actually feels. And depending on what actually matters to you, your opinion on the matter will be different. And honestly, where all of this leads to is AGI. And yeah, I fully understand and fully agree that LLMs alone probably will never reach AGI. Setting aside what AGI even means, which is totally a separate video for another time. But my point is this. Right now, we're doing all the manual work that actually goes into training AI models. But what if all of these manual tasks like gathering data for pre-training, optimizing hyperparameters, aligning the model in post- trainining are all automated? Will we then reach singularity at that point? I mean, if we figure out a way to automate all of these manual tasks, could we then have reached AGI by inherently letting it do all of that by itself? Now, I realize that LLMs have a huge flaw where it basically freezes its knowledge the moment training is done. But once we have gigawatt level compute available like Stargate in Colossus where AI models like GPT 5.1 or Gemini 3 can theoretically be trained in less than 24 hours. The path to singularity now starts to seem decently close, doesn't it? With that said, I do think the release of Gemini 3 and GPT 5.1 Pro, we're still working out the kinks. And one benchmark that I'm personally interested in is from artificial analysis called Omniscience Index. This benchmark shows you the credibility of the model where if the model scored zero, then the model is as often correct as it's often wrong. And if it tilts positively, the model is actually more often correct than it's false and vice versa. And this also rewards abstension, which basically means if the model isn't sure about its answer, it says it's unsure rather than guessing the answer or just hallucinating it. And we got Gemini 3 Pro that scored 13. Claude 4.1 Opus still taking the second place at five and GPT 5.1 high at two and close fourth for Gro 4. And as we reach closer and closer to AGI, I think credibility of the model is going to matter more and more where the model is able to demonstrate its ability to be more objective rather than actually hallucinating answer. Okay, I realized that I only covered the significance of these models rather than covering the actual use cases and the typical ways that model reviews are actually done. And thankfully, you have a lot of YouTubers who are faithfully doing that. So, I fully recommend checking out those channels for more in-depth reviews. Well, I'm just trying to share my thoughts on the AI industry in general and how I'm excited about these models and why they matter.",
  "fetchedAt": "2026-01-18T18:34:30.181Z"
}