{
  "videoId": "y__qEgqXcF4",
  "language": "en",
  "source": "caption-extractor",
  "segments": [
    {
      "start": 0.24,
      "duration": 5.76,
      "text": "to end the year. Uh I wanted to do this"
    },
    {
      "start": 2.24,
      "duration": 6.48,
      "text": "year an AI awards 2025. So basically"
    },
    {
      "start": 6,
      "duration": 4,
      "text": "this is just going to be everything I"
    },
    {
      "start": 8.72,
      "duration": 3.839,
      "text": "thought about different things that"
    },
    {
      "start": 10,
      "duration": 4.32,
      "text": "happened in 2025. So I put up all of"
    },
    {
      "start": 12.559,
      "duration": 3.28,
      "text": "these categories. You can see I'm going"
    },
    {
      "start": 14.32,
      "duration": 4.4,
      "text": "to go through like best vibe coding"
    },
    {
      "start": 15.839,
      "duration": 5.2,
      "text": "platform, best AI IDE, best Aentic"
    },
    {
      "start": 18.72,
      "duration": 5.6,
      "text": "coder, best open source company, best"
    },
    {
      "start": 21.039,
      "duration": 5.841,
      "text": "open-source LLM, best image models, best"
    },
    {
      "start": 24.32,
      "duration": 5.68,
      "text": "video model, biggest disappointment,"
    },
    {
      "start": 26.88,
      "duration": 6.08,
      "text": "biggest surprise and the best AI startup"
    },
    {
      "start": 30,
      "duration": 5.2,
      "text": "of the year, best LLM, large language"
    },
    {
      "start": 32.96,
      "duration": 6.56,
      "text": "model, and the biggest moments I think"
    },
    {
      "start": 35.2,
      "duration": 6.64,
      "text": "in AI in biggest moment in AI in 25 and"
    },
    {
      "start": 39.52,
      "duration": 4.719,
      "text": "the AI person of the year. So these are"
    },
    {
      "start": 41.84,
      "duration": 4.239,
      "text": "kind of my categories and I thought we"
    },
    {
      "start": 44.239,
      "duration": 4.961,
      "text": "could just go through this and of course"
    },
    {
      "start": 46.079,
      "duration": 5.121,
      "text": "this is my award, right? So this is what"
    },
    {
      "start": 49.2,
      "duration": 3.92,
      "text": "I think. It's just my opinion. You might"
    },
    {
      "start": 51.2,
      "duration": 4.32,
      "text": "have a different opinion, but I think"
    },
    {
      "start": 53.12,
      "duration": 4,
      "text": "you will agree on some of them. So we're"
    },
    {
      "start": 55.52,
      "duration": 4.08,
      "text": "just going to go through this in almost"
    },
    {
      "start": 57.12,
      "duration": 4.8,
      "text": "this order. I think I put best LLM at"
    },
    {
      "start": 59.6,
      "duration": 3.92,
      "text": "the end of the video because I think"
    },
    {
      "start": 61.92,
      "duration": 3.84,
      "text": "that's the biggest thing, at least for"
    },
    {
      "start": 63.52,
      "duration": 4.48,
      "text": "me. So yeah, let's just get started and"
    },
    {
      "start": 65.76,
      "duration": 4.16,
      "text": "take a look at our first category and"
    },
    {
      "start": 68,
      "duration": 5.52,
      "text": "that is going to be the best vibe code"
    },
    {
      "start": 69.92,
      "duration": 6.16,
      "text": "platform for 2025. So uh I put up like"
    },
    {
      "start": 73.52,
      "duration": 4.88,
      "text": "the ones I have tried, right? And there"
    },
    {
      "start": 76.08,
      "duration": 4.32,
      "text": "are others too, but Rift, that's a"
    },
    {
      "start": 78.4,
      "duration": 3.759,
      "text": "Norwegian startup. Uh I think they do a"
    },
    {
      "start": 80.4,
      "duration": 4.719,
      "text": "pretty good job, so I had to have them"
    },
    {
      "start": 82.159,
      "duration": 5.6,
      "text": "in there. I played with them in 2025."
    },
    {
      "start": 85.119,
      "duration": 5.36,
      "text": "Bot new, Replabable,"
    },
    {
      "start": 87.759,
      "duration": 4.72,
      "text": "we all know those pretty well. So yeah,"
    },
    {
      "start": 90.479,
      "duration": 4.241,
      "text": "I think they have a good year and the"
    },
    {
      "start": 92.479,
      "duration": 4.401,
      "text": "numbers they put up. Uh all of these are"
    },
    {
      "start": 94.72,
      "duration": 5.84,
      "text": "very good. So there's definitely have"
    },
    {
      "start": 96.88,
      "duration": 6.16,
      "text": "been a blow up of this market in 2025."
    },
    {
      "start": 100.56,
      "duration": 5.04,
      "text": "And yeah, I just had to pick the one I"
    },
    {
      "start": 103.04,
      "duration": 5.691,
      "text": "think kind of has the most impact in"
    },
    {
      "start": 105.6,
      "duration": 3.839,
      "text": "2025. And the winner is"
    },
    {
      "start": 108.731,
      "duration": 2.549,
      "text": "[cheering]"
    },
    {
      "start": 109.439,
      "duration": 3.601,
      "text": "Lovable. I think they did a pretty good"
    },
    {
      "start": 111.28,
      "duration": 4.56,
      "text": "job this year. They got a lot of users."
    },
    {
      "start": 113.04,
      "duration": 5.759,
      "text": "They got a big like revenue spike. And"
    },
    {
      "start": 115.84,
      "duration": 5.599,
      "text": "basically W coding this year has had a"
    },
    {
      "start": 118.799,
      "duration": 4.481,
      "text": "large impact and Lobo Ball is one of"
    },
    {
      "start": 121.439,
      "duration": 4.96,
      "text": "them. I think they have a pretty easy"
    },
    {
      "start": 123.28,
      "duration": 6.16,
      "text": "software to use and yeah I don't know"
    },
    {
      "start": 126.399,
      "duration": 4.961,
      "text": "you can see here a lot of users pretty"
    },
    {
      "start": 129.44,
      "duration": 4.799,
      "text": "good product easy to use for people that"
    },
    {
      "start": 131.36,
      "duration": 4.4,
      "text": "are not no technical skills and I think"
    },
    {
      "start": 134.239,
      "duration": 3.521,
      "text": "it's a good entry point if you want to"
    },
    {
      "start": 135.76,
      "duration": 5.28,
      "text": "get into some more advanced stuff like"
    },
    {
      "start": 137.76,
      "duration": 5.52,
      "text": "cloud code and things. Uh yeah so not so"
    },
    {
      "start": 141.04,
      "duration": 6.4,
      "text": "hard to pick that one. Next category is"
    },
    {
      "start": 143.28,
      "duration": 6.8,
      "text": "the best AI IDE and I think we have a"
    },
    {
      "start": 147.44,
      "duration": 5.12,
      "text": "pretty good uh selection here. Cursor of"
    },
    {
      "start": 150.08,
      "duration": 5.439,
      "text": "course is the major player. Uh I have"
    },
    {
      "start": 152.56,
      "duration": 4.959,
      "text": "tried Klein. I had tried Ader this year."
    },
    {
      "start": 155.519,
      "duration": 3.601,
      "text": "Uh anti-gravity I tried at the end of"
    },
    {
      "start": 157.519,
      "duration": 5.201,
      "text": "the year. I kind of like that but I"
    },
    {
      "start": 159.12,
      "duration": 5.68,
      "text": "haven't used it much. So this one is"
    },
    {
      "start": 162.72,
      "duration": 5.84,
      "text": "also pretty easy for me. This is like my"
    },
    {
      "start": 164.8,
      "duration": 5.84,
      "text": "personal choice and that is going to be"
    },
    {
      "start": 168.56,
      "duration": 4.88,
      "text": "yeah cursor. That's the one I have used"
    },
    {
      "start": 170.64,
      "duration": 7.04,
      "text": "all year and I haven't felt any need to"
    },
    {
      "start": 173.44,
      "duration": 7.04,
      "text": "switch right you all know cursor pretty"
    },
    {
      "start": 177.68,
      "duration": 5.12,
      "text": "simple to use if you are kind of used to"
    },
    {
      "start": 180.48,
      "duration": 4,
      "text": "like VS code and stuff uh they"
    },
    {
      "start": 182.8,
      "duration": 4.96,
      "text": "introduced new features this year they"
    },
    {
      "start": 184.48,
      "duration": 5.92,
      "text": "have the agent and yeah updated with"
    },
    {
      "start": 187.76,
      "duration": 7.44,
      "text": "their own model I think is it called is"
    },
    {
      "start": 190.4,
      "duration": 7.44,
      "text": "it composer I think cursor composer one"
    },
    {
      "start": 195.2,
      "duration": 4.48,
      "text": "right I think they brought in their own"
    },
    {
      "start": 197.84,
      "duration": 5.36,
      "text": "Frontier model that's pretty I think"
    },
    {
      "start": 199.68,
      "duration": 6.16,
      "text": "this does pretty good job at least uh"
    },
    {
      "start": 203.2,
      "duration": 4.64,
      "text": "what I have tried and kind of the tab"
    },
    {
      "start": 205.84,
      "duration": 3.84,
      "text": "are kind of the best on the market. So"
    },
    {
      "start": 207.84,
      "duration": 5.52,
      "text": "yeah, not a hard pick for me to pick"
    },
    {
      "start": 209.68,
      "duration": 6.16,
      "text": "cursor for the best AI IDE of 2025. Next"
    },
    {
      "start": 213.36,
      "duration": 5.92,
      "text": "up we have the category for best aentic"
    },
    {
      "start": 215.84,
      "duration": 5.44,
      "text": "coder and here it's a bit more difficult"
    },
    {
      "start": 219.28,
      "duration": 4.72,
      "text": "I think because here I have two"
    },
    {
      "start": 221.28,
      "duration": 4.16,
      "text": "favorites this year I used a lot. Uh of"
    },
    {
      "start": 224,
      "duration": 3.599,
      "text": "course we have closed code. If you watch"
    },
    {
      "start": 225.44,
      "duration": 4.799,
      "text": "any of my videos you know I yeah love"
    },
    {
      "start": 227.599,
      "duration": 4.161,
      "text": "that one. Open Code. I really enjoyed"
    },
    {
      "start": 230.239,
      "duration": 4,
      "text": "Open Code this year. They are great,"
    },
    {
      "start": 231.76,
      "duration": 4.08,
      "text": "right? Uh I did try CodeCli. I think"
    },
    {
      "start": 234.239,
      "duration": 3.36,
      "text": "they are pretty good. They're getting"
    },
    {
      "start": 235.84,
      "duration": 5.2,
      "text": "better. Gemini CLI. This is the one I"
    },
    {
      "start": 237.599,
      "duration": 5.521,
      "text": "done the least. I gave it a shot like uh"
    },
    {
      "start": 241.04,
      "duration": 4.72,
      "text": "yeah in when it came out. I haven't"
    },
    {
      "start": 243.12,
      "duration": 4.88,
      "text": "really used it since. Uh so for me here,"
    },
    {
      "start": 245.76,
      "duration": 4.32,
      "text": "this pretty much between two. I would"
    },
    {
      "start": 248,
      "duration": 5.2,
      "text": "say it's between Claw Code and Open"
    },
    {
      "start": 250.08,
      "duration": 5.28,
      "text": "Code. And I think Codeex, yeah, like I"
    },
    {
      "start": 253.2,
      "duration": 5.52,
      "text": "said, they have done a pretty good job."
    },
    {
      "start": 255.36,
      "duration": 6.8,
      "text": "Uh actually uh more than I thought but"
    },
    {
      "start": 258.72,
      "duration": 5.903,
      "text": "um yeah for me uh as you will probably"
    },
    {
      "start": 262.16,
      "duration": 3.84,
      "text": "guess the winner is going to be"
    },
    {
      "start": 264.623,
      "duration": 4.257,
      "text": "[cheering and applause]"
    },
    {
      "start": 266,
      "duration": 4.88,
      "text": "yeah cloud code but open code I really"
    },
    {
      "start": 268.88,
      "duration": 4.48,
      "text": "recommend it because I have been using"
    },
    {
      "start": 270.88,
      "duration": 4.319,
      "text": "open code with open router that is also"
    },
    {
      "start": 273.36,
      "duration": 4.24,
      "text": "pretty good and I had a lot of fun with"
    },
    {
      "start": 275.199,
      "duration": 3.921,
      "text": "that. Uh but for me this is quite easy"
    },
    {
      "start": 277.6,
      "duration": 3.84,
      "text": "but that's kind of more like a personal"
    },
    {
      "start": 279.12,
      "duration": 4.88,
      "text": "choice. I think claude code is just"
    },
    {
      "start": 281.44,
      "duration": 5.12,
      "text": "amazing I I just love it. Everything I"
    },
    {
      "start": 284,
      "duration": 6,
      "text": "do is almost through CL code. I will say"
    },
    {
      "start": 286.56,
      "duration": 6.48,
      "text": "I use it almost every day, right? And"
    },
    {
      "start": 290,
      "duration": 4.8,
      "text": "yeah, I just and with the new skills"
    },
    {
      "start": 293.04,
      "duration": 5.36,
      "text": "that we're going to look more on in"
    },
    {
      "start": 294.8,
      "duration": 5.28,
      "text": "2026, I think, and MCP, they brought in"
    },
    {
      "start": 298.4,
      "duration": 4.64,
      "text": "that and everything and all the tools"
    },
    {
      "start": 300.08,
      "duration": 5.36,
      "text": "they have and now with Opus 4.5, I'm on"
    },
    {
      "start": 303.04,
      "duration": 4.48,
      "text": "the Max 200 plan. So, yeah, nothing else"
    },
    {
      "start": 305.44,
      "duration": 4,
      "text": "to say. H I'm a big fan of Cloud Code"
    },
    {
      "start": 307.52,
      "duration": 5.04,
      "text": "and I'm going to keep using it next"
    },
    {
      "start": 309.44,
      "duration": 6.4,
      "text": "year. And that's my winner for 2025 when"
    },
    {
      "start": 312.56,
      "duration": 6.639,
      "text": "it comes to agentic coders. Next"
    },
    {
      "start": 315.84,
      "duration": 4.88,
      "text": "category is best opensource company. And"
    },
    {
      "start": 319.199,
      "duration": 5.041,
      "text": "this one I think is a bit interesting."
    },
    {
      "start": 320.72,
      "duration": 6.479,
      "text": "Uh we have DeepSeek, Quen, Moonshot AI,"
    },
    {
      "start": 324.24,
      "duration": 4.799,
      "text": "and Flux. That's the one I picked out."
    },
    {
      "start": 327.199,
      "duration": 4.641,
      "text": "And we all know kind of DeepSick very"
    },
    {
      "start": 329.039,
      "duration": 5.681,
      "text": "well. Uh Quen uh had a great year. I"
    },
    {
      "start": 331.84,
      "duration": 6.96,
      "text": "think Moonshot AI came kind of in with"
    },
    {
      "start": 334.72,
      "duration": 5.68,
      "text": "Kim K2 and Flux. I really enjoy the Flux"
    },
    {
      "start": 338.8,
      "duration": 3.679,
      "text": "models. they are kind of doing some open"
    },
    {
      "start": 340.4,
      "duration": 4.079,
      "text": "source too. So I think they have a good"
    },
    {
      "start": 342.479,
      "duration": 3.361,
      "text": "job uh done a good job on kind of the"
    },
    {
      "start": 344.479,
      "duration": 5.041,
      "text": "media side of things. I wanted to"
    },
    {
      "start": 345.84,
      "duration": 6.56,
      "text": "include one media category here. Um,"
    },
    {
      "start": 349.52,
      "duration": 5.6,
      "text": "yeah, for me, uh, I guess this was"
    },
    {
      "start": 352.4,
      "duration": 6.72,
      "text": "pretty easy for me to be honest. And"
    },
    {
      "start": 355.12,
      "duration": 7.2,
      "text": "that's going to be, [cheering]"
    },
    {
      "start": 359.12,
      "duration": 5.6,
      "text": "yeah, I had to pick Quen just because"
    },
    {
      "start": 362.32,
      "duration": 4.56,
      "text": "uh, Quen AI. If we go to them, you can"
    },
    {
      "start": 364.72,
      "duration": 4,
      "text": "see they do a bunch of stuff stuff,"
    },
    {
      "start": 366.88,
      "duration": 3.12,
      "text": "right? Open source. And we can see some"
    },
    {
      "start": 368.72,
      "duration": 3.039,
      "text": "of their future products here. They have"
    },
    {
      "start": 370,
      "duration": 3.919,
      "text": "a great image generation models that is"
    },
    {
      "start": 371.759,
      "duration": 4.081,
      "text": "open source. I think it's the Quen 3VL"
    },
    {
      "start": 373.919,
      "duration": 4.321,
      "text": "model. They have some deep research"
    },
    {
      "start": 375.84,
      "duration": 4.88,
      "text": "tools. The thinking models are great. I"
    },
    {
      "start": 378.24,
      "duration": 4.799,
      "text": "like the Quen 3 coder. Yeah, as I said,"
    },
    {
      "start": 380.72,
      "duration": 5.599,
      "text": "and they did also a video model that is"
    },
    {
      "start": 383.039,
      "duration": 5.28,
      "text": "sup super popular, the van 2.2 model."
    },
    {
      "start": 386.319,
      "duration": 4.081,
      "text": "So, for me, this again was pretty easy"
    },
    {
      "start": 388.319,
      "duration": 4.481,
      "text": "to pick Quen as the best open source"
    },
    {
      "start": 390.4,
      "duration": 3.84,
      "text": "company of 2025."
    },
    {
      "start": 392.8,
      "duration": 4,
      "text": "So, there were some other good"
    },
    {
      "start": 394.24,
      "duration": 3.92,
      "text": "candidates, but for me, yeah, this is uh"
    },
    {
      "start": 396.8,
      "duration": 2.88,
      "text": "going to be Quen. I think they're owned"
    },
    {
      "start": 398.16,
      "duration": 4.64,
      "text": "by Alibaba now, but I'm just going to"
    },
    {
      "start": 399.68,
      "duration": 6.079,
      "text": "call them Quen anyway. So, next up, we"
    },
    {
      "start": 402.8,
      "duration": 5.119,
      "text": "have the best open-source large language"
    },
    {
      "start": 405.759,
      "duration": 5.44,
      "text": "model. And here you can see I've set the"
    },
    {
      "start": 407.919,
      "duration": 6.4,
      "text": "Kim K2 thinking deep 3.2 or I guess it"
    },
    {
      "start": 411.199,
      "duration": 4.56,
      "text": "would vi 3.2 too. Quentry, this could be"
    },
    {
      "start": 414.319,
      "duration": 3.361,
      "text": "coder. This could be just their main"
    },
    {
      "start": 415.759,
      "duration": 3.921,
      "text": "model. And I wanted to include the open"
    },
    {
      "start": 417.68,
      "duration": 4.32,
      "text": "source model from OpenAI. I I think it's"
    },
    {
      "start": 419.68,
      "duration": 4.32,
      "text": "a pretty good model. Actually, the 120B"
    },
    {
      "start": 422,
      "duration": 3.919,
      "text": "is great. I also like the 20B model."
    },
    {
      "start": 424,
      "duration": 4.16,
      "text": "Very good. So, this was more like all"
    },
    {
      "start": 425.919,
      "duration": 5.041,
      "text": "open source models, not the one only one"
    },
    {
      "start": 428.16,
      "duration": 5.12,
      "text": "you can run on your computer. And uh"
    },
    {
      "start": 430.96,
      "duration": 4.56,
      "text": "yeah, for me uh I had to think about"
    },
    {
      "start": 433.28,
      "duration": 5.28,
      "text": "this a bit because I played a lot of"
    },
    {
      "start": 435.52,
      "duration": 5.44,
      "text": "around with the Quen 3 uh coder model. I"
    },
    {
      "start": 438.56,
      "duration": 4.4,
      "text": "think that's a very good one. Deep 3.2"
    },
    {
      "start": 440.96,
      "duration": 4.32,
      "text": "too. I haven't used a lot to be honest."
    },
    {
      "start": 442.96,
      "duration": 4.799,
      "text": "I spent a lot of time on their earliest"
    },
    {
      "start": 445.28,
      "duration": 6.24,
      "text": "models. I think that was very good. Uh I"
    },
    {
      "start": 447.759,
      "duration": 7.28,
      "text": "have used the GPT OSS 20B quite a while"
    },
    {
      "start": 451.52,
      "duration": 6.399,
      "text": "and I think that's a good one. And yeah,"
    },
    {
      "start": 455.039,
      "duration": 5.681,
      "text": "Kim K2. Uh let's take a look at the"
    },
    {
      "start": 457.919,
      "duration": 5.041,
      "text": "winner. [cheering]"
    },
    {
      "start": 460.72,
      "duration": 4.08,
      "text": "Yeah, for me this is Kim K2 thinking. I"
    },
    {
      "start": 462.96,
      "duration": 6.48,
      "text": "think this is a superb model. I have"
    },
    {
      "start": 464.8,
      "duration": 8.239,
      "text": "used it in um clo in open code, right?"
    },
    {
      "start": 469.44,
      "duration": 5.92,
      "text": "And it's so good. I really like it and I"
    },
    {
      "start": 473.039,
      "duration": 4.641,
      "text": "would definitely go try this out on open"
    },
    {
      "start": 475.36,
      "duration": 5.2,
      "text": "router if you haven't and it's a really"
    },
    {
      "start": 477.68,
      "duration": 4.799,
      "text": "popular model. Kim K2 thinking you won't"
    },
    {
      "start": 480.56,
      "duration": 4.479,
      "text": "be disappointed. So this is from the"
    },
    {
      "start": 482.479,
      "duration": 5.521,
      "text": "company Moonshot AI as we saw just uh"
    },
    {
      "start": 485.039,
      "duration": 6.241,
      "text": "earlier and I think they did a very good"
    },
    {
      "start": 488,
      "duration": 5.919,
      "text": "job on this. Um, so if you haven't tried"
    },
    {
      "start": 491.28,
      "duration": 5.199,
      "text": "it out, maybe go to open router, link it"
    },
    {
      "start": 493.919,
      "duration": 5.761,
      "text": "up with your open code and give this"
    },
    {
      "start": 496.479,
      "duration": 5.521,
      "text": "model a test because uh I have been"
    },
    {
      "start": 499.68,
      "duration": 4.32,
      "text": "super impressed by this model. Okay, so"
    },
    {
      "start": 502,
      "duration": 4.479,
      "text": "our next category is going to be best"
    },
    {
      "start": 504,
      "duration": 6.8,
      "text": "image model or AI model of course of the"
    },
    {
      "start": 506.479,
      "duration": 5.92,
      "text": "year. Nano Banana Pro GPT image 1.5 that"
    },
    {
      "start": 510.8,
      "duration": 3.28,
      "text": "basically we just got I think it was"
    },
    {
      "start": 512.399,
      "duration": 3.921,
      "text": "last week, but it's a really good model"
    },
    {
      "start": 514.08,
      "duration": 5.6,
      "text": "though. I've tested it a bit and I think"
    },
    {
      "start": 516.32,
      "duration": 5.12,
      "text": "it's really good. Flux one uh context uh"
    },
    {
      "start": 519.68,
      "duration": 3.52,
      "text": "I really enjoyed earlier parts of the"
    },
    {
      "start": 521.44,
      "duration": 3.519,
      "text": "year so I wanted to include that. I used"
    },
    {
      "start": 523.2,
      "duration": 3.84,
      "text": "it a lot for like editing and stuff like"
    },
    {
      "start": 524.959,
      "duration": 4.641,
      "text": "that. This was kind of before Nano"
    },
    {
      "start": 527.04,
      "duration": 4.72,
      "text": "Bananaish around that time and I think"
    },
    {
      "start": 529.6,
      "duration": 4.72,
      "text": "it's a really good model to be honest"
    },
    {
      "start": 531.76,
      "duration": 4.88,
      "text": "and kind of my favorite model of the"
    },
    {
      "start": 534.32,
      "duration": 4.8,
      "text": "last part of the year at least from open"
    },
    {
      "start": 536.64,
      "duration": 5.36,
      "text": "source models is the said image turbo"
    },
    {
      "start": 539.12,
      "duration": 6.48,
      "text": "model. Uh, it's really good and it's"
    },
    {
      "start": 542,
      "duration": 5.68,
      "text": "superb fast, superb, super fast and it's"
    },
    {
      "start": 545.6,
      "duration": 4.16,
      "text": "really fun to use in applications on"
    },
    {
      "start": 547.68,
      "duration": 3.76,
      "text": "stuff just because of the speed and I've"
    },
    {
      "start": 549.76,
      "duration": 4.4,
      "text": "been so impressed kind of by the quality"
    },
    {
      "start": 551.44,
      "duration": 4.32,
      "text": "of this and they are releasing a bigger"
    },
    {
      "start": 554.16,
      "duration": 4.56,
      "text": "model soon that I think it's going to be"
    },
    {
      "start": 555.76,
      "duration": 4.56,
      "text": "very good. Uh, but again this was pretty"
    },
    {
      "start": 558.72,
      "duration": 3.84,
      "text": "easy, right? If you watch any of my"
    },
    {
      "start": 560.32,
      "duration": 6.959,
      "text": "videos this year, you know who is this"
    },
    {
      "start": 562.56,
      "duration": 6.16,
      "text": "uh who this awards goes to."
    },
    {
      "start": 567.279,
      "duration": 3.201,
      "text": "Yeah, of course it's going to be Nano"
    },
    {
      "start": 568.72,
      "duration": 4.239,
      "text": "Banana Pro. I think this is one of my"
    },
    {
      "start": 570.48,
      "duration": 4.56,
      "text": "highlights of the year to be honest."
    },
    {
      "start": 572.959,
      "duration": 4.56,
      "text": "It's such a fun model to play around"
    },
    {
      "start": 575.04,
      "duration": 4.479,
      "text": "with if you like to do images and stuff."
    },
    {
      "start": 577.519,
      "duration": 5.041,
      "text": "And I've been using a lot on the API"
    },
    {
      "start": 579.519,
      "duration": 5.361,
      "text": "side, maybe from FAL or Google itself."
    },
    {
      "start": 582.56,
      "duration": 4.8,
      "text": "And yeah, basically I did this"
    },
    {
      "start": 584.88,
      "duration": 4.639,
      "text": "presentation with Nano Balan Pro. That"
    },
    {
      "start": 587.36,
      "duration": 4.96,
      "text": "kind of says it all, right? And it's"
    },
    {
      "start": 589.519,
      "duration": 6.161,
      "text": "such a fun model. And what you can do"
    },
    {
      "start": 592.32,
      "duration": 5.92,
      "text": "with this is kind of mindblowing if you"
    },
    {
      "start": 595.68,
      "duration": 6.159,
      "text": "ask me. the infographics that you can"
    },
    {
      "start": 598.24,
      "duration": 5.52,
      "text": "put in like all of these im input images"
    },
    {
      "start": 601.839,
      "duration": 4.881,
      "text": "and put them all together while keeping"
    },
    {
      "start": 603.76,
      "duration": 5.28,
      "text": "their consistency and it's so much fun"
    },
    {
      "start": 606.72,
      "duration": 5.119,
      "text": "to play around with. So if you haven't"
    },
    {
      "start": 609.04,
      "duration": 5.359,
      "text": "tried it yet, I'm quite surprised. But"
    },
    {
      "start": 611.839,
      "duration": 4.56,
      "text": "uh yeah, definitely go check that out if"
    },
    {
      "start": 614.399,
      "duration": 3.601,
      "text": "you haven't tried it yet. So a clear"
    },
    {
      "start": 616.399,
      "duration": 4.081,
      "text": "winner for me. There was really no"
    },
    {
      "start": 618,
      "duration": 5.92,
      "text": "competition to be honest. So next up is"
    },
    {
      "start": 620.48,
      "duration": 6.24,
      "text": "the best AI video model and a big year"
    },
    {
      "start": 623.92,
      "duration": 6,
      "text": "for AI video to be honest. Uh, a lot has"
    },
    {
      "start": 626.72,
      "duration": 4.96,
      "text": "happened. So, uh, yeah, V3 was kind of"
    },
    {
      "start": 629.92,
      "duration": 3.76,
      "text": "the big thing I would say. Uh, so I"
    },
    {
      "start": 631.68,
      "duration": 4.719,
      "text": "added in 3.1. They're kind of the small"
    },
    {
      "start": 633.68,
      "duration": 5.68,
      "text": "upgrade. We had Sora 2 that had like a"
    },
    {
      "start": 636.399,
      "duration": 5.281,
      "text": "big up spike in users and there was a"
    },
    {
      "start": 639.36,
      "duration": 3.84,
      "text": "lot of headlines and stuff uh, for a few"
    },
    {
      "start": 641.68,
      "duration": 4.56,
      "text": "weeks, but then it kind of died down"
    },
    {
      "start": 643.2,
      "duration": 6.8,
      "text": "again. Uh, I really enjoyed clinging"
    },
    {
      "start": 646.24,
      "duration": 6.24,
      "text": "models, the 2.6 Pro, the 2.5, and the"
    },
    {
      "start": 650,
      "duration": 4.079,
      "text": "van 2.2 in the open source community is"
    },
    {
      "start": 652.48,
      "duration": 2.88,
      "text": "really popular. I think that's a very"
    },
    {
      "start": 654.079,
      "duration": 3.521,
      "text": "good one."
    },
    {
      "start": 655.36,
      "duration": 5.44,
      "text": "And yeah, I had to think a bit here, but"
    },
    {
      "start": 657.6,
      "duration": 7.232,
      "text": "uh just thinking back on 2025,"
    },
    {
      "start": 660.8,
      "duration": 5.52,
      "text": "uh yeah, I had to go for this one."
    },
    {
      "start": 664.832,
      "duration": 3.488,
      "text": "[cheering]"
    },
    {
      "start": 666.32,
      "duration": 4.079,
      "text": "Yeah, I just think VO had kind of the"
    },
    {
      "start": 668.32,
      "duration": 5.28,
      "text": "most impact. Maybe it's not the best"
    },
    {
      "start": 670.399,
      "duration": 6.081,
      "text": "model to date. Uh but it had the most"
    },
    {
      "start": 673.6,
      "duration": 4.799,
      "text": "impact I would say in 2025 when it comes"
    },
    {
      "start": 676.48,
      "duration": 3.599,
      "text": "to video models. Therefore, I'm just"
    },
    {
      "start": 678.399,
      "duration": 3.921,
      "text": "going to give this award and I think"
    },
    {
      "start": 680.079,
      "duration": 5.2,
      "text": "it's kind of deserved. Uh it brought"
    },
    {
      "start": 682.32,
      "duration": 6.24,
      "text": "kind of native audio first in and we all"
    },
    {
      "start": 685.279,
      "duration": 7.841,
      "text": "kind of remember all the videos, right?"
    },
    {
      "start": 688.56,
      "duration": 6.56,
      "text": "Uh that was produced by VO. I don't"
    },
    {
      "start": 693.12,
      "duration": 4.64,
      "text": "really have to show you this if you are"
    },
    {
      "start": 695.12,
      "duration": 5.76,
      "text": "following the AI space. You kind of know"
    },
    {
      "start": 697.76,
      "duration": 5.68,
      "text": "VO, right? And I was thinking should I"
    },
    {
      "start": 700.88,
      "duration": 4.72,
      "text": "do like a thank you speech with VO, but"
    },
    {
      "start": 703.44,
      "duration": 4.56,
      "text": "I thought I just drop it because yeah,"
    },
    {
      "start": 705.6,
      "duration": 3.919,
      "text": "you know how it would sound anyway. So"
    },
    {
      "start": 708,
      "duration": 3.839,
      "text": "yeah, I think it's a welld deserved for"
    },
    {
      "start": 709.519,
      "duration": 4.32,
      "text": "VO3. Is it going to win next year? We'll"
    },
    {
      "start": 711.839,
      "duration": 4,
      "text": "see. Maybe we get a VO4. That's going to"
    },
    {
      "start": 713.839,
      "duration": 4.721,
      "text": "be interesting. So, the next category"
    },
    {
      "start": 715.839,
      "duration": 5.761,
      "text": "now doesn't have any nominees. So, yeah,"
    },
    {
      "start": 718.56,
      "duration": 6.08,
      "text": "we're just going to go straight into it."
    },
    {
      "start": 721.6,
      "duration": 4.88,
      "text": "And yeah, you will see what I mean. And"
    },
    {
      "start": 724.64,
      "duration": 4.72,
      "text": "I'm just going to talk a bit about it."
    },
    {
      "start": 726.48,
      "duration": 6.479,
      "text": "Right. So, the next uh winner, if you"
    },
    {
      "start": 729.36,
      "duration": 6,
      "text": "want to call it like that, is"
    },
    {
      "start": 732.959,
      "duration": 4.641,
      "text": "biggest disappointment. I've been a bit"
    },
    {
      "start": 735.36,
      "duration": 5.44,
      "text": "disappointed with OpenAI this year"
    },
    {
      "start": 737.6,
      "duration": 5.359,
      "text": "because they had such a big lead like"
    },
    {
      "start": 740.8,
      "duration": 4.159,
      "text": "and I thought they had like a great"
    },
    {
      "start": 742.959,
      "duration": 5.44,
      "text": "trajectory. I don't say they don't have"
    },
    {
      "start": 744.959,
      "duration": 6.641,
      "text": "that yet, but uh yeah, we saw that"
    },
    {
      "start": 748.399,
      "duration": 5.761,
      "text": "OpenAI red code or code red or whatever"
    },
    {
      "start": 751.6,
      "duration": 6.239,
      "text": "they call it, right? Uh yeah, declares"
    },
    {
      "start": 754.16,
      "duration": 5.76,
      "text": "code red and last part of the year they"
    },
    {
      "start": 757.839,
      "duration": 4.961,
      "text": "have been really I wouldn't say they"
    },
    {
      "start": 759.92,
      "duration": 5.68,
      "text": "have struggled but uh they have been"
    },
    {
      "start": 762.8,
      "duration": 6.32,
      "text": "yeah at least equalized or maybe"
    },
    {
      "start": 765.6,
      "duration": 6.32,
      "text": "slightly overtaken by like Google and I"
    },
    {
      "start": 769.12,
      "duration": 6.159,
      "text": "would even say anthropic. Uh so the"
    },
    {
      "start": 771.92,
      "duration": 7.039,
      "text": "biggest disappointment for me is OpenAI"
    },
    {
      "start": 775.279,
      "duration": 6.721,
      "text": "not focusing mostly on their core values"
    },
    {
      "start": 778.959,
      "duration": 6.241,
      "text": "like their their language models and"
    },
    {
      "start": 782,
      "duration": 5.44,
      "text": "maybe chat GPT they keep branching out"
    },
    {
      "start": 785.2,
      "duration": 4.319,
      "text": "to these things that never happen right"
    },
    {
      "start": 787.44,
      "duration": 5.12,
      "text": "open air what do they call it uh"
    },
    {
      "start": 789.519,
      "duration": 6.481,
      "text": "whatever they call it was it GPT"
    },
    {
      "start": 792.56,
      "duration": 6.88,
      "text": "store or something introducing the GPT"
    },
    {
      "start": 796,
      "duration": 5.76,
      "text": "store I know this was in 202"
    },
    {
      "start": 799.44,
      "duration": 4.399,
      "text": "4 but still"
    },
    {
      "start": 801.76,
      "duration": 4,
      "text": "and they keep all they keep trying to"
    },
    {
      "start": 803.839,
      "duration": 3.841,
      "text": "play all fields like I don't think they"
    },
    {
      "start": 805.76,
      "duration": 3.44,
      "text": "are big enough company to do that they"
    },
    {
      "start": 807.68,
      "duration": 4.08,
      "text": "do some good products I'm not saying"
    },
    {
      "start": 809.2,
      "duration": 5.52,
      "text": "that but uh maybe that all that"
    },
    {
      "start": 811.76,
      "duration": 5.519,
      "text": "computers kind of going over taking"
    },
    {
      "start": 814.72,
      "duration": 4.559,
      "text": "stuff away from their research and if"
    },
    {
      "start": 817.279,
      "duration": 4.881,
      "text": "they fall behind on kind of the core"
    },
    {
      "start": 819.279,
      "duration": 4.961,
      "text": "models yeah they could be in big trouble"
    },
    {
      "start": 822.16,
      "duration": 5.119,
      "text": "so yeah a bit of a disappointment I"
    },
    {
      "start": 824.24,
      "duration": 5.279,
      "text": "guess for me personally from OpenAI"
    },
    {
      "start": 827.279,
      "duration": 5.041,
      "text": "because I've been trying testing their"
    },
    {
      "start": 829.519,
      "duration": 6.241,
      "text": "models from 20 since 2020, right, with"
    },
    {
      "start": 832.32,
      "duration": 5.44,
      "text": "GT3 beta. So, a bit of a disappointment,"
    },
    {
      "start": 835.76,
      "duration": 3.759,
      "text": "but that's just my personal opinion. And"
    },
    {
      "start": 837.76,
      "duration": 6.4,
      "text": "for the next one, that's going to be uh"
    },
    {
      "start": 839.519,
      "duration": 7.841,
      "text": "the biggest surprise of the year."
    },
    {
      "start": 844.16,
      "duration": 5.919,
      "text": "And I would have to say Google's strong"
    },
    {
      "start": 847.36,
      "duration": 6.64,
      "text": "comeback because they had a really rough"
    },
    {
      "start": 850.079,
      "duration": 6.161,
      "text": "start to kind of the AI uh boom, right?"
    },
    {
      "start": 854,
      "duration": 5.68,
      "text": "And they were really struggling. Does"
    },
    {
      "start": 856.24,
      "duration": 5.2,
      "text": "anyone remember kind of Google Bard?"
    },
    {
      "start": 859.68,
      "duration": 3.92,
      "text": "Google Bard? I don't even think we can"
    },
    {
      "start": 861.44,
      "duration": 4.959,
      "text": "find it anymore. Yeah, that's a while"
    },
    {
      "start": 863.6,
      "duration": 6.4,
      "text": "ago now. And all the controversies they"
    },
    {
      "start": 866.399,
      "duration": 7.68,
      "text": "had in with their models, they weren't"
    },
    {
      "start": 870,
      "duration": 6.88,
      "text": "barely used like Gemini 2 and stuff and"
    },
    {
      "start": 874.079,
      "duration": 5.681,
      "text": "Bard and their models. Uh but uh I think"
    },
    {
      "start": 876.88,
      "duration": 5.04,
      "text": "when they released Gemini 2.5 Pro,"
    },
    {
      "start": 879.76,
      "duration": 4.079,
      "text": "something kind of changed. Uh they had a"
    },
    {
      "start": 881.92,
      "duration": 4.32,
      "text": "million context window. The model was"
    },
    {
      "start": 883.839,
      "duration": 4.24,
      "text": "really good and a lot of people starting"
    },
    {
      "start": 886.24,
      "duration": 5.92,
      "text": "to going over there. Then they followed"
    },
    {
      "start": 888.079,
      "duration": 6.801,
      "text": "up with like u VO3 that was like big in"
    },
    {
      "start": 892.16,
      "duration": 5.52,
      "text": "2025 and then they came with Nanu"
    },
    {
      "start": 894.88,
      "duration": 5.199,
      "text": "Banana. So I feel they had a great year"
    },
    {
      "start": 897.68,
      "duration": 3.92,
      "text": "right and the comeback they I would say"
    },
    {
      "start": 900.079,
      "duration": 4.161,
      "text": "they are on top now. They are kind of"
    },
    {
      "start": 901.6,
      "duration": 4.64,
      "text": "the best on almost the best on video. I"
    },
    {
      "start": 904.24,
      "duration": 4.959,
      "text": "think they are best on images and I"
    },
    {
      "start": 906.24,
      "duration": 5.36,
      "text": "think they are yeah almost likely like"
    },
    {
      "start": 909.199,
      "duration": 5.121,
      "text": "in the best of the language models too"
    },
    {
      "start": 911.6,
      "duration": 5.359,
      "text": "especially with the Gemini 3.3 Flash I"
    },
    {
      "start": 914.32,
      "duration": 6.079,
      "text": "think is a really good model. So yeah"
    },
    {
      "start": 916.959,
      "duration": 5.281,
      "text": "big s not maybe not a surprise but like"
    },
    {
      "start": 920.399,
      "duration": 4.161,
      "text": "yeah I would I I'm just going to call it"
    },
    {
      "start": 922.24,
      "duration": 4.959,
      "text": "a surprise uh because they had a really"
    },
    {
      "start": 924.56,
      "duration": 5.68,
      "text": "good comeback right so I think it's well"
    },
    {
      "start": 927.199,
      "duration": 6.801,
      "text": "deserved to Google for their comeback in"
    },
    {
      "start": 930.24,
      "duration": 6.08,
      "text": "2025. Next up, we have the best AI"
    },
    {
      "start": 934,
      "duration": 6.639,
      "text": "startup of the year. Uh, not everyone"
    },
    {
      "start": 936.32,
      "duration": 7.12,
      "text": "was started in maybe in 2025. Uh, but"
    },
    {
      "start": 940.639,
      "duration": 5.121,
      "text": "uh, yeah, these are kind of the startups"
    },
    {
      "start": 943.44,
      "duration": 5.519,
      "text": "I thought about that I've been thinking"
    },
    {
      "start": 945.76,
      "duration": 4.72,
      "text": "mostly about in 2025 and I think these"
    },
    {
      "start": 948.959,
      "duration": 3.521,
      "text": "are the best nominations. These are"
    },
    {
      "start": 950.48,
      "duration": 6.08,
      "text": "mine, right? You could say OpenAI is a"
    },
    {
      "start": 952.48,
      "duration": 6.479,
      "text": "startup, but yeah. Uh, so basically uh,"
    },
    {
      "start": 956.56,
      "duration": 4.16,
      "text": "Open Code. I love Open Code. I think"
    },
    {
      "start": 958.959,
      "duration": 6.161,
      "text": "it's super great. I don't know if they"
    },
    {
      "start": 960.72,
      "duration": 6,
      "text": "have like a big revenue model uh but uh"
    },
    {
      "start": 965.12,
      "duration": 3.279,
      "text": "yeah they have a really good product at"
    },
    {
      "start": 966.72,
      "duration": 4.239,
      "text": "least and it's open source and that's"
    },
    {
      "start": 968.399,
      "duration": 4,
      "text": "really cool. Artificial analysis is"
    },
    {
      "start": 970.959,
      "duration": 3.041,
      "text": "something I've been looking more into."
    },
    {
      "start": 972.399,
      "duration": 3.761,
      "text": "If you don't know what it is I can"
    },
    {
      "start": 974,
      "duration": 4.079,
      "text": "quickly show you is this I'm sure you've"
    },
    {
      "start": 976.16,
      "duration": 3.919,
      "text": "seen this. This is the index they run"
    },
    {
      "start": 978.079,
      "duration": 4.081,
      "text": "right. So they do a lot of benchmarking"
    },
    {
      "start": 980.079,
      "duration": 4.081,
      "text": "and I think it's pretty valuable. They"
    },
    {
      "start": 982.16,
      "duration": 5.039,
      "text": "have their intelligence index. You can"
    },
    {
      "start": 984.16,
      "duration": 4.88,
      "text": "see Gemini 3 Pro is on top here with uh"
    },
    {
      "start": 987.199,
      "duration": 4.721,
      "text": "GP2.5.2"
    },
    {
      "start": 989.04,
      "duration": 6.4,
      "text": "high extra high and then you see Gemini"
    },
    {
      "start": 991.92,
      "duration": 5.76,
      "text": "3 flash all the up here uh Opus 4.5 and"
    },
    {
      "start": 995.44,
      "duration": 6.399,
      "text": "they do a lot of really good stuff in"
    },
    {
      "start": 997.68,
      "duration": 6.32,
      "text": "like um benchmarking testing and it's a"
    },
    {
      "start": 1001.839,
      "duration": 6.321,
      "text": "really good place to just uh they also"
    },
    {
      "start": 1004,
      "duration": 7.36,
      "text": "do images just um image editing image"
    },
    {
      "start": 1008.16,
      "duration": 5.039,
      "text": "over okay so yeah definitely they're a"
    },
    {
      "start": 1011.36,
      "duration": 4.24,
      "text": "really cool company and I hope they will"
    },
    {
      "start": 1013.199,
      "duration": 5.041,
      "text": "continue to do this uh personally for me"
    },
    {
      "start": 1015.6,
      "duration": 5.039,
      "text": "I like foul AI they kind of compile all"
    },
    {
      "start": 1018.24,
      "duration": 4.56,
      "text": "the media model so I can do an API call"
    },
    {
      "start": 1020.639,
      "duration": 4.4,
      "text": "to all of them. Really helpful for me"
    },
    {
      "start": 1022.8,
      "duration": 3.84,
      "text": "that is building pipelines and stuff and"
    },
    {
      "start": 1025.039,
      "duration": 3.28,
      "text": "we talked about lovable they have just"
    },
    {
      "start": 1026.64,
      "duration": 4.72,
      "text": "had a great year so I thought I can"
    },
    {
      "start": 1028.319,
      "duration": 7.041,
      "text": "include them. Uh but for me personally"
    },
    {
      "start": 1031.36,
      "duration": 6.16,
      "text": "the winner is going to be"
    },
    {
      "start": 1035.36,
      "duration": 4.24,
      "text": "that was a bit laggy but open code."
    },
    {
      "start": 1037.52,
      "duration": 4.319,
      "text": "Yeah. Uh I think they are a superb"
    },
    {
      "start": 1039.6,
      "duration": 4.4,
      "text": "product. Uh I almost wanted to include"
    },
    {
      "start": 1041.839,
      "duration": 5.441,
      "text": "open router too but I couldn't find a"
    },
    {
      "start": 1044,
      "duration": 5.84,
      "text": "place for them. So, I really like the"
    },
    {
      "start": 1047.28,
      "duration": 4.48,
      "text": "combination of open code and the open"
    },
    {
      "start": 1049.84,
      "duration": 4.88,
      "text": "router, right? If you haven't tried"
    },
    {
      "start": 1051.76,
      "duration": 5.52,
      "text": "that. So, you can do open router uh to"
    },
    {
      "start": 1054.72,
      "duration": 4.64,
      "text": "kind of include um bunch of different"
    },
    {
      "start": 1057.28,
      "duration": 5.36,
      "text": "models and it's super easy to include"
    },
    {
      "start": 1059.36,
      "duration": 6,
      "text": "with open code. So, yeah, go try it out."
    },
    {
      "start": 1062.64,
      "duration": 5.44,
      "text": "Superb product if you haven't. So, yeah,"
    },
    {
      "start": 1065.36,
      "duration": 5.04,
      "text": "that is kind of my startup of the year."
    },
    {
      "start": 1068.08,
      "duration": 4.4,
      "text": "So, next up is also going to be like uh"
    },
    {
      "start": 1070.4,
      "duration": 4.8,
      "text": "no nominations. It's just going to be"
    },
    {
      "start": 1072.48,
      "duration": 5.76,
      "text": "the AI person of the year. And for me,"
    },
    {
      "start": 1075.2,
      "duration": 4.64,
      "text": "this was super easy. H I had don't even"
    },
    {
      "start": 1078.24,
      "duration": 6.16,
      "text": "have to think about this one. And for"
    },
    {
      "start": 1079.84,
      "duration": 8.88,
      "text": "me, that's clearly gonna be [cheering]"
    },
    {
      "start": 1084.4,
      "duration": 6.72,
      "text": "Deis Habis from Gemini and at least the"
    },
    {
      "start": 1088.72,
      "duration": 5.04,
      "text": "co-founder of Deep Mind and he's at"
    },
    {
      "start": 1091.12,
      "duration": 4.64,
      "text": "Google now. And yeah, I just think he"
    },
    {
      "start": 1093.76,
      "duration": 4.88,
      "text": "had a great year, right? Taking Google"
    },
    {
      "start": 1095.76,
      "duration": 6,
      "text": "kind of back on top. And I love all his"
    },
    {
      "start": 1098.64,
      "duration": 5.84,
      "text": "interviews, right? He seems so"
    },
    {
      "start": 1101.76,
      "duration": 4.88,
      "text": "intelligent and I really like his takes"
    },
    {
      "start": 1104.48,
      "duration": 4.559,
      "text": "on science and everything. He has like a"
    },
    {
      "start": 1106.64,
      "duration": 4.72,
      "text": "coder gaming background. He did game"
    },
    {
      "start": 1109.039,
      "duration": 5.441,
      "text": "design. He was a chess player. He did"
    },
    {
      "start": 1111.36,
      "duration": 5.76,
      "text": "open um not open but alpha fold and all"
    },
    {
      "start": 1114.48,
      "duration": 4.96,
      "text": "that work on deep mind kind of before"
    },
    {
      "start": 1117.12,
      "duration": 4.08,
      "text": "the generative AI stuff and I really"
    },
    {
      "start": 1119.44,
      "duration": 4.88,
      "text": "like him. He seems like a very smart"
    },
    {
      "start": 1121.2,
      "duration": 5.2,
      "text": "person and uh the what he's done with"
    },
    {
      "start": 1124.32,
      "duration": 4.719,
      "text": "Google and Deep Mind and stuff has just"
    },
    {
      "start": 1126.4,
      "duration": 5.44,
      "text": "been really impressive to be honest. So"
    },
    {
      "start": 1129.039,
      "duration": 5.281,
      "text": "yeah, kind of easy for me and I I I"
    },
    {
      "start": 1131.84,
      "duration": 4.88,
      "text": "would say a lot of other people would uh"
    },
    {
      "start": 1134.32,
      "duration": 4.16,
      "text": "agree on this. I think also the next"
    },
    {
      "start": 1136.72,
      "duration": 3.68,
      "text": "category is just going to be without any"
    },
    {
      "start": 1138.48,
      "duration": 4.96,
      "text": "nominations and I think pretty much"
    },
    {
      "start": 1140.4,
      "duration": 6.32,
      "text": "everyone will agree with me. So that is"
    },
    {
      "start": 1143.44,
      "duration": 5.76,
      "text": "kind of the biggest moment of AI in"
    },
    {
      "start": 1146.72,
      "duration": 4.959,
      "text": "2025. And again, I think this was pretty"
    },
    {
      "start": 1149.2,
      "duration": 4.923,
      "text": "easy and I think you all will agree with"
    },
    {
      "start": 1151.679,
      "duration": 3.36,
      "text": "this one to be honest."
    },
    {
      "start": 1154.123,
      "duration": 2.436,
      "text": "[cheering and applause]"
    },
    {
      "start": 1155.039,
      "duration": 4.241,
      "text": "Yeah, that was quite early this year."
    },
    {
      "start": 1156.559,
      "duration": 4.721,
      "text": "That was the Deep Seek R1, right? And"
    },
    {
      "start": 1159.28,
      "duration": 4.48,
      "text": "I'm sure you remember this one. This was"
    },
    {
      "start": 1161.28,
      "duration": 4.96,
      "text": "kind of all over the news. Everyone was"
    },
    {
      "start": 1163.76,
      "duration": 5.76,
      "text": "talking about this and it had a big"
    },
    {
      "start": 1166.24,
      "duration": 5.84,
      "text": "impact on kind of the the stock market."
    },
    {
      "start": 1169.52,
      "duration": 5.84,
      "text": "I think Nvidia dropped like was it like"
    },
    {
      "start": 1172.08,
      "duration": 7.12,
      "text": "20% or something? It was just insane."
    },
    {
      "start": 1175.36,
      "duration": 8,
      "text": "And the tech uh stock market in US"
    },
    {
      "start": 1179.2,
      "duration": 6.08,
      "text": "dropped like yeah 10 12%. Uh, I think"
    },
    {
      "start": 1183.36,
      "duration": 5.76,
      "text": "they had a big bounce back, but this was"
    },
    {
      "start": 1185.28,
      "duration": 6,
      "text": "an impressive moment uh to follow and I"
    },
    {
      "start": 1189.12,
      "duration": 4.96,
      "text": "think DeepSick R1 really put kind of"
    },
    {
      "start": 1191.28,
      "duration": 4.96,
      "text": "China back on the map in AI and it kind"
    },
    {
      "start": 1194.08,
      "duration": 4.8,
      "text": "of opened some doors for like Quen and"
    },
    {
      "start": 1196.24,
      "duration": 4.319,
      "text": "Kimmy Moonshot and the other models too"
    },
    {
      "start": 1198.88,
      "duration": 3.36,
      "text": "and I think they are doing still a good"
    },
    {
      "start": 1200.559,
      "duration": 4.161,
      "text": "job DeepSick and it's going to be"
    },
    {
      "start": 1202.24,
      "duration": 5.52,
      "text": "interesting to see what they do in 2026."
    },
    {
      "start": 1204.72,
      "duration": 5.68,
      "text": "So for me, yeah, pretty easy one uh to"
    },
    {
      "start": 1207.76,
      "duration": 7.12,
      "text": "pick for the biggest moment in AI in"
    },
    {
      "start": 1210.4,
      "duration": 8.639,
      "text": "2025. Okay, so last but not least, the"
    },
    {
      "start": 1214.88,
      "duration": 5.52,
      "text": "best large language model of 2025. So"
    },
    {
      "start": 1219.039,
      "duration": 2.88,
      "text": "this is pretty interesting, right?"
    },
    {
      "start": 1220.4,
      "duration": 4.08,
      "text": "Because we have some really good"
    },
    {
      "start": 1221.919,
      "duration": 4.88,
      "text": "candidates here and we have like a a"
    },
    {
      "start": 1224.48,
      "duration": 4.96,
      "text": "model that just came out, right? So for"
    },
    {
      "start": 1226.799,
      "duration": 5.841,
      "text": "me, it's going to be between Opus 4.5"
    },
    {
      "start": 1229.44,
      "duration": 5.44,
      "text": "from Antropic, Google's Gemini 3 Flash."
    },
    {
      "start": 1232.64,
      "duration": 4.56,
      "text": "I pick flash over pro because I've been"
    },
    {
      "start": 1234.88,
      "duration": 4.64,
      "text": "playing around with both and just the"
    },
    {
      "start": 1237.2,
      "duration": 5.04,
      "text": "speed of flash just makes me want to put"
    },
    {
      "start": 1239.52,
      "duration": 5.2,
      "text": "this up on top here. Uh is it the best"
    },
    {
      "start": 1242.24,
      "duration": 5.84,
      "text": "one? I'm not sure, but for me I I really"
    },
    {
      "start": 1244.72,
      "duration": 6.48,
      "text": "like it. Uh GPD 5.1 I think is good,"
    },
    {
      "start": 1248.08,
      "duration": 6,
      "text": "right? Uh I wouldn't say maybe it's up"
    },
    {
      "start": 1251.2,
      "duration": 4.719,
      "text": "with those two on top there, but it's a"
    },
    {
      "start": 1254.08,
      "duration": 3.76,
      "text": "good model. I think they did a pretty"
    },
    {
      "start": 1255.919,
      "duration": 4.481,
      "text": "good job on that. At least the pro"
    },
    {
      "start": 1257.84,
      "duration": 4,
      "text": "version, I would say. And I had to"
    },
    {
      "start": 1260.4,
      "duration": 3.04,
      "text": "include like an open source model. And"
    },
    {
      "start": 1261.84,
      "duration": 4.16,
      "text": "that's for me is pretty easy. It's the"
    },
    {
      "start": 1263.44,
      "duration": 4.96,
      "text": "Kimik K2 thinking model that I really"
    },
    {
      "start": 1266,
      "duration": 5.6,
      "text": "enjoy this year using here on open"
    },
    {
      "start": 1268.4,
      "duration": 4.88,
      "text": "router with open code. And yeah, it's"
    },
    {
      "start": 1271.6,
      "duration": 5.68,
      "text": "just such a fun model to play around"
    },
    {
      "start": 1273.28,
      "duration": 5.759,
      "text": "with the Kim K2 thinking. So yeah, I had"
    },
    {
      "start": 1277.28,
      "duration": 3.279,
      "text": "to think a bit here, but for me again,"
    },
    {
      "start": 1279.039,
      "duration": 4.401,
      "text": "it was pretty obvious. I might have some"
    },
    {
      "start": 1280.559,
      "duration": 5.441,
      "text": "biases and stuff like that, but uh yeah,"
    },
    {
      "start": 1283.44,
      "duration": 4.239,
      "text": "this was yeah, not that hard to be"
    },
    {
      "start": 1286,
      "duration": 4.64,
      "text": "honest. And for me, the winner is going"
    },
    {
      "start": 1287.679,
      "duration": 6.24,
      "text": "to be"
    },
    {
      "start": 1290.64,
      "duration": 6.8,
      "text": "OPUS 4.5. I think this is such a good"
    },
    {
      "start": 1293.919,
      "duration": 6.161,
      "text": "model, right? So, the Opus 4.5, uh,"
    },
    {
      "start": 1297.44,
      "duration": 5.2,
      "text": "maybe it's not the highest rated model"
    },
    {
      "start": 1300.08,
      "duration": 4.64,
      "text": "now, if you kind of look at benchmarks,"
    },
    {
      "start": 1302.64,
      "duration": 4.24,
      "text": "uh, but it just performs so good, at"
    },
    {
      "start": 1304.72,
      "duration": 5.36,
      "text": "least in combination kind of with Cloud"
    },
    {
      "start": 1306.88,
      "duration": 5.2,
      "text": "Code. And yeah, I really don't want to"
    },
    {
      "start": 1310.08,
      "duration": 4.719,
      "text": "kind of switch out this model at the"
    },
    {
      "start": 1312.08,
      "duration": 4.8,
      "text": "moment. And yeah, they they benchmark"
    },
    {
      "start": 1314.799,
      "duration": 3.921,
      "text": "pretty good here. But uh like I said, if"
    },
    {
      "start": 1316.88,
      "duration": 3.76,
      "text": "you try it out, at least in combination"
    },
    {
      "start": 1318.72,
      "duration": 3.6,
      "text": "with cloud code, you won't be"
    },
    {
      "start": 1320.64,
      "duration": 4,
      "text": "disappointed. At least if you do some"
    },
    {
      "start": 1322.32,
      "duration": 3.839,
      "text": "kind of coding and stuff like that. Uh I"
    },
    {
      "start": 1324.64,
      "duration": 3.44,
      "text": "also use it for other stuff. I think"
    },
    {
      "start": 1326.159,
      "duration": 5.361,
      "text": "it's pretty good. Even though it's kind"
    },
    {
      "start": 1328.08,
      "duration": 5.28,
      "text": "of mostly optimized for uh coding and"
    },
    {
      "start": 1331.52,
      "duration": 4.96,
      "text": "for me, yeah, this is the best large"
    },
    {
      "start": 1333.36,
      "duration": 4.88,
      "text": "language model for 2025."
    },
    {
      "start": 1336.48,
      "duration": 3.84,
      "text": "uh with good good competition from"
    },
    {
      "start": 1338.24,
      "duration": 4.08,
      "text": "Gemini 3. I would say at least the flash"
    },
    {
      "start": 1340.32,
      "duration": 4.56,
      "text": "model and the agentic tool calling and"
    },
    {
      "start": 1342.32,
      "duration": 6.32,
      "text": "the speed and stuff. Uh but I think Opus"
    },
    {
      "start": 1344.88,
      "duration": 5.84,
      "text": "did some good um they lowered the price"
    },
    {
      "start": 1348.64,
      "duration": 4.48,
      "text": "and they have some good optimization for"
    },
    {
      "start": 1350.72,
      "duration": 6.079,
      "text": "token use and that also makes it a bit"
    },
    {
      "start": 1353.12,
      "duration": 7.2,
      "text": "faster. Uh but yeah, for me this was the"
    },
    {
      "start": 1356.799,
      "duration": 6.081,
      "text": "best large language models of 2025 and"
    },
    {
      "start": 1360.32,
      "duration": 4.88,
      "text": "Tropics Opus 4.5. [music]"
    },
    {
      "start": 1362.88,
      "duration": 4.72,
      "text": "And yeah, that is basically what I had."
    },
    {
      "start": 1365.2,
      "duration": 4.56,
      "text": "So yeah, basically thanks for all the"
    },
    {
      "start": 1367.6,
      "duration": 4.48,
      "text": "support this year. It's been really fun"
    },
    {
      "start": 1369.76,
      "duration": 5.279,
      "text": "and I kind of completed my shipmas"
    },
    {
      "start": 1372.08,
      "duration": 4.88,
      "text": "series that I also enjoyed uh doing like"
    },
    {
      "start": 1375.039,
      "duration": 3.681,
      "text": "a video a day and it was really fun"
    },
    {
      "start": 1376.96,
      "duration": 4.4,
      "text": "being creative, thinking about new ideas"
    },
    {
      "start": 1378.72,
      "duration": 5.36,
      "text": "and stuff. So yeah, all I have to do now"
    },
    {
      "start": 1381.36,
      "duration": 4.72,
      "text": "is just wish you a merry Christmas and"
    },
    {
      "start": 1384.08,
      "duration": 3.44,
      "text": "I'm going to do like an update video"
    },
    {
      "start": 1386.08,
      "duration": 3.52,
      "text": "what I'm going to do with this channel"
    },
    {
      "start": 1387.52,
      "duration": 4,
      "text": "next year. I haven't decided yet."
    },
    {
      "start": 1389.6,
      "duration": 4.319,
      "text": "Probably do it in a week or so around"
    },
    {
      "start": 1391.52,
      "duration": 5.68,
      "text": "the New Year's. So yeah, enjoy your"
    },
    {
      "start": 1393.919,
      "duration": 6.321,
      "text": "holidays and have a happy new year. And"
    },
    {
      "start": 1397.2,
      "duration": 7.2,
      "text": "yeah, I'll see you again probably in a"
    },
    {
      "start": 1400.24,
      "duration": 4.16,
      "text": "week or so. So yeah, take care."
    }
  ],
  "fullText": "to end the year. Uh I wanted to do this year an AI awards 2025. So basically this is just going to be everything I thought about different things that happened in 2025. So I put up all of these categories. You can see I'm going to go through like best vibe coding platform, best AI IDE, best Aentic coder, best open source company, best open-source LLM, best image models, best video model, biggest disappointment, biggest surprise and the best AI startup of the year, best LLM, large language model, and the biggest moments I think in AI in biggest moment in AI in 25 and the AI person of the year. So these are kind of my categories and I thought we could just go through this and of course this is my award, right? So this is what I think. It's just my opinion. You might have a different opinion, but I think you will agree on some of them. So we're just going to go through this in almost this order. I think I put best LLM at the end of the video because I think that's the biggest thing, at least for me. So yeah, let's just get started and take a look at our first category and that is going to be the best vibe code platform for 2025. So uh I put up like the ones I have tried, right? And there are others too, but Rift, that's a Norwegian startup. Uh I think they do a pretty good job, so I had to have them in there. I played with them in 2025. Bot new, Replabable, we all know those pretty well. So yeah, I think they have a good year and the numbers they put up. Uh all of these are very good. So there's definitely have been a blow up of this market in 2025. And yeah, I just had to pick the one I think kind of has the most impact in 2025. And the winner is [cheering] Lovable. I think they did a pretty good job this year. They got a lot of users. They got a big like revenue spike. And basically W coding this year has had a large impact and Lobo Ball is one of them. I think they have a pretty easy software to use and yeah I don't know you can see here a lot of users pretty good product easy to use for people that are not no technical skills and I think it's a good entry point if you want to get into some more advanced stuff like cloud code and things. Uh yeah so not so hard to pick that one. Next category is the best AI IDE and I think we have a pretty good uh selection here. Cursor of course is the major player. Uh I have tried Klein. I had tried Ader this year. Uh anti-gravity I tried at the end of the year. I kind of like that but I haven't used it much. So this one is also pretty easy for me. This is like my personal choice and that is going to be yeah cursor. That's the one I have used all year and I haven't felt any need to switch right you all know cursor pretty simple to use if you are kind of used to like VS code and stuff uh they introduced new features this year they have the agent and yeah updated with their own model I think is it called is it composer I think cursor composer one right I think they brought in their own Frontier model that's pretty I think this does pretty good job at least uh what I have tried and kind of the tab are kind of the best on the market. So yeah, not a hard pick for me to pick cursor for the best AI IDE of 2025. Next up we have the category for best aentic coder and here it's a bit more difficult I think because here I have two favorites this year I used a lot. Uh of course we have closed code. If you watch any of my videos you know I yeah love that one. Open Code. I really enjoyed Open Code this year. They are great, right? Uh I did try CodeCli. I think they are pretty good. They're getting better. Gemini CLI. This is the one I done the least. I gave it a shot like uh yeah in when it came out. I haven't really used it since. Uh so for me here, this pretty much between two. I would say it's between Claw Code and Open Code. And I think Codeex, yeah, like I said, they have done a pretty good job. Uh actually uh more than I thought but um yeah for me uh as you will probably guess the winner is going to be [cheering and applause] yeah cloud code but open code I really recommend it because I have been using open code with open router that is also pretty good and I had a lot of fun with that. Uh but for me this is quite easy but that's kind of more like a personal choice. I think claude code is just amazing I I just love it. Everything I do is almost through CL code. I will say I use it almost every day, right? And yeah, I just and with the new skills that we're going to look more on in 2026, I think, and MCP, they brought in that and everything and all the tools they have and now with Opus 4.5, I'm on the Max 200 plan. So, yeah, nothing else to say. H I'm a big fan of Cloud Code and I'm going to keep using it next year. And that's my winner for 2025 when it comes to agentic coders. Next category is best opensource company. And this one I think is a bit interesting. Uh we have DeepSeek, Quen, Moonshot AI, and Flux. That's the one I picked out. And we all know kind of DeepSick very well. Uh Quen uh had a great year. I think Moonshot AI came kind of in with Kim K2 and Flux. I really enjoy the Flux models. they are kind of doing some open source too. So I think they have a good job uh done a good job on kind of the media side of things. I wanted to include one media category here. Um, yeah, for me, uh, I guess this was pretty easy for me to be honest. And that's going to be, [cheering] yeah, I had to pick Quen just because uh, Quen AI. If we go to them, you can see they do a bunch of stuff stuff, right? Open source. And we can see some of their future products here. They have a great image generation models that is open source. I think it's the Quen 3VL model. They have some deep research tools. The thinking models are great. I like the Quen 3 coder. Yeah, as I said, and they did also a video model that is sup super popular, the van 2.2 model. So, for me, this again was pretty easy to pick Quen as the best open source company of 2025. So, there were some other good candidates, but for me, yeah, this is uh going to be Quen. I think they're owned by Alibaba now, but I'm just going to call them Quen anyway. So, next up, we have the best open-source large language model. And here you can see I've set the Kim K2 thinking deep 3.2 or I guess it would vi 3.2 too. Quentry, this could be coder. This could be just their main model. And I wanted to include the open source model from OpenAI. I I think it's a pretty good model. Actually, the 120B is great. I also like the 20B model. Very good. So, this was more like all open source models, not the one only one you can run on your computer. And uh yeah, for me uh I had to think about this a bit because I played a lot of around with the Quen 3 uh coder model. I think that's a very good one. Deep 3.2 too. I haven't used a lot to be honest. I spent a lot of time on their earliest models. I think that was very good. Uh I have used the GPT OSS 20B quite a while and I think that's a good one. And yeah, Kim K2. Uh let's take a look at the winner. [cheering] Yeah, for me this is Kim K2 thinking. I think this is a superb model. I have used it in um clo in open code, right? And it's so good. I really like it and I would definitely go try this out on open router if you haven't and it's a really popular model. Kim K2 thinking you won't be disappointed. So this is from the company Moonshot AI as we saw just uh earlier and I think they did a very good job on this. Um, so if you haven't tried it out, maybe go to open router, link it up with your open code and give this model a test because uh I have been super impressed by this model. Okay, so our next category is going to be best image model or AI model of course of the year. Nano Banana Pro GPT image 1.5 that basically we just got I think it was last week, but it's a really good model though. I've tested it a bit and I think it's really good. Flux one uh context uh I really enjoyed earlier parts of the year so I wanted to include that. I used it a lot for like editing and stuff like that. This was kind of before Nano Bananaish around that time and I think it's a really good model to be honest and kind of my favorite model of the last part of the year at least from open source models is the said image turbo model. Uh, it's really good and it's superb fast, superb, super fast and it's really fun to use in applications on stuff just because of the speed and I've been so impressed kind of by the quality of this and they are releasing a bigger model soon that I think it's going to be very good. Uh, but again this was pretty easy, right? If you watch any of my videos this year, you know who is this uh who this awards goes to. Yeah, of course it's going to be Nano Banana Pro. I think this is one of my highlights of the year to be honest. It's such a fun model to play around with if you like to do images and stuff. And I've been using a lot on the API side, maybe from FAL or Google itself. And yeah, basically I did this presentation with Nano Balan Pro. That kind of says it all, right? And it's such a fun model. And what you can do with this is kind of mindblowing if you ask me. the infographics that you can put in like all of these im input images and put them all together while keeping their consistency and it's so much fun to play around with. So if you haven't tried it yet, I'm quite surprised. But uh yeah, definitely go check that out if you haven't tried it yet. So a clear winner for me. There was really no competition to be honest. So next up is the best AI video model and a big year for AI video to be honest. Uh, a lot has happened. So, uh, yeah, V3 was kind of the big thing I would say. Uh, so I added in 3.1. They're kind of the small upgrade. We had Sora 2 that had like a big up spike in users and there was a lot of headlines and stuff uh, for a few weeks, but then it kind of died down again. Uh, I really enjoyed clinging models, the 2.6 Pro, the 2.5, and the van 2.2 in the open source community is really popular. I think that's a very good one. And yeah, I had to think a bit here, but uh just thinking back on 2025, uh yeah, I had to go for this one. [cheering] Yeah, I just think VO had kind of the most impact. Maybe it's not the best model to date. Uh but it had the most impact I would say in 2025 when it comes to video models. Therefore, I'm just going to give this award and I think it's kind of deserved. Uh it brought kind of native audio first in and we all kind of remember all the videos, right? Uh that was produced by VO. I don't really have to show you this if you are following the AI space. You kind of know VO, right? And I was thinking should I do like a thank you speech with VO, but I thought I just drop it because yeah, you know how it would sound anyway. So yeah, I think it's a welld deserved for VO3. Is it going to win next year? We'll see. Maybe we get a VO4. That's going to be interesting. So, the next category now doesn't have any nominees. So, yeah, we're just going to go straight into it. And yeah, you will see what I mean. And I'm just going to talk a bit about it. Right. So, the next uh winner, if you want to call it like that, is biggest disappointment. I've been a bit disappointed with OpenAI this year because they had such a big lead like and I thought they had like a great trajectory. I don't say they don't have that yet, but uh yeah, we saw that OpenAI red code or code red or whatever they call it, right? Uh yeah, declares code red and last part of the year they have been really I wouldn't say they have struggled but uh they have been yeah at least equalized or maybe slightly overtaken by like Google and I would even say anthropic. Uh so the biggest disappointment for me is OpenAI not focusing mostly on their core values like their their language models and maybe chat GPT they keep branching out to these things that never happen right open air what do they call it uh whatever they call it was it GPT store or something introducing the GPT store I know this was in 202 4 but still and they keep all they keep trying to play all fields like I don't think they are big enough company to do that they do some good products I'm not saying that but uh maybe that all that computers kind of going over taking stuff away from their research and if they fall behind on kind of the core models yeah they could be in big trouble so yeah a bit of a disappointment I guess for me personally from OpenAI because I've been trying testing their models from 20 since 2020, right, with GT3 beta. So, a bit of a disappointment, but that's just my personal opinion. And for the next one, that's going to be uh the biggest surprise of the year. And I would have to say Google's strong comeback because they had a really rough start to kind of the AI uh boom, right? And they were really struggling. Does anyone remember kind of Google Bard? Google Bard? I don't even think we can find it anymore. Yeah, that's a while ago now. And all the controversies they had in with their models, they weren't barely used like Gemini 2 and stuff and Bard and their models. Uh but uh I think when they released Gemini 2.5 Pro, something kind of changed. Uh they had a million context window. The model was really good and a lot of people starting to going over there. Then they followed up with like u VO3 that was like big in 2025 and then they came with Nanu Banana. So I feel they had a great year right and the comeback they I would say they are on top now. They are kind of the best on almost the best on video. I think they are best on images and I think they are yeah almost likely like in the best of the language models too especially with the Gemini 3.3 Flash I think is a really good model. So yeah big s not maybe not a surprise but like yeah I would I I'm just going to call it a surprise uh because they had a really good comeback right so I think it's well deserved to Google for their comeback in 2025. Next up, we have the best AI startup of the year. Uh, not everyone was started in maybe in 2025. Uh, but uh, yeah, these are kind of the startups I thought about that I've been thinking mostly about in 2025 and I think these are the best nominations. These are mine, right? You could say OpenAI is a startup, but yeah. Uh, so basically uh, Open Code. I love Open Code. I think it's super great. I don't know if they have like a big revenue model uh but uh yeah they have a really good product at least and it's open source and that's really cool. Artificial analysis is something I've been looking more into. If you don't know what it is I can quickly show you is this I'm sure you've seen this. This is the index they run right. So they do a lot of benchmarking and I think it's pretty valuable. They have their intelligence index. You can see Gemini 3 Pro is on top here with uh GP2.5.2 high extra high and then you see Gemini 3 flash all the up here uh Opus 4.5 and they do a lot of really good stuff in like um benchmarking testing and it's a really good place to just uh they also do images just um image editing image over okay so yeah definitely they're a really cool company and I hope they will continue to do this uh personally for me I like foul AI they kind of compile all the media model so I can do an API call to all of them. Really helpful for me that is building pipelines and stuff and we talked about lovable they have just had a great year so I thought I can include them. Uh but for me personally the winner is going to be that was a bit laggy but open code. Yeah. Uh I think they are a superb product. Uh I almost wanted to include open router too but I couldn't find a place for them. So, I really like the combination of open code and the open router, right? If you haven't tried that. So, you can do open router uh to kind of include um bunch of different models and it's super easy to include with open code. So, yeah, go try it out. Superb product if you haven't. So, yeah, that is kind of my startup of the year. So, next up is also going to be like uh no nominations. It's just going to be the AI person of the year. And for me, this was super easy. H I had don't even have to think about this one. And for me, that's clearly gonna be [cheering] Deis Habis from Gemini and at least the co-founder of Deep Mind and he's at Google now. And yeah, I just think he had a great year, right? Taking Google kind of back on top. And I love all his interviews, right? He seems so intelligent and I really like his takes on science and everything. He has like a coder gaming background. He did game design. He was a chess player. He did open um not open but alpha fold and all that work on deep mind kind of before the generative AI stuff and I really like him. He seems like a very smart person and uh the what he's done with Google and Deep Mind and stuff has just been really impressive to be honest. So yeah, kind of easy for me and I I I would say a lot of other people would uh agree on this. I think also the next category is just going to be without any nominations and I think pretty much everyone will agree with me. So that is kind of the biggest moment of AI in 2025. And again, I think this was pretty easy and I think you all will agree with this one to be honest. [cheering and applause] Yeah, that was quite early this year. That was the Deep Seek R1, right? And I'm sure you remember this one. This was kind of all over the news. Everyone was talking about this and it had a big impact on kind of the the stock market. I think Nvidia dropped like was it like 20% or something? It was just insane. And the tech uh stock market in US dropped like yeah 10 12%. Uh, I think they had a big bounce back, but this was an impressive moment uh to follow and I think DeepSick R1 really put kind of China back on the map in AI and it kind of opened some doors for like Quen and Kimmy Moonshot and the other models too and I think they are doing still a good job DeepSick and it's going to be interesting to see what they do in 2026. So for me, yeah, pretty easy one uh to pick for the biggest moment in AI in 2025. Okay, so last but not least, the best large language model of 2025. So this is pretty interesting, right? Because we have some really good candidates here and we have like a a model that just came out, right? So for me, it's going to be between Opus 4.5 from Antropic, Google's Gemini 3 Flash. I pick flash over pro because I've been playing around with both and just the speed of flash just makes me want to put this up on top here. Uh is it the best one? I'm not sure, but for me I I really like it. Uh GPD 5.1 I think is good, right? Uh I wouldn't say maybe it's up with those two on top there, but it's a good model. I think they did a pretty good job on that. At least the pro version, I would say. And I had to include like an open source model. And that's for me is pretty easy. It's the Kimik K2 thinking model that I really enjoy this year using here on open router with open code. And yeah, it's just such a fun model to play around with the Kim K2 thinking. So yeah, I had to think a bit here, but for me again, it was pretty obvious. I might have some biases and stuff like that, but uh yeah, this was yeah, not that hard to be honest. And for me, the winner is going to be OPUS 4.5. I think this is such a good model, right? So, the Opus 4.5, uh, maybe it's not the highest rated model now, if you kind of look at benchmarks, uh, but it just performs so good, at least in combination kind of with Cloud Code. And yeah, I really don't want to kind of switch out this model at the moment. And yeah, they they benchmark pretty good here. But uh like I said, if you try it out, at least in combination with cloud code, you won't be disappointed. At least if you do some kind of coding and stuff like that. Uh I also use it for other stuff. I think it's pretty good. Even though it's kind of mostly optimized for uh coding and for me, yeah, this is the best large language model for 2025. uh with good good competition from Gemini 3. I would say at least the flash model and the agentic tool calling and the speed and stuff. Uh but I think Opus did some good um they lowered the price and they have some good optimization for token use and that also makes it a bit faster. Uh but yeah, for me this was the best large language models of 2025 and Tropics Opus 4.5. [music] And yeah, that is basically what I had. So yeah, basically thanks for all the support this year. It's been really fun and I kind of completed my shipmas series that I also enjoyed uh doing like a video a day and it was really fun being creative, thinking about new ideas and stuff. So yeah, all I have to do now is just wish you a merry Christmas and I'm going to do like an update video what I'm going to do with this channel next year. I haven't decided yet. Probably do it in a week or so around the New Year's. So yeah, enjoy your holidays and have a happy new year. And yeah, I'll see you again probably in a week or so. So yeah, take care.",
  "fetchedAt": "2026-01-18T18:34:43.138Z"
}